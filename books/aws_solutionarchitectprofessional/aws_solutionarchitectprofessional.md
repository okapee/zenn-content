---

title: "AWS Solution Architect Professionalに一発合格する方法"
summary: "AWS Solution Architect Professionalに確実に一発合格する方法、教えます。"
topics: ["AWS", "AWS Solution Architect Professional", "資格"] # トピック（5つまで）
published: true # falseだと下書き
price: 1000 # 有料の場合200〜5000

---



## AWS Solution Architect Professional について

まず試験を知りましょう。[公式ページ](https://aws.amazon.com/jp/certification/certified-solutions-architect-professional/)にまずはめをとおすことをオススメします。

> ### この試験の受験対象者
>
> AWS Certified Solutions Architect - Professional は、AWS でのクラウドアーキテクチャの設計とデプロイにおいて 2 年以上の実践的な経験を持つ個人を対象とするものです。この試験を受ける前に、以下の要件を満たすことをお勧めします。
>
> - AWS CLI、AWS API、AWS CloudFormation テンプレート、AWS 請求コンソール、AWS マネジメントコンソール、スクリプティング言語、および Windows と Linux 環境についての知識
> - エンタープライズの複数のアプリケーションやプロジェクトのアーキテクチャ設計に対し、ベストプラクティスガイダンスを提供する能力、およびビジネスの目標をアプリケーション/アーキテクチャ要件に関連付ける能力
> - クラウドアプリケーション要件を評価し、AWS でアプリケーションの実装、デプロイ、プロビジョニングを行うためのアーキテクチャを提案する能力
> - 主要な AWS テクノロジー (VPN、AWS Direct Connect など) や継続的なインテグレーション、デプロイプロセスを使用して、ハイブリッドアーキテクチャを設計する能力

> ### 試験の概要
>
> **レベル:** プロフェッショナル
> **時間:** 試験完了までに 180 分
> **コスト:** 300 USD



(当たり前ですが)明らかにAssociatesより難しいです。Associatesではゆるふわな理解でも乗り切れた部分もありましたが、Professionalはそれなりにきちんと理解していないと解けない問題もあります。

それ故に取得することはAWSの知識の底上げに繋がると考えます。



## モチベーション

- 私はガチエンジニアではないのですが、エンジニアに片足突っ込んだポジションのため、会社で提供しているサービスのインフラであるAWSをよりよく知り、提供しているサービスの全体像を明確に把握すること、インシデント発生時などに発生事象を解像度高く把握することなどを目的の一つとしています。
- プライベートではAWSを用いたサービス開発を行っておりますが、Amplifyを使っているためにだいぶ隠蔽されている部分があるため、その部分を明らかにし、スピーディーなトラブルシューティングや将来的なインフラ拡張に備えることができればと考えています。
- 単純にITに携わるものとして、このソリューションアーキテクトは、仮にAWSを使わなかったとしても知っておくべきインフラの知識が凝縮されており、取得しておいて損はないと思いました。



## 学習前の知識

- 普段、業務では極稀にAWSを触る程度。エンジニアではありません。
- 週末プログラマとして自分のサービスを開発中です。
- AWS Solution Architect Associatesは保持しています。



## 学習時間

140時間



以降で紹介している[AWS初心者がAWS 認定ソリューションアーキテクト – プロフェッショナル資格試験に合格した時の勉強法]というページでは、100時間が合格の目安になると仰っていますが、そのとおりだと思います。よく[40時間で合格しました!] というようなページを見かけますが、普段からAWSを触っている方以外はあまり参考にならない情報だと思います。事前知識に乏しい私のような人間は、最低でも100時間、確実に合格したければ150時間程度の学習は必要だと思います。(よっぽど効率の悪い学習方をしているわけではなければ)学習時間で結果はついてくると思います。



## オススメの学習方法

- まずは以下のようなページで試験の全体像を掴むと良い。
  - AWS初心者がAWS 認定ソリューションアーキテクト – プロフェッショナル資格試験に合格した時の勉強法 - Qiita https://qiita.com/fkooo/items/17fa401f4e46ecd00675#%E8%A9%A6%E9%A8%93%E5%AE%9F%E7%B8%BE
- 以下テキストでとにかく問題を解く。
  - AWS認定資格試験テキスト&問題集 AWS認定ソリューションアーキテクト - プロフェッショナル(Kindle版)
- AWS公式に模擬試験(AWS Certified Solutions Architect - Professional Official Practice Question Set (SAP-C02 - Japanese))があるので解く。
- AWSの公式でBlack BeltのドキュメントやYoutubeを見る。
  - 全部きっちりみようとしない。途中まででサービスの概要をつかめればOK。
  - 広告に時間を割くのは無駄。Youtube Premium登録必須。
  - 倍速で見れるChrome Extension([Video Speed Controller](https://pc-karuma.net/google-chrome-video-speed-controller/))必須。

- わからない部分を(本投稿のように)整理する。



## オススメしない学習方法

こちらは個人差がありますので、あくまで私の主観です。

- Udemy

  - 見返すのに時間を要する。リファレンス的にサッと引きづらい。時間がない人にはあまりオススメしない。

- koiwa club

  - Webで学べる問題集。解説はAWS公式からひっぱってきただけのような内容で、これだったらしっかり問題集やった方が良いと思われる。

  

## 合格して何を得たか

- 会社で提供しているサービスの構造についてより深堀りして理解することができた(進行形で理解している最中ではございますが)。
- プライベートで提供しているサービスの将来的なインフラ拡張のイメージが持てた。
- インフラ全体の知識の底上げが(たぶん)業務に役立つ。



## 試験を終えて試験問題について思うこと

- AWS Organizationsの知識は必須。大部分がアカウントを跨いだ場合の設問だったため、ここを理解ていないと厳しい。
- Organizationsと絡めたIAMの知識が問われる。特にロールに関する権限移譲の知識は必須。
- 逆に言うと↑の知識をしっかり押さえていれば合格点は取れると考える。



## 頻出知識整理

ここからは頻出知識の整理です。

### VPC全般

- 【図解/AWS】インターネットGWとNAT-GWの違い〜各メリット、パブリックサブネットとは〜 | SEの道標 https://milestone-of-se.nesuke.com/sv-advanced/aws/internet-nat-gateway/

  [![img](https://milestone-of-se.nesuke.com/wp-content/uploads/2019/02/inet-gw-and-nat-gw-1.png.webp)](https://milestone-of-se.nesuke.com/wp-content/uploads/2019/02/inet-gw-and-nat-gw-1.png)

- ルートテーブルとVPC内のルーティングについては[こちら](VPC Ingress Routingとは何かを噛み砕いて理解してみる | DevelopersIO https://dev.classmethod.jp/articles/what-is-vpc-ingress-routing/#toc-1)を一読しておくとよい。

- [こちら](https://qiita.com/c60evaporator/items/2f24d4796202e8b06a77#%E3%82%AA%E3%83%B3%E3%83%97%E3%83%AC%E3%81%A8vpc%E3%81%AE%E3%83%AB%E3%83%BC%E3%83%86%E3%82%A3%E3%83%B3%E3%82%B0%E3%81%AE%E9%81%95%E3%81%84)もVPCに係る情報が整理されていて一読の価値あり。

  >![VPCとリージョンとAZ](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F610167%2F9c219c92-c835-2073-b6f9-a77878a6c1e3.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&s=1d225acb610a6486829d2327cd4d2ce8)
  >
  >![VPCとサブネット](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F610167%2F0a2939b1-3fa0-5fd2-16eb-a7f0a1e20902.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&s=786d32d100d30018d7eec48eab8a869b)
  >
  >
  >
  >**ルートテーブルはサブネットごとに作成する事が可能**ですが、この際に重要となる概念が「**メインルートテーブル**」と「**サブネットルートテーブル**」です
  >
  >- **メインルートテーブル**：VPCごとに自動で作成されるルートテーブル(編集も可能)。**サブネットルートテーブルが設定されていないサブネットに適用**される
  >- **サブネットルートテーブル**：ユーザが自分で作成し、サブネットと紐づけるルートテーブル
  
  > | 名称                                   | VPC内部の接続対象            | 外部の接続対象                       | 料金 (リンク先に料金表)                                      |
  > | :------------------------------------- | :--------------------------- | :----------------------------------- | :----------------------------------------------------------- |
  > | **インターネットゲートウェイ**         | パブリックサブネット         | インターネット                       | [外向き通信量に課金](https://aws.amazon.com/jp/ec2/pricing/on-demand/#Data_Transfer) |
  > | **NATゲートウェイ**                    | プライベートサブネット       | インターネット(外向き通信のみ)       | [利用時間＋通信量に応じ課金](https://aws.amazon.com/jp/vpc/pricing/) |
  > | Egress Only インターネットゲートウェイ | プライベートサブネット       | インターネット(IPv6の外向き通信のみ) |                                                              |
  > | キャリアゲートウェイ                   | AWS Wavelength内のサブネット | インターネット(5Gネットワークのみ)   | [外向き通信量に課金](https://aws.amazon.com/jp/ec2/pricing/on-demand/#Data_Transfer) |
  > | **エンドポイント**                     | VPC全体                      | 他のAWSサービス                      | [インターフェース型のみ有料](https://aws.amazon.com/jp/privatelink/pricing/) (ゲートウェイ型は無料) |
  > | **エンドポイントサービス**             | VPC全体                      | 他アカウントのAWSサービス            | [後述](https://qiita.com/c60evaporator/items/2f24d4796202e8b06a77#エンドポイントサービス) |
  > | **VPCピアリング**                      | VPC全体                      | 他のVPC                              | [AZをまたぐ場合、通信量に応じ課金](https://aws.amazon.com/jp/ec2/pricing/on-demand/#Data_Transfer_within_the_same_AWS_Region) |
  > | **トランジットゲートウェイ**           | VPC全体                      | 他のVPCやオンプレネットワーク        | [利用時間＋通信量に応じ課金](https://aws.amazon.com/jp/transit-gateway/pricing/) |
  
  > #### インターネットゲートウェイ
  >
  > インターネットゲートウェイは**パブリックサブネットを作成する際に必ず必要となる**サービスであり、インターネットとの外向き、内向き**双方向**の通信を許可します。
  >
  > インターネットゲートウェイではグローバルIPアドレスとプライベートIPアドレスが1対1で変換されるため、**NAT**としての機能を果たします。
  >
  > #### ・NATゲートウェイ
  >
  > プライベートサブネットからは通常インターネットにアクセスできません([後述のエンドポイント経由のyumコマンド](https://qiita.com/c60evaporator/items/2f24d4796202e8b06a77#ゲートウェイエンドポイント経由でプライベートサブネットからyumコマンド実行)を除く)が、セキュリティパッチ更新等のためにインターネットにアクセスしたい場面も度々生じます。このような用途のために**プライベートサブネット**から**外向きの通信のみを許可**する(内向きは許可しない)サービスが、**NATゲートウェイ**です
  >
  > NATゲートウェイはプライベートサブネットのインターネット接続を実現するサービスですが、**NATゲートウェイ自身はパブリックサブネット上に設置**されます。
  >
  > なお名前が紛らわしいですが、NATゲートウェイは[前述した狭義のNAT](https://qiita.com/c60evaporator/items/2f24d4796202e8b06a77#nat-1)ではなく、ポートを含めて1対多でグローバルIPとプライベートIPを変換する[NAPT](https://qiita.com/c60evaporator/items/2f24d4796202e8b06a77#napt)としての機能を果たします。
  > グローバルIPとプライベートIPを1対1変換する狭義のNATの役割を果たすのは「インターネットゲートウェイ」ですので、ご注意ください
  >
  > ### Egress Only インターネットゲートウェイ
  >
  > IPv6専用のインターネットゲートウェイで、**外向きの通信のみを許可**する(内向きは許可しない)という意味で、IPv4におけるNATゲートウェイと同様の役割を果たします("Egress"とは「出力」を表します)
  >
  > ### エンドポイント (VPCエンドポイント)
  >
  > エンドポイントは、VPC内のインスタンスと**VPC外のAWSサービス**とを**インターネットを経由しない接続**(プライベート接続)で通信できるようにする機能です。
  >
  > VPCと他のAWSサービスとの接続はインターネットゲートウェイやNATゲートウェイ経由でも実現できますが、[**コスト面でエンドポイントを使用した方がメリットが大きい**](https://qiita.com/c60evaporator/items/2f24d4796202e8b06a77#vpcとコスト)です。
  >
  > エンドポイントは大きく以下の2種類に分けられます
  >
  > - **インターフェイスエンドポイント** ：**AWSサービスにVPC内のIPアドレスが割り振られる**(仮想NICとして機能する)方式。見かけ上はVPC内での通信で完結しているように見えるため、**設定がシンプルで管理しやすい**が、アクセスに**料金が発生**する (下図の`Endpoint network interface`が相当)
  >
  > [![img](https://qiita-user-contents.imgix.net/https%3A%2F%2Fdocs.aws.amazon.com%2Fja_jp%2Fvpc%2Flatest%2Fprivatelink%2Fimages%2Fvpc-endpoint-kinesis-private-dns-diagram.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&s=f332b561babf80ec912ad4eb2e001e46)](https://camo.qiitausercontent.com/2de941be8051c62528c028849cb4662ce9869679/68747470733a2f2f646f63732e6177732e616d617a6f6e2e636f6d2f6a615f6a702f7670632f6c61746573742f707269766174656c696e6b2f696d616765732f7670632d656e64706f696e742d6b696e657369732d707269766174652d646e732d6469616772616d2e706e67)
  >
  > - **ゲートウェイエンドポイント** ：**グローバルIPを持ったAWSサービス**へのルーティング設定が追加される方式。VPC外の機器という扱いとなるため、ACL等の**設定がやや複雑**となるが、アクセスは**無料**。S3とDynamoDBのみ使用可能 (下図の`VPC endpoint`が相当)
  >
  > [![img](https://qiita-user-contents.imgix.net/https%3A%2F%2Fdocs.aws.amazon.com%2Fja_jp%2Fvpc%2Flatest%2Fprivatelink%2Fimages%2Fvpc-endpoint-s3-diagram.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&s=25ed54f74fd3e39832e685f6f897830b)](https://camo.qiitausercontent.com/f97f78247cf73092433a94b5f3897ef2129a8f44/68747470733a2f2f646f63732e6177732e616d617a6f6e2e636f6d2f6a615f6a702f7670632f6c61746573742f707269766174656c696e6b2f696d616765732f7670632d656e64706f696e742d73332d6469616772616d2e706e67)
  >
  > 図を見ると分かりますが、**接続先のAWSサービス**は**インターフェイスエンドポイントではVPC内のホスト**(サブネット内にIPアドレスが存在する)、**ゲートウェイエンドポイントではVPC外のホスト** (VPC外のグローバルIPアドレスが割り振られ、ルーター経由でルーティングされる)として認識されていることが分かります
  
  [こちら](https://www.fenet.jp/aws/column/tool/999/)も参考に。

  > **AWS PrivateLinkとは、独自のアプリケーションとAWS上のサービス群をよりセキュアに接続する仕組みのことです。**
  >
  > AWSにおいてWebアプリケーションを作成する際、Amazon VPC（Amazon Virtual Private Cloud）上で割り当てられた仮想ネットワーク上に構築されます。
  >
  > 通常であれば、そのようにして作成されたWebアプリケーションはAWSでホストになり他のサービス、オンプレミス間で通信する場合、一度公開されたインターネットを経由してデータをやり取りします。
  >
  > AWS PrivateLink を利用すると、VPC およびサービス間のすべての通信を Amazon ネットワーク内で完結させるため、多くの規制・法令に対するセキュリティ要件を満たすことが可能になります。
  >
  > ### VPC エンドポイントとは？
  >
  > **VPC エンドポイントとは、Amazon PrivateLinkを利用したサービスとAmazon内でのプライベートな接続を可能にするための仮想デバイスのことです。**
  >
  > また、通信はプライベートなネットワークで行われるためインターネットゲートウェイ、NAT デバイス、VPN 接続、または AWS Direct Connectといったものは不要です。
  >
  > 独自のアプリケーションにVPC エンドポイントを設置すると、複雑な設定はなく接続先のエンドポイントサービス名を指定することでAWS PrivateLinkを利用できます。
  >
  > ### VPC エンドポイントの種類
  >
  > **VPC エンドポイントは全部で3つです。**設置の際はAWSのVPC Management Console上で操作します。
  >
  > クライアント側かサービス提供側で設置するVPCエンドポイントの種類が違いますが、きちんと項目で分けられているため設置の際は意識せずに作業できるようになっています。
  >
  > Amazon内のプライベートIPアドレスを持つ仮想ネットワークインターフェイスであり、これらのエンドポイントを通過する通信は全てAWS PrivateLinkを使用します。
  >
  > #### インターフェイスエンドポイント
  >
  > **インターフェイスゲートポイントはAWSでホストされたサービスを宛先とする通信のエントリポイントとして機能します。**
  >
  > VPC Management Consoleから「エンドポイント」の項目を選択して設置でき、独自のアプリケーションの他、AWSのサービスやAWS Marketplaceのサービスを指定できます。
  >
  > AWSのサービスから検索する場合、「AWS サービス」を検索し、検索結果一覧上でタイプが「Interface」と表示されている「com.amazonaws.リージョン名.サービス名」を選択すると設置できます。
  >
  > 「サービスを名前で検索」の場合は「com.amazonaws.リージョン名.サービス名」（DynamoDBとs3除く）で検索、「ご使用の AWS Marketplace サービス」の場合は表示される全てがインターフェイスエンドポイントとなります。
  >
  > #### ゲートウェイエンドポイント
  >
  > **ゲートウェイエンドポイントとは「Amazon S3」および「DynamoDB」のが宛先の通信のルートテーブルで、ルートのターゲットとして機能するものです。**
  >
  > こちらはその名の通りインターネットゲートウェイとして動作します。
  >
  > VPC Management Consoleから「エンドポイント」の項目を選択して「AWS サービス」を検索し、検索結果一覧上でタイプが「Gateway」と表示されている「com.amazonaws.リージョン名.dynamodb」もしくは「com.amazonaws.リージョン名.s3」を選択すると設置できます。
  >
  > 「サービスを名前で検索」の場合は「com.amazonaws.リージョン名.DynamoDB」もしくは「com.amazonaws.リージョン名.s3」で検索しましょう。
  >
  > #### ゲートウェイロードバランサーエンドポイント
  >
  > **ゲートロードバランサーエンドポイントは宛先への通信をインターセプトし、ゲートウェイロードバランサーを使用して各サービスに振り分けるためのエントリポイントとして機能します。**
  >
  > VPC Management Consoleから「エンドポイントサービス」の項目を選択して設置できます。
  >
  > こちらは独自のアプリケーションを公開する際の宛先としてエンドポイントサービスを構成できます。
  >
  > ただし、エンドポイントサービスを構成するには事前にAmazon EC2コンソールでNetwork Load Balancerを作成しておく必要があります。
  >
  > ## AWS PrivateLinkのメリット3つ
  >
  > ![img](https://b-engineer-media-cms.s3.amazonaws.com/item/image/user/9e08934fd24485c7d9e691a312f16a4ef7ff96eb/92e5f7e9-db15-40b0-a27f-8f192f3215b1.jpg)
  >
  > **AWS PrivateLinkには「通信の保護」「ネットワーク管理の簡素化」「クラウド移行が簡単に可能」といったメリットがあります。**
  >
  > 
  >
  > なお、「**エンドポイントサービス**」は[前述](https://qiita.com/c60evaporator/items/2f24d4796202e8b06a77#エンドポイント-vpcエンドポイント)の「**エンドポイント**」と**AWS内のサービス間でインターネットを経由しないセキュアな通信を提供**するという意味で共通しており、**まとめて"PrivateLink"と呼ばれる**事もあります。
  
  > ### トランジットゲートウェイ
  >
  > トランジットゲートウェイは、VPCピアリングと同様に**VPC同士を接続**できるサービスですが、VPCピアリングが2個のVPCを接続するケーブルの役割を果たすのに対して、トランジットゲートウェイは**3個以上のVPCを放射状に接続**する事ができます。
  >
  > [![VPCピアリングとトランジットゲートウェイ](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F610167%2Fe0126027-3133-1f24-eab6-ce02ec28b677.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&s=6be2871e53a3318774acc5ffad728ad8)](https://camo.qiitausercontent.com/663dfe6bee561fbfe594945ab9217251048822ea/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3631303136372f65303132363032372d333133332d316632342d656162362d6365303265633238623637372e706e67)
  >
  > **多数のVPC同士を接続**したい際に構成がシンプルになるのみならず、オンプレネットワークとの**VPN接続**([後述](https://qiita.com/c60evaporator/items/2f24d4796202e8b06a77#vpn-仮想プライベートネットワーク))を追加することもできます。
  >
  > 但し、**VPCピアリングよりも若干通信料金がお高め**のため、どちらを選択するかはコストと利便性のバランスを見て判断してください。
  >
  > トランジットゲートウェイにも異なるリージョン間のVPCを直接接続できない等の制約があります。詳細は以下の記事が参考になります。
  
  > ## VPN (仮想プライベートネットワーク)
  >
  > 仮想プライベートネットワークは、**VPCとオンプレネットワーク間に仮想的なプライベートネットワークを作成**するサービスです。
  >
  > VPNの通信路は実際にはインターネット内に作成されるのですが、[**トンネリング**](https://ja.wikipedia.org/wiki/トンネリング)と呼ばれる技術を用いる事によって、遠く離れた2点 (AWSの場合、VPCとオンプレネットワークそれぞれのゲートウェイ)をあたかも同一点であるかのように扱えます。
  > これにより**セキュアな通信路を確保**できるため、社内ネットワーク等によく利用されています。
  >
  > AWSでは、以下の2種類のVPNを使用できます。
  >
  > | 名称                 | オンプレ側のVPN接続地点                                      | トンネリングプロトコル | 料金 (リンク先に料金表)                                      |
  > | :------------------- | :----------------------------------------------------------- | :--------------------- | :----------------------------------------------------------- |
  > | **Site-to-Site VPN** | オンプレネットワーク上の**ルーター** (カスタマーゲートウェイ) | IPsec                  | [利用時間※＋通信量に応じ課金](https://docs.aws.amazon.com/ja_jp/vpn/latest/s2svpn/VPC_VPN.html#pricing) |
  > | **クライアントVPN**  | **クライアントPC**                                           | SSL-VPN                | [利用時間に応じ課金](https://docs.aws.amazon.com/ja_jp/vpn/latest/clientvpn-admin/what-is.html#what-is-pricing) |
  >
  > 
  >
  > ### ネットワークファイアウォール
  >
  > セキュリティグループはホワイトリスト形式のため「特定のターゲットをブロックしたい」といった用途で使用する事は出来ません。また、ブラックリスト形式のネットワークACLはステートレスなため、[前述のように](https://qiita.com/c60evaporator/items/2f24d4796202e8b06a77#ネットワークacl)設定が複雑となりミスを引き起こしやすいというデメリットが存在します。
  >
  > そこで、両者の欠点を補えるよう2020年に登場したサービスが、**ネットワークファイアウォール**です。
  > ネットワークファイアウォールは**ホワイトリスト・ブラックリスト両者**、かつ**ステートレス・ステートフル両者**を設定可能で、**柔軟なアクセス制御**を実現できます。
  >
  > また、ネットワークACLやセキュリティグループはVPC上に「ルール」を設定するだけで動作しましたが、ネットワークファイアウォールは以下のようにVPCのサブネット上に「**ファイアウォールエンドポイント**」という**オブジェクトを設置する必要**があります
  > （ファイアウォールエンドポイントはルートテーブル上では[Gateway Load Balancer エンドポイント](https://qiita.com/c60evaporator/items/2f24d4796202e8b06a77#エンドポイントサービス)として認識されます。またエンドポイントはAZごとに設置する必要があります）
  >
  > [![ネットワークファイアウォール](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F610167%2F950e77e5-e9d3-68e1-3866-ff1c9a79ce1d.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&s=35c0c9cbfcc8ec5c843ae55d4a867827)](https://camo.qiitausercontent.com/0a344d59acf4e5007a745527df81288520a377f0/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3631303136372f39353065373765352d653964332d363865312d333836362d6666316339613739636531642e706e67)
  >
  > 注意点として、ネットワークファイアウォール使用時は**ルートテーブルを編集**して、**インターネットとの通信が必ずファイアウォールエンドポイントを経由するよう設定**する必要があります。
  > 例えばWebアプリにおけるネットワークファイアウォールの設置方法や、WAF・サードパーティのファイアウォールとの使い分けに関しては、以下の公式ドキュメントで詳細に解説されています。
  >
  > ネットワークファイアウォールにより通信の流れを上記のような図で可視化する事ができるため、オンプレのネットワークに慣れている人には直感的に理解しやすい構成となります。一方でルートテーブル等の**設定すべき項目が複雑**となってしまう事や、**料金が高め**であること(かつAZごとに必要なため、冗長化するとさらに高額となる)がデメリットとなります。
  > よって比較的上級者向けのサービスと言え、**初心者はなるべくセキュリティグループを使用する事が望ましい**でしょう。
  >
  > ### Elastic IP
  >
  > 通常、VPC内部のインスタンスのグローバルIPアドレスは、[DHCP機能](https://qiita.com/c60evaporator/items/2f24d4796202e8b06a77#dhcp)により動的に付与されるため、インスタンスを停止 ⇨ 再起動するたびにIPアドレスが変わってしまいます。
  > このIPアドレスの変化を防ぐために**固定のグローバルIPアドレス**を割り振る機能が、Elastic IP (EIP)です。
  > Elastic IPにより、インスタンスを再起動しても同一のIPアドレスでアクセスできるようになります。
  >
  > Elastic IPは**稼働中のEC2インスタンスに付与した場合は無料**ですが、**休止中のEC2インスタンスに使用する場合やインスタンスと紐づいていない場合**は$0.005/hの**料金が掛かる**のでご注意ください。
  >
  > Elastic IPは、EC2インスタンス以外にもNATゲートウェイ、[Network Load Balancer(NLB)](https://dev.classmethod.jp/articles/elb-network-load-balancer-static-ip-adress/)でも用いる事ができ、この場合1つのElastic IPアドレスを複数のインスタンスやサービスで共有する事ができます。
  >
  > ## VPCとログ
  >
  > VPCには、内部のENI (EC2インスタンス, ELBなどに紐づけられたネットワークインターフェイス)に出入りする**IPトラフィックを記録**する**フローログ**と呼ばれる機能が存在します
  >
  > [公式ドキュメント](https://docs.aws.amazon.com/ja_jp/vpc/latest/userguide/flow-logs.html)では、フローログのユースケースとして以下が挙げられています
  >
  > - 制限が厳しすぎるセキュリティグループルールを診断する (想定外の通信拒否の有無を確認できる)
  > - インスタンスに到達するトラフィックをモニタリングする
  > - ネットワークインターフェイスに出入りするトラフィックの方向を特定する
  >
  > 以下で、実際に記録される内容と保存場所について解説します
  >
  > ### フローログの構造
  >
  > フローログは、以下のような構造となっています。　　
  >
  > ```
  > 2 123456789010 eni-1235b8ca123456789 172.31.16.139 172.31.16.21 20641 22 6 20 4249 1418530010 1418530070 ACCEPT OK
  > ```
  >
  > 上記だけでは分かりづらいですが、以下のようなフィールドから構成されています([公式ドキュメントでの解説](https://docs.aws.amazon.com/ja_jp/vpc/latest/userguide/flow-logs.html#flow-log-records))
  >
  > | フィールド名 | 上例での値            | 内容                                                         |
  > | :----------- | :-------------------- | :----------------------------------------------------------- |
  > | version      | 2                     | フローログのバージョン                                       |
  > | account-id   | 123456789010          | VPCが所属するAWSアカウントID                                 |
  > | interface-id | eni-1235b8ca123456789 | トラフィックが記録されるENIのID (送受信元のインスタンスやELB等と紐づく) |
  > | srcaddr      | 172.31.16.139         | 送信元のIPアドレス                                           |
  > | dstaddr      | 172.31.16.21          | 受信先のIPアドレス                                           |
  > | srcport      | 20641                 | 送信元ポート                                                 |
  > | dstport      | 22                    | 受信先ポート                                                 |
  > | protocol     | 6                     | トラフィックの[IANAプロトコル番号](https://www.iana.org/assignments/protocol-numbers/protocol-numbers.xhtml) |
  > | packets      | 20                    | フロー中に転送されたパケットの数                             |
  > | bytes        | 4249                  | フロー中に転送されたバイト数                                 |
  > | start        | 1418530010            | フローの最初のパケットが受信された時間 ([UNIX秒](https://ja.wikipedia.org/wiki/UNIX時間)) |
  > | end          | 1418530070            | フローの最後のパケットが受信された時間 ([UNIX秒](https://ja.wikipedia.org/wiki/UNIX時間)) |
  > | action       | ACCEPT                | トラフィックの許可状況 (ACCEPT: 承認、 REJECT: セキュリティグループやネットワークACL等により拒否) |
  > | log-status   | OK                    | ログのステータス (OK: データは選択された送信先に正常に記録、 NODATA: 集約間隔内に対象ENIへのトラフィックなし、 SKIPDATA: 集約間隔内に一部のフローログレコードがスキップ (内部的なキャパシティー制限、または内部エラーが原因の可能性あり)) |
  >
  > 例えば`action`フィールドから想定外のREJECTとなっているトラフィックがないかを確認することで、前述の「制限が厳しすぎるセキュリティグループルールの診断」を実施する事ができます。
  >
  > 見ての通り生のログを目視で確認するのは大変ですが、他の多くのログと同様に[CloudWatch Logs](https://aws.amazon.com/jp/premiumsupport/knowledge-center/cloudwatch-vpc-flow-logs/)で要約や各種検知を実施したり、[Amazon Athena](https://docs.aws.amazon.com/ja_jp/athena/latest/ug/vpc-flow-logs.html)を利用して分析すると効率よく活用できるかと思います。
  >
  > ### フローログの保存場所
  >
  > フローログの保存場所は、以下から選択する事ができます。
  >
  > - **CloudWatch Logs**
  > - **S3**
  >
  > [こちらのサイト](https://dev.classmethod.jp/articles/vpc-flow-logs-athena/)をみる限り、2つの保存場所は以下のように使い分けるとよさそうです。
  >
  > | フローログの保存場所 | 用途                                                         |
  > | :------------------- | :----------------------------------------------------------- |
  > | **CloudWatch Logs**  | ネットワークトラフィックの特定のアクセス傾向を検知してアラームを発する場合 |
  > | **S3**               | フローログを蓄積してAthenaで分析する場合                     |
  >
  > 具体的なフローログの取得方法は、以下の記事で解説します
  
- 各サービスがどこにあるかも認識しておくと良い。[こちら](https://qiita.com/saitotak/items/d2ede050e7a2224da46d)を参照。

  >[![Image](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F130874%2F1a6cf2b2-163b-1e3f-b80c-f8ac5aaf7517.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&s=10561710f4078ca66deb8bf06b1e85aa)](https://camo.qiitausercontent.com/13b44eb3456b0fbb0b139b4a58f1e9c5b417d75a/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f3133303837342f31613663663262322d313633622d316533662d623830632d6638616335616166373531372e706e67)



### EC2 Fleet

[こちら]([レポート] CMP201: より良く、より速く、より安く – Amazon EC2 Fleet によるコスト最適化コンピューティング #reinvent | DevelopersIO https://dev.classmethod.jp/articles/reinvent2018-cmp201/)を参照。

> 仮想マシンの EC2 を単一インスタンスの運用ではなく、複数からなるフリート(艦隊)として運用する手法です。
>
> 複数のインスタンスタイプやアベイラビリティゾーン(AZ)や購入オプションを組み合わせるとができるため、リソースな必要な分だけ確保され、AZを跨ぐため可用性が確保され、RIやスポットインスタンスの利用で価格メリットも出せます。



### クロスアカウントアクセス

[こちら]([AWS]クロスアカウント設定の外部IDについて簡単にまとめてみた https://storage.googleapis.com/zenn-user-upload/8708e350a547-20220115.png)や[こちら](超簡単！今すぐ使える「クロスアカウントアクセス」 | DevelopersIO https://dev.classmethod.jp/articles/signin-with-cross-account-access/)などがわかりやすいです。AssumeRoleによるRoleの引き渡しだけではRole名を推測されてしまうと乗っ取りのような被害にあってしまう可能性があるため、外部IDもあわせて認証認可情報とすることでセキュリティを高めることができます、ということのようです。



### API Gateway

- API Gatewayから呼び出されるLambdaの実行回数をなるべく減らしたい→API Gatewayでキャッシュを有効にする
  - キャッシュはGETリクエストにのみ有効



### ネットワーク

#### VPCで起動しているEC2に対してトラフィックを調査し、特にUser-Agent確認する必要がある場合

User-Agentなどのパケットの内容は**Flow Logsでは確認できない**。そのため、**VPCトラヒックミラーリング**を使用する。VPCトラヒックミラーリングの宛先はENIかNetwork Load Balancerを選択できる。CloudWatch Logsに送信することはできない。



#### IPv6が必要な場合

VPC新規作成時に設定することで使用できる。プライベートサブネットからはEgress-Onlyインターネットゲートウェイを使用することでアウトバウンド専用のネットワークを構築できる。Egress-OnlyインターネットゲートウェイはVPCにアタッチする。



#### ネットワークレイテンシの最小化

- クラスタプレイスメントグループ
  - EC2同士を同じAZの同じネットワークセグメントに配置されることでネットワークレイテンシを最小化する
- パーティションプレイスメントグループ
  - クラスタプレイスメントグループを更に特定のまとまりの単位でパーティションに分ける
  - **パーティション単位でラックがわかれるため対障害性が増す**
- スプレッドプレイスメントグループ
  - 同一AZのEC2を独自のネットワーク、電源がある異なるラックに納め、対障害性を高めることができる
  - ただし、**レイテンシ自体はクラスタプレイスメントグループの方が抑えられる**可能性がある

[こちら](https://qiita.com/mzmz__02/items/8651f578601f3a567fa0)参照。

![](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F642821%2F13495ea2-f259-c275-2806-527ddb65baf7.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=803d40e8f99be38c69b7c33477e58008)

- レイテンシの問題でVPNとDirectConnectが選択肢にある場合、VPNはネットワーク経路の影響を受けやすいので除外できる。複数リージョンのVPCに接続したい場合、Direct Connect Gatewayを使う。

#### Global Accelerator

[こちら](https://blog.yuu26.com/static-ip-hosting/)参照。

> AWSのグローバルネットワークを活用してパフォーマンスを改善できるサービスです。
> 固定IPアドレスが2つ割り当てられ、ALB・NLB・EIP・EC2をバックエンドとして指定できます。
> https://aws.amazon.com/jp/global-accelerator/
>
> IPエニーキャストにより**ユーザから近いAWSロケーションへトラフィックが吸収され、エンドポイントまではAWS内ネットワークを通るようになります。**AWS内はインターネットより低遅延のため、エンドポイントへ直接アクセスするよりもパフォーマンスが向上するという仕組みです。
>
> **「グローバル分散かつ固定IPのNLB」と考えれば分かりやすいかと思います**。ヘルスチェックや重み付けルーティングも出来るため、DR構成のフロントにも使えそうですね。



#### オンプレ→VPC

##### AWS Client VPN

[こちら](AWS Client VPNを分かりやすく解説してみる - サーバーワークスエンジニアブログ https://blog.serverworks.co.jp/tech/2019/06/10/awsclientvpn/)がわかりやすいです。ローカルからVPCにVPN張る際にはマネージドで最も簡単に環境構築できるってことです。

> AWS Client VPN のポイントを記載します。
>
> - VPC上に Client VPN Endpoint を作成することで、クライアント（普通のPCなど）とVPCの間でVPNを張ることができる
>
> - **OpenVPN** （オープンソースのVPNソフトウェア）を利用
>
> - 認証には 
>
>   Active Directoryによるアカウント管理, サーバ証明書・クライアント証明書による相互認証、その両方
>
>   を利用できる
>
>   - Active Directory認証では AWS Directory Serviceを利用。オンプレのADと連携したい場合は AD Connectorを噛ませることで可能



##### Site-to-Site VPN

[こちら]([AWS] Site to Site VPN の冗長化を考える | DevelopersIO https://dev.classmethod.jp/articles/redundancy-of-aws-site-to-site-vpn/)がわかりやすい。インターネット経由でIPSecを張る。Direct Connectのバックアップとして使われたりする模様。構築にはCustomer GatewayとVGW(Virtual private GateWay)もしくはTransit GateWayが必須。Client VPNと比べると構築がめんどい。



##### Direct Connect

[こちら](https://www.itechh.ne.jp/blog/column/column-aws-direct-connect.html)参照。

> 専用接続は、AWSとの物理接続となり、AWS ダイレクトコネクト用に1Gbpsもしくは10Gbpsのポートが提供され、これを丸ごと借りるタイプです。そのため、複数のVPCを利用する可能性の高いユーザーに向いています。ホスト型接続は、物理接続を論理的に分割し、複数のユーザーで共有するタイプです。単一のVPC利用の場合は、専用接続よりもコストを抑えることができるという特徴があります。ホスト型接続型の帯域は50M、100M、200M、300M、400M、500M、1G、2G、5G、10Gbpsの10種類から選べます。



[こちら](https://aws.typepad.com/sajp/2014/12/aws-direct-connect-public.html)に記載のとおり、Direct Connectは通信先によって2つに分かれます。

> 赤:AWSクラウドへの接続（パブリック接続）
>
> 青:VPC上のサブネットへの接続（プライベート接続）
>
> ![](https://aws.typepad.com/.a/6a00d8341c534853ef01b8d08ec219970c-500wi)



> Direct Connectには冗長性の度合いに応じてベストプラクティスがある。詳しくは[こちら](回復性に関する推奨事項 - AWS Direct Connect | AWS https://aws.amazon.com/jp/directconnect/resiliency-recommendation/)を参照。

物理回線のなかに論理回線も作ることが出来る。この論理回線をVIFと呼び、何と接続するかで、

- プライベートVIF
- パブリックVIF
- トランジットVIF

に分かれる。たくさんの拠点と接続したいならトランジットVIFだが、VPC間のルーティングはできない。VPC間ルーティングがしたいならTransit Gatewayを利用する必要がある。

[こちら](https://atbex.attokyo.co.jp/blog/detail/40/)が分かりやすい。

基本的にはDirect Connectサービスの障害に備え、VPNを別途用意する。プライベートVIFでの速度遅延とパブリックVIFのインターネット経由でのアクセスが発生することを許容する必要がある。[公式](https://aws.amazon.com/jp/directconnect/faqs/)を参照。

> **Q: 高可用性のために AWS Direct Connect への接続を発注するにはどうしたらよいですか?**
>
> ユースケースに最適な回復モデルを決定するには、「[AWS Direct Connect の回復性に関する推奨事項](https://aws.amazon.com/jp/directconnect/resiliency-recommendation/)」ページで説明されている、回復性に関するベストプラクティスに従うことをお勧めします。回復モデルを選択した後、[AWS Direct Connect 回復ツールキット](https://docs.aws.amazon.com/directconnect/latest/UserGuide/resiliency_toolkit.html)により、冗長的な接続を注文するプロセスがガイドされます。さらに AWS では、回復ツールキットのフェイルオーバーテスト機能を使用して、稼働前に設定をテストすることも奨励しています。 
>
> 専用の各 AWS Direct Connect 接続は、お客様のルーター上にあるポートと AWS Direct Connect デバイス間で、単一の専用接続として構成されています。冗長性が必要な場合は、2 番目の接続を確立することをお勧めします。同じ AWS Direct Connect ロケーションで複数のポートをリクエストすると、それらは冗長的な AWS 機器の上でプロビジョニングされます。 
>
> これとは違い、バックアップ IPsec VPN 接続を設定済みの場合は、すべての VPC トラフィックが自動的にその VPN 接続にフェイルオーバーされます。パブリックのリソース (例: Simple Storage Service (Amazon S3)) との間のトラフィックは、インターネットを介してルーティングされます。バックアップの AWS Direct Connect リンクまたは IPsec VPN リンクがない場合は、Amazon VPC のトラフィックは障害発生時にドロップされます。パブリックのリソースとの双方向のトラフィックは、インターネットを介してルーティングされます。



##### Direct Connect Gateway

- 「一貫した帯域幅」と「複数リージョンのVPC接続」に対応できる。

- Direct Connectのルーティングは[このあたり](https://blog.serverworks.co.jp/2021/04/05/100639#%E7%89%A9%E7%90%86%E6%8E%A5%E7%B6%9A%E3%81%A8%E8%AB%96%E7%90%86%E6%8E%A5%E7%B6%9A%E3%81%AE%E9%96%A2%E4%BF%82)も読んでおくと良いかも。

  > ## 物理接続
  >
  > とはいえ、オフィスからAWSが飛行経路（専用線）を提供しているわけではありません。
  >
  > ユーザがAWS Direct Connectに接続するためには、AWSがDXのデリバリーを認めた、AWSパートナーと契約するか、ユーザ所有のルータをDirect Connectロケーションに設置する必要があります。
  >
  > [パートナー - AWS Direct Connect | AWS](https://aws.amazon.com/jp/directconnect/partners/)![img](https://cdn-ak.f.st-hatena.com/images/fotolife/s/swx-yuki-kato/20210402/20210402134749.png)
  >
  > ### Direct Connect Location
  >
  > AWS Direct Connectロケーションは、ユーザが契約したキャリアとAWSが接続する場所であり、AWS Direct ConnectロケーションからAWS Cloud環境までを、AWS Direct Connectが接続します。
  >
  > 例えると…
  >
  > - AWS Direct Connectロケーション = 空港
  > - キャリアのルータ = 空港入り口
  > - AWSのルータ = 飛行機の乗り口
  >
  > ![img](https://cdn-ak.f.st-hatena.com/images/fotolife/s/swx-yuki-kato/20210402/20210402140225.png)こんな感じ。
  >
  > **Direct Connectの提供範囲は、AWS Direct ConnectロケーションからAWS Cloud環境まで**です！ユーザからDXまではAWSパートナーのキャリアさん宜しく！！という感じになっています。
  >
  > オフィスから空港までは、空港リムジンバスでも京急でも行き方はお任せするイメージですね。
  >
  > ## 論理接続
  >
  > > - 論理接続
  > >   - ネットワークの論理的な接続を表したもの。物理的な接続は意識せず、ネットワーク層(L3)を意識した接続。
  > > - 物理接続
  > >   - 主に物理層-データリンク層(L1-L2)の情報をもとにする接続。ネットワークの物理的な配線を表したもの。
  >
  > ### 物理接続と論理接続の関係
  >
  > Direct Connectロケーションの接続部分は、**Connection**と呼ばれる物理接続があります。この中に、複数の論理接続（仮想ローカルエリアネットワーク = **VLAN**）と仮想インターフェイス（Virtual Interface = **VIF**）があり、VIFでAWSとユーザのルータ間でのBGPピアリングを作ります。
  >
  > [20210209 AWS Black Belt Online Seminar AWS Direct Connect](https://image.slidesharecdn.com/20210209-aws-blackbelt-directconnect-210209094650/95/20210209-aws-black-belt-online-seminar-aws-direct-connect-24-1024.jpg?cb=1612864069)
  >
  > **BGPピアリング**
  > インターネットに接続する際、オンプレミスのルーターとAWSのルータはBGP(Border Gateway Protocol)により接続し、**ルート情報の交換を動的に**行います。
  >
  > > ※**BGP(Border Gateway Protocol)**
  > > ：ISPが形成する、固有のAS（Autonomous System (自律システム)）が、相互接続時にお互いの経路情報をやり取りするために使われる経路制御プロトコル
  > > ※**ISP（Internet Service Provider）**
  > > ：インターネット接続サービスを提供している事業者。上記物理接続の解説部分では、「キャリアと接続」と記載しましたが、このキャリアにあたるのがISPです。
  > > ※**AS（Autonomous System (自律システム)）**
  > > ：同じルーティング・ポリシーのもとで動作するルータの集合体のこと。ISPが固有で形成しており、世界中に存在する。
  >
  > 一般的に、ISPはBGPでお互いの経路情報を交換しています。交換することで、ISPと契約しているユーザとインターネット上での通信が可能になります。
  >
  > BGPピアリングによって、**AWSとユーザの経路情報を動的ルーティングで伝えあってくれるので、通信が出来る**という事です。
  >
  > ### Virtual Interface (VIF)
  >
  > **VIFとは**
  > AWS側の接続先のことを、Direct ConnectではVirtual Interfaceと呼びます。VLANのIDを持つインターフェースの事です。 このVIFによってユーザ環境とAWS環境（VPC）を接続（BGPピアを確立）しています。
  >
  > > 【VIF3種類】
  > >
  > > - プライベートVIF
  > >   VPCにプライベートIPを使って接続（DXを利用するタイプがAWS推奨） 最大10個のVPCと接続が可能。これにより、BGPピアリングのセッション数が減ります。
  > > - パブリックVIF
  > >   パブリックIPを使って接続。リージョン（中国を除く）を超えた接続が可能で、VPC外のAWSサービス（S3等）にオンプレから直接接続できる。（PrivateLinkのアップデートがあったため、S3に接続するためだけにパブリックVIFを使う必要はなくなりました）
  > > - トランジットVIF
  > >   Trangit Gateway用のDirect Connect Gatewayに接続 TrangitGatewayに接続されたVPCを相互に接続が可能 （深く言及しませんが、利用できない条件があるので確認が必要です）
  >
  > [AWS Direct Connect 仮想インターフェイス](https://docs.aws.amazon.com/ja_jp/directconnect/latest/UserGuide/WorkingWithVirtualInterfaces.html)
  >
  > **VLAN（論理接続）**
  > BGPピアリングは、物理接続の上に論理接続を確立しています。 この**論理的接続がVLAN、物理的な接続がConnection**です。
  >
  > ### VIFの使い方
  >
  > ![img](https://cdn-ak.f.st-hatena.com/images/fotolife/s/swx-yuki-kato/20210402/20210402134820.png)
  >
  > **占有型**
  >
  > - Connectionをマルっと自分のものにして、VLANは好きな用途で利用するタイプ
  > - 用途に応じて、１つのAWSアカウントでVIFを管理
  >
  > **共有型**
  >
  > - Connectionをキャリアが所有し、VIFをユーザに払い出して利用するタイプ
  > - キャリアが持つConnectionを様々なユーザで共有する使い方
  >
  > [20210209 AWS Black Belt Online Seminar AWS Direct Connect](https://image.slidesharecdn.com/20210209-aws-blackbelt-directconnect-210209094650/95/20210209-aws-black-belt-online-seminar-aws-direct-connect-50-1024.jpg?cb=1612864069)
  >
  > ## Direct Connect Gateway ( DXGW )
  >
  > ![img](https://cdn-ak.f.st-hatena.com/images/fotolife/s/swx-yuki-kato/20210402/20210402134845.png)
  >
  > ### DXGWとは
  >
  > 利用料は不要で、リージョンに属さないグローバルなサービスです。 DXGWは**１つのVIFに対して複数のVPCを利用する**！これが便利ポイントです。
  >
  > DXGWを利用する事で、VPCに作成したVGWをDXGWに関連付けるだけで利用する事が出来るようになります。すごい！![img](https://cdn-ak.f.st-hatena.com/images/fotolife/s/swx-yuki-kato/20210402/20210402135001.png)ただし、制約があります。 DXGWを介してVGWからVGWへの通信**（VPC同士の通信）は出来ません**。 もし通信を行いたい場合には、VPCピアリングやPrivateLinkの利用が必要になります。
  >
  > ### DXGWを利用しない場合
  >
  > ![img](https://cdn-ak.f.st-hatena.com/images/fotolife/s/swx-yuki-kato/20210402/20210402001446.png)VIFを関連付ける対象がVGWになります。
  > VIFとVGWは同一リージョンに1対1で設定するという制約があるため、別のVPCを利用するたびにVIFの申請が必要になります。追加でVIFを用意する必要があるので、コストと手間がかかります。VPC毎に通信を完全に分けたい場合は有効です。



##### Direct ConnectやVPNという文脈で登場する、Route53 Resolverについて

[こちら](https://qiita.com/rotekxyz/items/585635a5ccd806b651e7)を参照ください。要するに、オンプレ→VPCの名前入解決とVPC→オンプレの名前解決にRoute53 Resolverが使えるということ、だと思う。

> ## Route53 Resolverの使いどころ
>
> AWSのインスタンスなどから見た場合の`フルサービスリゾルバ`については、
> 特にオプション指定を外さない限り、VPCを作成したタイミングでできる`Amazon Provided DNS`を使う動きになっていますが、いわゆる外部からの接続DX(Direct Connect)やVPN接続を行なっている場合に重宝します。
> `Amazon Provided DNS`はVPC外からの参照が直接できないため、
> 今まではAWS上のPrivate Zoneを解決するにはBINDやUnbound等を用いてDNS forwarderを
> 作成する必要があったかと思いますが、これを作成しなくて済むのが大きなポイントです。
> 脆弱性対応や冗長の取り方を悩まなくて良いのもポイント。
>
> > Amazon Provided DNS
> > 10.1.0.0/16で立てた場合に10.1.0.2とかで作成されるもの
> > https://docs.aws.amazon.com/ja_jp/vpc/latest/userguide/VPC_DHCP_Options.html#AmazonDNS
>
> 以下はマネジメントコンソール上のRoute53 Resolverの説明の図
> 図では自身のオンプレ等の設備とVPCの間にDNS Endpointが設置され、
> 自設備からAWSへのInbound Traffic(図中の赤アンダーライン)、
> AWSから自設備へのOutbound Traffic(図中の青アンダーライン)についての図が書かれており、
> 2つ以上のEndpointが作成される事がわかる(図中の緑色枠)
> また、Outbound trafficでForwarder ruleを書けるのもポイントです(図中の黄色枠)。
> [![img](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F90309%2F664870c5-a02e-6407-03ad-2e85cbbeccef.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&s=6593f08b1e5c2ba92ee3b4b4f83cd26a)](https://camo.qiitausercontent.com/4acb107de3a7f1b4fbd96d93fe38fc46bc718768/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e616d617a6f6e6177732e636f6d2f302f39303330392f36363438373063352d613032652d363430372d303361642d3265383563626265636365662e706e67)

- PrivateLinkを通じてオンプレ-VPCから外部ネットワークに出ることなくS3にアクセスできる模様。
  - AWS Privatelink for S3 を利用してオンプレのDirectConnectからS3にアクセスできました - 協栄情報ブログ https://cloud5.jp/s3_interface_endpoint/



##### 冗長性について

###### 最大回復性

以下の図のように、1つのロケーションもしくはロケーション内部の物理障害があったとしても冗長構成を維持できる最もレベルの高い冗長構成。

![最大回復性](https://d1.awsstatic.com/AWS%20Direct%20Connect/Redundancy-Highest.cc18117d65de87b62bf4b8e10db7f980e3ac13fd.png)

他には以下のようなものがある。

- 1つのロケーションもしくはロケーション内部で障害があった場合に冗長化が失われる「高い回復性」
- ロケーションの障害があった場合に不通となる「開発ワークロード」



AWS側のVPCを多数接続する場合、Direct Connect GatewayやTransit Gatewayといった選択肢がある。これを使うことでVPC同士をPeering接続でメッシュ状に繋ぐ必要がなくなり、VPCの追加を用意にすることができる。[こちら](https://www.cloudsolution.tokai-com.co.jp/white-paper/2020/0427-99.html#anc-04-03)の絵がわかりやすい。

![](https://www.cloudsolution.tokai-com.co.jp/white-paper/2019/resource/0205-01-img-07.png)



[こちら](https://www.itechh.ne.jp/blog/column/direct-connect-redundancy-1.html)もわかりやすいので一読する。

> ### 1.高い回復性を持たせるケース：Direct Connectロケーションを冗長化
>
> アクティブ-アクティブ、アクティブ-スタンドバイ（待機）問わず、1つの接続に対して複数のDirect Connectロケーションを確保します。ちなみに、AWS定義のSLAで99.9%を満たすには、
>
> 1. Direct Connectロケーションを2つに分けること
> 2. エンタープライズサポート契約に加入すること
> 3. AWSのリソースをマルチAZ化として実装すること
>
> が求められます。
>
> ![Direct Connectロケーションを冗長化](https://www.itechh.ne.jp/blog/images/13_direct-connect-03.png)
>
> ### 2.最大の回復性を持たせるケース：各ロケーション内のDirect Connectを冗長化
>
> 最も高い可用性を持たせるケースでは、1.の条件に加え、Direct Connectロケーション内においても複数のDirect Connectを確保し冗長化します。AWS定義のSLAで99.99%を満たすには、1.の条件に加え、AWSによるアーキテクチャーレビューを受ける必要があります。
>
> ![各ロケーション内のDirect Connectを冗長化](https://www.itechh.ne.jp/blog/images/13_direct-connect-04.png)
>
> ### 3.開発環境やテスト環境など多少の停止が許容できるケース
>
> 開発環境やテスト環境など、多少の停止が許容されるケースであれば、メインの接続にDirect Connect を利用し、バックアップの回線にVPN接続を利用するパターンがあります。また、この構成ではAWS側の終端にAWS Transit Gatewayを利用して、よりシンプルなアーキテクチャにすることも可能です。
>
> ### 4. リージョン間接続を行う（Direct Connect GatewayとAWS Transit Gatewayを利用）
>
> AWSには、複数のAmazon Virtual Private Cloud（Amazon VPC）をまとめて接続することができるDirect Connect Gatewayというサービスと、複数のAmazon VPC や複数のオンプレミス拠点をハブのように束ねて接続することが可能なAWS Transit Gatewayを併用することで、各リージョン間をピアリングする構成が可能です。これを東京と大阪それぞれに準備することで通常時は東京リージョンAWS Transit Gatewayを利用し、万が一の迂回時は大阪リージョンAWS Transit Gatewayへの経路を利用する、またはその逆の構成で運用することが可能です。
>
> ![リージョン間接続を行う](https://www.itechh.ne.jp/blog/images/14_direct-connect-07.png)
>
> ### より高い可用性を求める場合にはマルチリージョン
>
> より高い可用性を求める場合は、マルチリージョンでのフェイルオーバーが実装可能です。
>
> ## 冗長化における主な考慮点
>
> ここまで、主な冗長化の方法とパターンを整理しましたが、実装の際に考慮すべき点があります。Direct Connectの観点では、大きく、障害発生時の挙動（障害発生時の経路制御や、非対称ルーティングなど）や、災対訓練、運用（Direct Connectのモニタリング）の考慮が必要になります。自社で回線を手配している場合には、自社データセンター側の運用や回線の運用も上記考慮の中に組み入れる必要があります。また、 AWSの構成全体として、Well-Architectedフレームワークに従ったレビューを実施して環境全体としての考慮点を洗いだす作業も推奨されています。



#### Transit Gateway

[こちら]()を参照。

> Transit Gateway は中央※ハブを介して、 VPC とオンプレミスネットワークを接続するクラウドルーターだと言われています。
> ネットワークが簡素化され、VPCの複雑なピアリング接続をしなくてよくなります。
>
> [![2020-06-25_14h28_52.png](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F543340%2Fbd9404cb-2b63-4f50-d897-b304cba3e92c.png?ixlib=rb-1.2.2&auto=format&gif-q=60&q=75&s=1eb4ff8d3c4a0e58ec251727d22fdd4f)](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F543340%2Fbd9404cb-2b63-4f50-d897-b304cba3e92c.png?ixlib=rb-1.2.2&auto=format&gif-q=60&q=75&s=1eb4ff8d3c4a0e58ec251727d22fdd4f)
>
> 中略
>
> ![](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F543340%2Fbd878bf4-dffd-37d3-9950-ac60eebe68dc.png?ixlib=rb-1.2.2&auto=format&gif-q=60&q=75&w=1400&fit=max&s=81b7125314e2bd03f68d1176d28c20ab)

組織に新たなユーザーが加わりAWSアカウントを持っている場合、Resource ManagerでTransit Gatewayを共有する。

参考)AWS Resource Access Managerを使用して、複数アカウントでAWS Transit Gatewayを共有して通信する方法 - サーバーワークスエンジニアブログ https://blog.serverworks.co.jp/ram-transit-gateway-routing

##### Transit Gateway ピアアタッチメント

別リージョンのTransit Gateway同士をつなぐもの

##### Enable Acceleration

Transit GatewayのVPN接続で**Enable Acceleration**を有効にすると、Global Acceleratorを使用したVPNネットワークの高速化になる。



#### Transfer Family

サービス概要は[こちら](https://qiita.com/sugimount-a/items/2d643d5435d5845cc815)を参考に。

> AWS Transfer Family は、AWS で提供されている SFTP, FTPS, FTP のプロトコルが使える安全なファイル転送のサービスです。転送先は、S3 と EFS を選べます。オンプレミスで FTP などを利用しているシステムがある場合、マネージドサービスとして AWS に管理負担を任せられます。



SFTPを使いたい場合は[こちら](https://dev.classmethod.jp/articles/aws-transfer-for-sftp-supports-vpc-security-groups-and-eip/)。AWS Transfer for SFTPでEIPおよびセキュリティグループがサポートされている模様。

![](https://cdn-ssl-devio-img.classmethod.jp/wp-content/uploads/2020/01/sftpeip01.png)



#### VPC Flow Logs

サービス概要は[公式]()参照。

> VPC フローログは、VPC のネットワークインターフェイスとの間で行き来する IP トラフィックに関する情報をキャプチャできるようにする機能です。フローログデータは Amazon CloudWatch Logs または Amazon S3 に発行できます。フローログを作成したら、選択した送信先でそのデータを取得して表示できます。
>
> フローログは、以下のような多くのタスクに役立ちます。
>
> - 制限の過度に厳しいセキュリティグループルールを診断する
> - インスタンスに到達するトラフィックをモニタリングする
> - ネットワークインターフェイスに出入りするトラフィックの方向を決定する
>
> フローログデータはネットワークトラフィックのパスの外で収集されるため、ネットワークのスループットやレイテンシーには影響しません。ネットワークパフォーマンスに影響を与えるリスクなしに、フローログを作成または削除できます。

注意点として、User-Agentなどのパケットの内容はVPC Flow Logsでは調査できず、VPCトラフィックミラーリングを使用する。トラフィックミラーリングの宛先はENIかNetwork Load Balancerを選択することが可能。

どんな情報が収集されるかは上述の公式ページを参照。IPの送信元・送信先でどのように情報が流れたか(はたまた流れなかったか)ということが分析できる(と思われる)。



#### IPv6

Egress-Only Internet Gateway というものがある。詳細は[こちら]()参照。NATゲートウェイはIPv4の世界でパブリックIPとプライベートIPを1対多で結びつけてくれるが、こちらはそれのIPv6版のようなイメージ(インバウンドはIPv4、アウトバウンドはIPv6)。

> ###  Egress-Only Internet Gateway とは
>
> IPv6を使用してインターネットに出たいときに使用するもの。
> しかし、IPv6はインターネットへのEgress(送信)のみでIngress(受信)はできません。
> NATゲートウェイのIPv6バージョンのようなもの



#### ENI

[こちら](https://business.ntt-east.co.jp/content/cloudsolution/column-14.html#:~:text=ENI%E3%81%AF%E3%80%81%E7%89%A9%E7%90%86%E7%9A%84%E3%81%AA,%E3%81%93%E3%81%A8%E3%81%8C%E3%81%A7%E3%81%8D%E3%81%BE%E3%81%97%E3%81%9F%E3%80%82)がわかりやすい。

> 物理的な環境であれば、ネットワークインターフェースを増加させるためには、サーバーに対してNICを挿す必要がありました。AWSの場合はENIに対して、IPアドレスの登録やMACアドレスの登録、セキュリティグループの登録など、必要な設定を行うことによりネットワークインターフェースを作成し、これを仮想インスタンスに取り付けたり、取り外したりすることをすべてWebブラウザ上で実現することができます。ただし、仮想インスタンスには、デフォルトのネットワークインターフェース（eth0）があらかじめ取り付けられています。このネットワークインターフェースは、取り外すことはできませんので注意が必要です。まずは、仮想インスタンスに対するネットワーク設定は、デフォルトのネットワークインターフェースに対して行い、さらにネットワークインターフェースを追加する必要がある場合は、ENIを追加していけばよいでしょう。
>
> ENIを追加して使う必要があるケースの代表的なものとしては、管理用ネットワークの作成が挙げられます。ユーザーからのアクセスは、デフォルトのネットワークインターフェースで受け付け、メンテナンス等の管理目的のアクセスは、ENIにより追加したネットワークインターフェースで管理者用パソコンからのアクセスのみを受け付けます。このように、ユーザーからのアクセスと管理者からのアクセスを明確に区別することで、セキュリティレベルを強化することができます。
>
> そのほかにも、ENIを使ってネットワークインターフェースを追加することで、ネットワークインターフェースの冗長化を実現することもあるでしょう。稼働系のネットワークインターフェースに障害が発生した場合、待機系のインターフェースに切り替わるプログラムコードを動かしておくこともできます。こうした仕組みを実現することで、障害発生時に、プライベートIPアドレス、Elastic IPアドレス、MACアドレスを待機系のネットワークインターフェースに引き継いで、ダウンタイムを最小化しながらサービスを継続することができます。
>
> ENIには、さまざまなネットワーク設定をすることができます。設定できる内容の詳細は以下の通りです。
>
> ##### プライベートIPv4アドレス（VPCのアドレス範囲内）の設定
>
> ##### 固定IPアドレス（Elastic IPアドレス）の設定
>
> ##### IPv6アドレスの設定
>
> ##### セキュリティグループの設定
>
> ##### MACアドレスの管理
>
> ##### ルーティング情報の設定
>
> 
>
> AWSの場合、ENIの利用により直接的に必要となる追加費用はありません。選択したインスタンスモデルに応じてネットワークインターフェースの数に制限はありますが、制限範囲内であれば追加費用を負担することなく、ENIを利用することができます。しかし、ENIを追加することに関連した費用負担が発生する可能性があるので注意しましょう。まず考慮するべきは、ネットワークトラフィックの増加です。ENIを追加するとネットワークインターフェースが追加されることになるため、一般的にはネットワークトラフィックが増加します。したがって、ENIを追加することで、AWSの利用料が増加する可能性が高いのです。
>
> そのほかにも、追加したネットワークインターフェースに、Elastic IPと呼ばれる固定グローバルIPアドレスを割り当てる場合は追加費用が発生することがあります。仮想インスタンスにつき1つのElastic IPを割り当てるのであれば無料ですが、2つ以上割り当てる場合は追加費用が発生しますので、注意しましょう。



ENIはEC2インスタンスの起動に関係なく、サブネットに作成しておくことが可能。AutoScaling時のライフサイクルフックイベントでスケールアウトを検知して新しく追加されたインスタンスにENIをアタッチするなどが可能。



### ELB

Elastic Load Balancer。[こちら](https://dev.classmethod.jp/articles/elb-explanation-try/)から以下の用語は覚えておくこと。

> ### ELBの用語
>
> - リスナー
>   - リスナーは設定したプロトコルとポートを使用して接続リクエストをチェックするプロセス。
>   - 最小1個のリスナーが必要になり、最大10個のリスナーまで設定できる。
> - ターゲットとターゲットグループ
>   - ターゲット：トラフィックを分散するところを言うこと。
>     - ターゲットはAmazon EC2 インスタンス、コンテナ、IP アドレス、Lambda 関数、仮想アプライアンスなどがある。
>   - ターゲットグループ：トラフィックを分散する複数のターゲットを含んでグループ化したこと。
> - ルール
>   - 定義したルールは、ロードバランサーが 1 つ以上のターゲットグループ内のターゲットにリクエストをルーティングする方法を決定する。
>   - 各ルールごと優先度·1 つ以上のアクション· 1 つ以上の条件で構成される。
>   - 各リスナーにはデフォルトのルールがあり、追加でルールを定義できる。
> - ヘルスチェック
>   - ターゲットとターゲットグループが問題なく起動できるように、定義された周期別にターゲットとターゲットグループの状態を確認する動作。





### DB

#### RDS

##### リードレプリカとは

> そもそもリードレプリカとは、読み込み専用として利用することができるマスターの複製データベースを指します。Amazon RDSでは、マスターのDBインスタンスのデータを非同期にレプリケーションする機能としてこのリードレプリカを提供しています。リードレプリカの場合、DBインスタンスに対して直接アクセスすることが可能です。
>
> 読み込みが多いアプリケーション等に有効ですが、非同期のため常にマスターと完全に内容が一致しているわけではなく、常に最新のデータが取得できるということはできません。しかし、マスターの読み取りにかかる負荷を軽減でき、これによりマスターのパフォーマンスが向上するため、マスターの負荷分散として多く利用されています。

#### Aurora

- リクエストによる接続拒否などが発生するときは、**RDS Proxyによりリクエストを調整**することができる

- Too Many Connectionsもよく知られる問題であるため知っておく必要がある。

  - Amazon Aurora MySQL インスタンスへの接続時に発生する「Too Many Connections」エラーを解決する https://aws.amazon.com/jp/premiumsupport/knowledge-center/aurora-mysql-max-connection-errors/

  - RDS Proxyを使うことも検討する。Proxyはデータベース接続プールの作成と再利用により、多くのリクエストを調整処理できる。

    - RDS Proxyと戯れた話【AWS】 - Qiita https://qiita.com/ttkn9a/items/2d325fc5e170721102d2

      > ざっくり言ってしまうと、RDSの前段に立ってコネクションをよしなにしてくれるマネージドのサービスです。

    - Secret Managerシークレットを作成してDBのユーザー名とパスワードを保存すること



##### RDSとAuroraの違い

[こちら](https://www.acrovision.jp/service/aws/?p=2462)を参照。

> AuroraとAuroraでないRDSの大きな違いは、『クラスタ』と『ストレージ』にあります。まずは、『クラスタ』についてです。Auroraはクラスタという単位で構成されています。クラスタとは、Auroraのデータベースを作成した際に作られるコンポーネント全体、つまりデータベースの管理単位と考えてください。次に『ストレージ』についてです。クラスタの要素は1つ以上のDBサーバーで構成されるインスタンス層とデータを管理するストレージ層の2層で成り立っています。つまり、SQL解析などの処理を行うインスタンスとデータを保存するストレージが分離しています。また、データを保管するストレージは、1AZあたり2箇所、3AZに渡り、合計6箇所にコピーされています。このような構成にすることで、仮にネットワーク障害、ディスク破損などの問題が起こっていたとしても、データベースの稼働に影響がないようにし、可用性の向上に貢献しています。
>
> ![](https://www.stylez.co.jp/wp-content/uploads/2022/06/img_62b969639b74d.png)

> Auroraは、主に下記のような特徴を持っており、AuroraでないRDSと比較して高性能になっています。
>
> - 豊富なオプション
>   従来のシングルマスター構成とは異なり、複数のプライマリDBを使用可能なマルチマスタークラスター、複数のAWSリージョンにまたがり高速でレプリケーションとフェイルオーバが可能になるグローバルデータベースといった、様々なオプションが用意されており、RDSよりも高可用性が実現できるオプションが用意されています。
> - 高速化の仕組み
>   プライマリインスタンスが持っているキャッシュを、他のインスタンスと共有することができるクラスタキャッシュという機能があります。これにより、障害でフェールオーバーが発生した先でもキャッシュを共有することができ、フェールオーバー先でも高速なデータベースの処理を継続することが可能です。
> - 選択できるデータベースエンジンが少ない
>   こちらは、AuroraでないRDSと比較と比較した場合のデメリットとなりますが、OracleやMicrosoft SQL Serverなどの一般的な商用データベースエンジンを使いたい場合はAuroraは使用できません。あくまでMySQLやPostgeSQL互換のデータベースエンジンとしてAuroraを利用することができます。
>
> ![img](https://www.stylez.co.jp/wp-content/uploads/2022/06/img_62b825f3a98d2.png)


##### Aurora Serverless

[こちら](https://service.plan-b.co.jp/blog/tech/28232/)参照。

> Aurora ServerlessとはAWSが提供するDBのサービスの1つです。AuroraというAWSが独自で開発したDBエンジンを搭載したサービスで、実務で発生するDBのメンテナンス作業や負荷に応じたDBインスタンスのスケーリング管理が不要なところが特徴的なサービスです。
>
> Aurora Serverlessに来たリクエストの量に合わせて、柔軟に性能をスケーリングすることができます。また、このときスケーリングした性能を表す単位をACU(Aurora capacity unit)といいます。
>
> Aurora Serverlessの料金は以下のように計算されます。
>
> **(ACUサイズ×起動時間)＋DBに対するリクエスト数+データ保存料金**



#### DynamoDB

以下の2つのモード(課金形態)がある。

- > ##### オンデマンドモード
  >
  > Amazon DynamoDB オンデマンドは、容量計画なしで 1 秒あたりに数千ものリクエストを処理できる柔軟な請求オプションです。DynamoDB オンデマンドには、読み取りおよび書き込みリクエストのリクエストごとの支払い料金が用意されているため、使用した分だけ課金されます。
  >
  > オンデマンドモードを選択すると、DynamoDB は、前に到達したトラフィックレベルまで拡張または縮小して、ワークロードを即座に受け入れることができるようにします。ワークロードのトラフィックレベルが新しいピークに達すると、DynamoDB はワークロードに対応するように迅速に対応します。オンデマンドモードを使用するテーブルは、同じ 1 桁ミリ秒のレイテンシー、サービスレベルアグリーメント (SLA) のコミットメント、DynamoDB が既に実現しているセキュリティを提供します。オンデマンドは、新しいテーブルと既存のテーブルの両方に選択できるだけでなく、コードを変更せずに既存の DynamoDB API を引き続き使用することができます。
  >
  > 以下の条件のいずれかに該当する場合、オンデマンドモードは適切なオプションです。
  >
  > - 不明なワークロードを含む新しいテーブルを作成する。
  > - アプリケーションのトラフィックが予測不可能です。
  > - わかりやすい従量課金制の支払いを希望する。
  >
  > ##### プロビジョニングモード
  >
  > プロビジョニングモードを選択した場合、アプリケーションに必要な 1 秒あたりの読み込みと書き込みの回数を指定します。Auto Scaling を使用すると、トラフィックの変更に応じて、テーブルのプロビジョンドキャパシティーを自動的に調整できます。これにより、コストの予測可能性を得るため、定義されたリクエストレート以下に維持されるように DynamoDB を制御することができます。
  >
  > 以下の条件のいずれかに該当する場合、プロビジョニングモードは適切なオプションです。
  >
  > - アプリケーションのトラフィックが予測可能である。
  >- トラフィックが一定した、または徐々に増加するアプリケーションを実行する。
  > - キャパシティーの要件を予測してコストを管理できる。
  
  詳細は[こちら](https://docs.aws.amazon.com/ja_jp/amazondynamodb/latest/developerguide/HowItWorks.ReadWriteCapacityMode.html)参照。
  
- オンデマンドモードにしたからといってスロットルがなくなるわけではない。

  - > Amazon DynamoDB オンデマンドは、キャパシティープラニングなしで 1 秒あたり数千のリクエストに対応できるフレキシブルなオプションです。DynamoDB オンデマンドでは、読み取りリクエストおよび書き込みリクエスト数に応じて料金が発生する従量課金となっているため、利用した分だけ料金をお支払いただく仕組みになっています。オンデマンドキャパシティーモードを使用する DynamoDB テーブルは、アプリケーションのトラフィック量に自動的に適応します。ただし、オンデマンドモードを使用するテーブルは、依然としてスロットルが発生する可能性があります。

    ※スロットル=スロットリングは[こちら](スロットリングとの付き合い方 | フューチャー技術ブログ https://future-architect.github.io/articles/20200121/)を参照。

    > 一定時間内に受信可能なリクエスト数を制限し、制限を上回るリクエストがなされた際には受信を拒否しエラーコードを返却すること。時間経過により再び受信可能となる仕組みです。
    >
    > リクエスト数を制限することでシステムにかかる負荷を抑えたり、スパムメールの送信を防止するのに利用されます。

- バックアップはオンデマンドバックアップというものがあり、AWS Backupの機能を使うと簡単にDailyなどでバックアップが取得可能。Restoreも簡単。詳しくは[こちら](https://dev.classmethod.jp/articles/aws-backup-dynamodb/)参照。

- **DynamoDB Global Tablesはリージョンレベルでのレプリカテーブルを作成する機能。アプリケーションがあるリージョンのレプリカテーブルにデータを書き込むと、DynamoDB は書き込みを他の AWSリージョンのレプリカテーブルに自動的に伝播する。**

  - ゲームなどで、各リージョンでのランキング表示と全世界のランキング表示を同時に見せたいような場合、DynamoDBテーブルストリームを有効にしてレプリケーションする。これによりマルチマスターとなるので、書き込みは各リージョンで可能となる。

- **DAX(DynamoDB Accelerator)を使用することで最大10倍のパフォーマンスが期待できる。また、DynamoDB APIとは互換性があるのでアプリケーションカスタマイズが最小限に抑えられる。**勘違いしていたが、そもそもモノが違うっぽい。[こちら](https://qiita.com/miyuki_samitani/items/ef2e3ce224162c37085e)を参照。



##### 大量のユーザーを認証し、データをログインユーザーに紐づくパーティションキーで保存する場合のベストプラクティス

エンドユーザーの認証はユーザープールで行い、DynamoDBへのAPIリクエストはIDプールで行う構成。集中しづらい値をパーティションキーにすることでDynamoDBのパフォーマンスのベストプラクティスが実現できる。

IAMユーザーを作成してARNをパーティションキーにすると、IAMユーザーの上限5,000とサインイン時にアクセスキー/シークレットアクセスキーが必要になり非現実的、IAMロールは上限が1,000で非現実的。

Cognito IDプールで認証されたユーザー向けにDynamoDBへの読み取り権限ポリシーをアタッチしたIAMロールを設定し、**ユーザープールで管理しているUUIDをパーティションキー**に設定するとよい。

※そもそもユーザープールとIDプールとは?

ユーザープールは認証を、IDプールは認可を行う。両方ともにCognitoで可能。ユーザープールで認証を行った後にユーザープールトークンとIDプールトークンを交換し、そのトークンを持って各種サービスのアクセスを制御する。

[参考](CognitoのユーザープールとIDプールの違いは？AWSの認証と認可を分かりやすく解説 | Ragate ブログ https://www.ragate.co.jp/blog/articles/112)



#### ElastiCache

[こちら](https://www.sunnycloud.jp/column/20210428-01/)参照。

> **・memcachedとは**
> memory cache daemon の略でメムキャッシュディーと読みます｡
> マルチスレッドで動作します。
> CPUのコア数を上げると、パフォーマンスも上がります。
> キーとバリューをシンプルな1対1で組み合わせて保存します。
>
> **・redisとは**
> シングルスレッドで動作します。
> snapshotベースでのバックアップ・リストアに対応しています。
> **マスターと複数のスレーブのクラスター構成により､負荷分散ができます。**
> クラスターモードについては、有効・無効を選ぶことができます。
> また､**メモリ上のデータをディスクに保存する事で､停電等の電源消失時にデータを失わずにすみます。**
>
> |                              | Memcached | Redis (クラスターモード無効) | Redis (クラスターモード有効) |
> | ---------------------------- | --------- | ---------------------------- | ---------------------------- |
> | データ型                     | シンプル  | 複雑                         | 複雑                         |
> | データのパーティション化     | はい      | いいえ                       | はい                         |
> | クラスターが変更可能         | はい      | はい                         | 3.2.10 以降                  |
> | オンラインリシャーディング   | いいえ    | いいえ                       | 3.2.10 以降                  |
> | Encryption                   | いいえ    | 3.2.6、4.0.10 以降           | 3.2.6、4.0.10 以降           |
> | コンプライアンス認定         | いいえ    | 3.2.6、4.0.10 以降           | 3.2.6、4.0.10 以降           |
> | マルチスレッド               | はい      | いいえ                       | いいえ                       |
> | ノードタイプのアップグレード | いいえ    | はい                         | はい                         |
> | エンジンのアップグレード     | はい      | はい                         | はい                         |
> | 高可用性 (レプリケーション)  | いいえ    | はい                         | はい                         |
> | 自動フェイルオーバー         | いいえ    | オプション                   | 必須                         |
> | パブリック/サブ機能          | いいえ    | はい                         | はい                         |
> | ソートされたセット           | いいえ    | はい                         | はい                         |
> | バックアップと復元           | いいえ    | はい                         | はい                         |
> | 地理空間インデックス作成     | いいえ    | 3.2.x 以降 – あり            | はい                         |



### ストレージ

まずは[このあたり](https://dev.classmethod.jp/articles/aws-summit-online-2020-day2-track2-1315-1345-aws-storage/)を見て全体像を押さえる。

> AWSのストレージサービスは複数ある
>
> ![https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2020/09/Untitled-1.png](https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2020/09/Untitled-1.png)
>
> ### データベースでのストレージ
>
> - データファイル、トランザクションログファイル、アーカイブなど様々な物がある
>   - ファイルの種類ごとに求められるI/O性能が異なるので、適切なストレージが必要
>
> ![https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2020/09/Untitled-2-1.png](https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2020/09/Untitled-2-1.png)
>
> - EBSはSSDのgp2/io1、HDDのst1/sc1がある
>   - 一部ではEC2インスタンスストアもある
> - ブロックストレージの選択はスライドのようなフローで選ぶと良い
>
> ![https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2020/09/Untitled-3-1.png](https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2020/09/Untitled-3-1.png)
>
> ### ファイルサーバー
>
> - 接続したいプロトコルによりサービスが異なる
>
> ![https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2020/09/Untitled-4-2.png](https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2020/09/Untitled-4-2.png)
>
> - EFS
>   - 複数AZで冗長化
>   - PBクラスの容量保持可能
>   - NFSでアクセスを提供
>
> ![https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2020/09/Untitled-5-2.png](https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2020/09/Untitled-5-2.png)
>
> - Amazon FSx for Windows File Server
>   - Windows ファイルサーバー完全マネージドサービス
>   - SMB
>   - 3PBまで拡張可能
>
> ![https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2020/09/Untitled-6-2.png](https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2020/09/Untitled-6-2.png)

#### S3

- S3バッチオペレーションとは

  - [こちら]()参照。

    > S3 バッチオペレーションは Amazon S3 のデータ管理機能です。Amazon S3 マネジメントコンソールからの数回クリックにより、または単一の API リクエストによって、数十億個ものオブジェクトを大規模に管理できます。この機能を使用して、オブジェクトメタデータとプロパティの変更や、その他のストレージ管理タスク (オブジェクトのバケット間でのコピーまたはレプリケート、オブジェクトタグセットの置き換え、アクセスコントロールの変更、S3 Glacier からのアーカイブオブジェクトの復元など) を実行できます。これらのタスクを実行するために数か月かけてカスタムアプリケーションを開発する必要はありません。

  - バッチオペレーションでは、以下のようなことが可能。

    - オブジェクトロックの保持設定
    - オブジェクトのコピー
    - Lambda関数の呼び出し

  - S3 RTC(Replication Time Control)を有効にすることで、ほとんどのオブジェクトは数秒でレプリケートされ、99.99%のオブジェクトは15分以内にレプリケートされる。15分の閾値を越えた場合と15分の閾値経過後にレプリケートされたオブジェクトのイベント通知を作成することができる。

- オブジェクトロックとは

  - [こちら]()参照。

    > 簡単に説明しますと、S3のオブジェクトロックとは、S3内にある対象のオブジェクトが絶対に削除されないようにするための保護機能となります。ロックする期間を設定することができます。

  - バッチオペレーションによるオブジェクトロックの保持とは

    - [こちら](https://aws.amazon.com/jp/blogs/news/how-to-manage-retention-periods-in-bulk-using-amazon-s3-batch-operations/)参照。

      > バケット内の多数のオブジェクトに S3 オブジェクトロック設定を適用、更新、または削除する必要がある場合は、S3 オブジェクトロック向け S3 バッチオペレーションサポートの使用をご検討ください。S3 オブジェクトロックを初めて使用する場合、S3 オブジェクトロック向け S3 バッチオペレーションのサポートを使えば、これらの変更を簡単に行えます。既存の S3 オブジェクトロック要件が変更され、多数のオブジェクトのロックを更新、追加、または削除する必要がある場合にも当てはまります。オブジェクトがバケットに追加されたときに、S3 オブジェクトロックポリシーをオブジェクトに自動的に割り当てることができます。これを行うには、そのバケットにデフォルトの保存モードを設定します。S3 バッチオペレーションを使用する必要はありません。



#### TimeStream

[こちら](時系列データの保存先をDynamoDBからTimestreamへ移行すべきか検討してみる | DevelopersIO https://dev.classmethod.jp/articles/comparison-dynamodb-and-timestream/)を参照。

> ## Timestreamの概要についておさらい
>
> DynamoDBとTimestreamを比較する前にTimestreamがどういうサービスなのか概要をおさらいしておきましょう。
>
> ### ディメンションとメジャー
>
> Timestreamと他のデータベースを比較したときに、特徴的なのがレコードの形式です。Timestreamにおける1レコードは以下の要素で構成されます。
>
> - ディメンション
>   - 時系列データのメタデータです。例えばIoTデバイスのデバイスIDなどがディメンションに相当します。
> - メジャー
>   - 時系列データの計測値です。例えばIoTデバイスが計測した温度やCPU使用率などはメジャーに相当します。メジャーはさらに名前と値から構成されます。
> - タイムスタンプ
>   - メジャーが計測された時のタイムスタンプです。時系列データベースであるTimestreamでは、各レコードは必ずタイムスタンプを持ちます。
>
> 例えばデバイスごとに時系列のCPU使用率と温度を収集するとします。RDBやDynamoDBだとデータの格納イメージは以下のようになります。
>
> | device_id     | time                          | cpu   | temperature |
> | ------------- | ----------------------------- | ----- | ----------- |
> | test-device-1 | 2020-12-19 12:00:00.000000000 | 50.00 | 10.1        |
>
> それに対してTimestreamは以下のような形式でデータを格納します。
>
> | device_id(ディメンション) | time(タイムスタンプ)          | measure_name(メジャー) | measure_value::double(メジャー) |
> | ------------------------- | ----------------------------- | ---------------------- | ------------------------------- |
> | test-device-1             | 2020-12-19 12:00:00.000000000 | cpu                    | 50.00                           |
> | test-device-1             | 2020-12-19 12:00:00.000000000 | temperature            | 10.1                            |
>
> 計測対象が増えた場合にカラムやアトリビュートが横に増えていくのか、レコードが縦に増えていくのかという違いがあります。
>
> ### ストレージ
>
> Timestreamはメモリストアとマグネティックストアという2種類のストレージを持ちます。それぞれ以下のような役割を持ちます。
>
> - メモリストア
>   - 新しいデータを保存するためのストレージ
>   - ある時点のデータを高速に抽出するようなクエリに最適化されている
> - マグネティックストア
>   - データを長期間保存するためのストレージ
>   - 分析クエリをサポートするように最適化されている
>
> 各ストレージにはデータの保持期間が設定でき、設定したデータ保持期間とレコードのタイムスタンプに応じてレコードの保存先がメモリストア　→　マグネティックストアと遷移し、マグネティックストアのデータ保持期間を超過したレコードは削除されます。
>
> 現在はメモリストアとマグネティックストアの2種類でストレージが構成されていますが、将来的にはこの2つの中間に位置するSSDストアの追加が予定されています。
>
> ### クエリ
>
> TimestreamではSQLを利用してデータをクエリできます。SQLのサポートも手厚く
>
> - JOIN(~~現状SELF JOINのみ対応~~ ※別テーブルとのJOINも可能になりました[【アップデート】Timestremで複数テーブルのJOINや高度な時系列関数が利用可能になりました](https://dev.classmethod.jp/articles/timestream-support-cross-table-queries-and-so-on/))
> - サブクエリ
> - CASE文
> - WITH句
> - 集約関数
> - Window関数
> - 時系列関数
>
> などなど様々な機能が利用できます。
>
> これがIoT AnalyticsだとJOINやWITH句が使えないためSQLが使えるという魅力が薄れてしまうのですが、TimestreamではSQLをフル活用した分析が可能です。
>
> ## DynamoDBとTimestreamの機能比較
>
> ここからDynamoDBとTimestreamそれぞれの機能について比較していきます。それぞれのメリット/デメリットと自身のユースケースを検討した上で最終的に判断頂ければと思います。
>
> 以後の内容は2020年12月時点のサービス仕様に基づいています。今後のアップデートにより仕様が変わる可能性があることにご注意下さい。なお、DynamoDBに関してはオンデマンドモードを前提とした比較になります。
>
> ### 共通点
>
> まずは共通点から見ていきましょう。DynamoDBとTimestreamに共通するメリットは以下のような項目が挙げられます。
>
> - 従量課金
>   - 後ほど料金の比較も行いますが、両サービスとも従量課金が原則です。RDSのようにインスタンスを上げているだけで課金されてるということはありません。
> - 自動スケール
>   - 両サービスともインスタンス管理の概念がありません。負荷に応じてクラスターにインスタンスを追加したり、インスタンスサイズを変更したりといった煩わしい管理作業は不要です。サービス基盤側で自動的にスケールしてくれるようになっています。
> - 自動バージョンアップ
>   - サービスのバージョンアップやパッチ適用も全て基盤側にお任せです。RDSのようにメンテナンスウインドウを定義して...といった管理は不要です。
> - スキーマレス
>   - データベースのスキーマを事前にカッチリ決めておく必要はありません。DynamoDBであればアトリビュート、Timestreamであればメジャーとディメンションに自由に項目追加が可能です。RDBのようにALTER文を流して列追加する必要はありません。
> - VPC不要
>   - 両サービスともVPC不要のサービスです。Lambdaからも利用しやすいです。
> - TTLによるデータの自動削除
>   - 両サービスともTTLの概念があり、時系列データを自動的に削除可能です
>
> これらのメリットに魅力を感じてDynamoDBを利用している方はTimestream移行後も同様のメリットが享受できます。
>
> ### Timestreamの方が強い点
>
> ここからはDynamoDBと比較したTimestreamの優位性として、以下のような項目が上げられます。
>
> - 集計処理
>   - さきほどご紹介したようにTimestreamではSQLが利用できます。デバイスごとに平均CPU使用率を求めたいといった要件にも集約関数を利用することで簡単に対応可能です。DynamoDBだとトランザクションやDynamoDBストリームと連携して集計用のテーブルをメンテナンスするか、クエリで取得したアイテムをアプリケーション側で集計する必要があります。
> - 柔軟な検索
>   - Timestreamではタイムスタンプ、ディメンション、メジャーを指定した柔軟な検索が可能です。サブクエリも利用できるので集計処理の結果によってデータを抽出するといった検索要件にも簡単に対応可能です。DynamoDBでクエリを実行するためにはインデックスが必須になりますし、インデックスを用いたクエリもTimestreamほどの柔軟性はありません。
> - 時系列処理
>   - Timestreamは時系列処理に特化したデータベースなので、当然時系列処理に強みを持ちます。例えば欠損値を保管したり指定した時間間隔で集計結果を丸めるといったことが可能です。例えばデバイスから1分に1回温度情報が送信されてくるとします。この送信されてきた温度情報を1時間ごとの平均値に集計する場合、DynamoDBではどのような実装になるでしょうか？アプリケーション側に集計ロジックを実装する必要があります。これがTimestreamであれば時系列関数を利用するだけで簡単に1時間ごとの平均値に丸めることができます。
>
> ### Timestreamの方が弱い点
>
> さきほどと逆にDynamoDBにできてTimestreamにできないことを見ていきましょう
>
> - レコードの削除
>
>   - Timestreamでは手動のレコード削除が行えません。レコードが削除されるのはデータ保持期間経過後の自動削除のみです。
>
> - バックアップ/リストア
>
>   - Timestreamはテーブルやデータベースのバックアップ/リストア機能を持ちません。データのバックアップが欲しければクエリの実行結果をチマチマとファイルに出力するような対応が必要です。
>
> - エクスポート
>
>   - バックアップとも似ていますが、テーブルの中身をS3にエクスポートするといったこともできません。
>
> - 過去データの投入
>
>   - Timestreamではメモリストアに設定されたデータ保持期間を経過しているレコードは登録することができません。メモリストアに設定可能な最長のデータ保持期間は1年なので、1年以上前のタイムスタンプが設定されたデータはTimestreamには登録不可能ということになります。
>
> - トランザクションが無い
>
>   - DynamoDBで利用できるTransactWriteのような概念はありません。レコードを書き込む際に、一部の書き込みのみ失敗するということも起こりえます。
>
> - データ型が少ない
>
>   - Timestreamで扱えるデータ型はスカラー値のみで、対応しているデータ型は以下の4種類です。
>     - BIGINT
>     - BOOLEAN
>     - DOUBLE
>     - VARCHAR
>
>   DynamoDBのMap、Listのようなドキュメント型やセット型には対応していません。
>
> - 東京リージョンで利用不可
>
>   - 機能的なデメリットではないのですが、Timestreamは東京リージョンでは利用できません。東京リージョンのLambdaからバージニアリージョンのTimestreamにクエリするといった構成も可能ですが、リージョン跨ぎによるレイテンシーとデータ転送料金が懸念となります。
>
> DynamoDBというサービスは歴史が長く、ここで挙げたような基本的な機能以外にもグローバルデータベースやDAXのように特定のユースケースで利用できる様々な機能を持っています。連携可能な別AWSサービスも豊富です。このあたりはDynamoDBに対するTimestreamの明確なディスアドバンテージと言えるでしょう。

#### EBS

- 暗号化する際は作成時に暗号化オプションを有効にする必要がある。使用中のEBSを暗号化する場合はスナップショットを作成し、スナップショットをもとに新規ボリュームを作成するときに暗号化を有効にする。

- バックアップはDLM(Data Lifecycle Manager)を使って簡単に取得できる。詳しくは[こちら](https://dev.classmethod.jp/articles/ec2-snapshot-by-amazon-dlm/)参照。

  > [Amazon DLM](https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/snapshot-lifecycle.html) とは、Amazon EBS ボリュームをバックアップする為のSnapshotの生成 → 保存 → 削除のライフサイクルを自動化して、以下のようなメリットがあるサービスです。
  >
  > - 定期的なバックアップスケジュールを実施して貴重なデータを保護する。
  > - 監査担当者または社内のコンプライアンスが必要とするバックアップを保持する。
  > - 古いバックアップを削除してストレージコストを削減する。



#### Gracier

- Deep Archiveは取り出しに最大12時間要する。



#### ストレージゲートウェイ

オンプレ→AWSにバックアップを取得する際などに利用する。[公式]()参照。

> [Simple Storage Service (Amazon S3) ファイルゲートウェイ](https://aws.amazon.com/jp/storagegateway/file/s3/)を利用すると、Network File System (NFS) や Server Message Block (SMB) などのファイルプロトコルを使用して、Amazon Simple Storage Service (S3) でオブジェクトの保存と取得を実行できます。S3 ファイルゲートウェイを通して書き込まれたオブジェクトには、S3 で直接アクセスできます。
>
> [Amazon FSx ファイルゲートウェイを](https://aws.amazon.com/jp/storagegateway/file/fsx/)使用すると、SMB プロトコルを使用して Amazon FSx for Windows ファイルサーバーでファイルを保存および取得できます。Amazon FSx ファイルゲートウェイを介して書き込まれたファイルは、Amazon FSx for Windows ファイルサーバーから直接アクセスできます。
>
> [ボリュームゲートウェイ](https://aws.amazon.com/jp/storagegateway/volume/)は、iSCSI 接続を使用してオンプレミスアプリケーションにブロックストレージを提供します。ボリューム上のデータは Simple Storage Service (Amazon S3) に保存されます。特定時点のボリュームを複製し、Amazon EBS スナップショットとして AWS に保存することが可能です。ボリュームのコピーを取得して、その保持期間を AWS Backup で管理することもできます。EBS スナップショットは、ボリュームゲートウェイや EBS ボリュームにリストアできます。
>
> [Tape Gateway](https://aws.amazon.com/jp/storagegateway/vtl/) は、仮想メディアチェンジャー、仮想テープドライブ、および仮想テープから構成される、iSCSI 仮想テープライブラリ (VTL) インターフェイスを使用したバックアップアプリケーションを提供します。仮想テープは Amazon S3 に保存されます。Amazon S3 Glacier や Amazon S3 Glacier Deep Archive にアーカイブすることもできます。

> ボリュームゲートウェイでは、オンプレミスのアプリケーションサーバーや EC2 のアプリケーションサーバーから iSCSI デバイスとしてブロックストレージボリュームの作成とマウントを実行できる iSCSI ターゲットを利用できます。ボリュームゲートウェイは、キャッシュ型モードと保管型モードのいずれかで動作します。
>
> - キャッシュ型モードでは、プライマリデータは S3 に書き込まれます。頻繁にアクセスするデータはキャッシュでローカルに保持され、低レイテンシーでのアクセスを実現できます。
> - 保管型モードでは、プライマリデータはローカルに保存されてデータセット全体が低レイテンシーのアクセスのために使用可能となり、非同期に AWS にバックアップされます。



#### バックアップ

[こちら](https://dev.classmethod.jp/articles/ec2-snapshot-by-amazon-dlm/)参照。

> ## 一般的なEC2のバックアップ方法
>
> EC2 インスタンスをバックアップする方法は大きく二つの方式があります。
>
> 1. AMI作成
> 2. Snapshot作成
>
> AMI作成の場合はインスタンスのメタデータおよびOSがインストールされたそのままのイメージ（一個以上のスナップショット + メタデータ）を作ります。 Snapshot作成の場合はインスタンスに付いているEBSボリュームのスナップショットが作成されます。
>
> AMIバックアップのユースケースを一部だけ並べてみると以下のようになります。
>
> - バックアップされたインスタンスを緊急復元したい
> - インスタンス設定等が複雑で、設定が完了されたインスタンスのイメージを作りたい
> - ASG(Auto Scaling Group)から新たなインスタンスを自動生成したい
>
> Snapshotバックアップのユースケースは以下のようになります。
>
> - OSとは別にデータのみバックアップしたい
> - 作成されたスナップショットを基づき、様々なAMIを作成したい
> - Amazon DLMを活用して周期的なバックアップを有効化して、更にストレージコストを最適化したい （古いスナップショットは自動削除、それに同じブリューむについてのスナップショットは変更された部分のみ追加）
>
> 本記事は最後のAmazon DLM（Data Lifecycle Manager)に該当するバックアップ方式です。
>
> ## Amazon DLM とは
>
> [Amazon DLM](https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/snapshot-lifecycle.html) とは、Amazon EBS ボリュームをバックアップする為のSnapshotの生成 → 保存 → 削除のライフサイクルを自動化して、以下のようなメリットがあるサービスです。
>
> - 定期的なバックアップスケジュールを実施して貴重なデータを保護する。
> - 監査担当者または社内のコンプライアンスが必要とするバックアップを保持する。
> - 古いバックアップを削除してストレージコストを削減する。
>
> 私は物事を理解する時にテキストを読むだけではなく、実際に操作して覚えたいので、DLMでスナップショットを作成してみます。:D



### IAM

IAMでhアクセス制御のための「ポリシー」という考え方がある。ポリシーは以下の3つに大別される。

1. ユーザーベースのポリシー
2. リソースベースのポリシー
3. IAMロールの信頼ポリシー

詳細は[こちら](IAM https://dev.classmethod.jp/articles/aws-iam-policy/)の記事がとてもわかり易い。[こちらのYoutube](https://www.youtube.com/watch?v=sOTOIbTMxds)もわかりやすいので一度参照いただくとよい。

[Black Beltの動画](https://www.youtube.com/watch?v=K7F5yTThynw)も余裕があれば見てください。

> ![スクリーンショット 2022-12-15 18.25.47](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-15 18.25.47.png)



#### 信頼ポリシー

[ここ](https://dev.classmethod.jp/articles/announcing-an-update-to-iam-role-trust-policy-behavior/)を参照。

> IAM ロールには以下 2 種類のポリシーをアタッチできます。 [*2](https://dev.classmethod.jp/articles/announcing-an-update-to-iam-role-trust-policy-behavior/#note-947959-2)
>
> - 信頼ポリシー
>
>   - 誰がその IAM ロールを引き受けられるかを定義
>
> - IAM ポリシー
>
>   （アイデンティティベースポリシー）
>
>   - その IAM ロールを引き受けたセッションが何をできるかを定義
>
> ![img](https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2022/09/STS-AssumeRole.png)
>
> IAM ロールを引き受ける（**Assume Role**）ことで、一定時間そのロールが持つ権限を利用できます。具体的には以下のステップからなります。
>
> 1. IAM ユーザーなどのプリンシパルが、引き受けたい IAM ロールを指定して`sts:AssumeRole`を実行する
> 2. `sts:AssumeRole`により払い出された一時的なクレデンシャルをセットする [*3](https://dev.classmethod.jp/articles/announcing-an-update-to-iam-role-trust-policy-behavior/#note-947959-3)
>
> ステップ 1 が成功するためには、実行元のプリンシパルが IAM ロールの**信頼ポリシー**で許可されている必要があります。例では IAM ロールを引き受けるプリンシパルとして IAM ユーザーを挙げましたが、他にもプリンシパルは存在します。



#### スイッチロール

スイッチロールまわりは出題されやすい。[こちら](https://business.ntt-east.co.jp/content/cloudsolution/column-try-25.html#section-02)を参考に。

> ### 2.スイッチロールとは？
>
> ロールの機能のひとつで、他アカウントからのログインを許可するロールのこと。
> 付与するポリシーによってさまざまな権限を与えることができます。
> （管理者権限であったり、EC2限定の閲覧権限であったり）
>
> ### 3.スイッチロールのない世界
>
> 複数アカウントを管理している場合、アカウント間を移動する際にログイン・ログアウトを繰り返していると非常に手間がかかりますよね？
>
> ![img](https://business.ntt-east.co.jp/content/cloudsolution/images/column/img_column-try25_02.png)
>
> 上図より開発アカウントからテストアカウントに移動する場合の作業。
> ①開発アカウントからログアウト
> ②テストアカウント用のアカウントID、ユーザ名、パスワードを入力してログイン
>
> これを毎回「アカウントIDは～、ユーザ名は～」と資料から探してログインするのは意外と時間がかかります。
> また管理するアカウントが増えると結構な重労働になります。
>
> 特に目が疲れてくる夕方以降は12桁のアカウントIDを確認するのは辛いですよね。
>
> ### 4.スイッチロールのある世界
>
> そんな上記の課題を解決してくれるのがこのスイッチロールになります。
>
> ![img](https://business.ntt-east.co.jp/content/cloudsolution/images/column/img_column-try25_03.png)
>
> 上図より開発アカウントからテストアカウントに移動する場合の作業。
> ①開発アカウントにてテストアカウント向けのスイッチロールをクリック
>
> これだけで移動が完了します。
>
> 設定すれば2クリックで異なるアカウントに移動できます！！すごくないですか？
> キーボードを使うことなく、マウス操作で移動できるため目にも優しいですよね。
>
> ### 5.どうやってスイッチロールするの？
>
> スイッチロールの設定方法は以下の手順で行います。
>
> - スイッチロール先（ログインされる側）で許可設定を行います。（6の作業）
> - スイッチロール元（ログインする側）でスイッチロールを行います。（7の作業）
> - スイッチロールの確認を行います。（8の作業）
>
> ![img](https://business.ntt-east.co.jp/content/cloudsolution/images/column/img_column-try25_04.png)
>
> やっとではありますが設定作業に入ります。



#### Active Directory

[こちら](AWS再入門ブログリレー2022 AWS Directory Service編 | DevelopersIO https://dev.classmethod.jp/articles/re-introduction-2022-directory-service/)が参考になる。

①Managed Microsoft AD、②SimpleAD、③AD Connectorのサービス概要は覚えておく必要あり。

①はMicrosoft ADをAWS管理化に置いたもの。オンプレのADを運用している場合、同一ドメインとして管理はできないが、信頼関係を結ぶことにより双方のリソースを利用することが可能。

②はMicrosoft ADとは別物のディレクトリサービス。一通りの機能を使うことはできるけど、オンプレのMicrosoft ADなどとあわせて使うことは考えられていない。③はADへのプロキシのような感じで、③自体はディレクトリサービスを持たない。



### コンテナ

#### ネットワーク

- none, host, bridge, awsvpcがある。詳しくは[こちら](https://blog.serverworks.co.jp/tech/2020/06/08/post-86015/)を参照。
- Fargateで設定できるネットワークモードはawsvpcのみ。
- ECSでもawsvpcを推奨しているようだが、全て選択可能。



#### EMR(Elastic Map Reduce)

マネージドな分散処理基盤、と理解してる。

マスターノード、コアノード、タスクノードで構成され、[公式](https://docs.aws.amazon.com/ja_jp/emr/latest/ManagementGuide/emr-overview.html)には以下のように書かれている。

> Amazon EMR の中心的なコンポーネントは、*クラスター*です。クラスターは、Amazon Elastic Compute Cloud (Amazon EC2) インスタンスの集合です。クラスター内の各インスタンスは、*ノード*と呼ばれます。各ノードには、クラスター内にロールがあり、*ノードタイプ*と呼ばれます。また、Amazon EMR は、各ノードタイプにさまざまなソフトウェアコンポーネントをインストールし、Apache Hadoop などの分散型アプリケーションでのロールを各ノードに付与します。
>
> Amazon EMR のノードタイプは、次のとおりです。
>
> - **マスターノード**: ソフトウェアコンポーネントを実行して処理対象の他のノード間でのデータおよびタスクの分散を調整することにより、クラスターを管理するノード。マスターノードは、タスクのステータスを追跡し、クラスターの状態を監視します。すべてのクラスターにはマスターノードがあり、マスターノードのみで 1 つのノードクラスターを作成することができます。
> - **コアノード**: タスクを実行してクラスターの Hadoop Distributed File System (HDFS) にデータを保存するソフトウェアコンポーネントを含むノード。マルチノードクラスターには、少なくとも 1 つのコアノードがあります。
> - **タスクノード**: タスクを実行するだけで、HDFS にデータを保存しないソフトウェアコンポーネントを含むノード。タスクノードはオプションです。
>
> 次の図に、マスターノード 1 つとコアノード 4 つが存在するクラスターを示します。
>
> ![ 					EMR クラスター内のマスターノードとコアノードの関係を示す Amazon EMR のクラスター図。 				](https://docs.aws.amazon.com/ja_jp/emr/latest/ManagementGuide/images/cluster-node-types.png)



大量のEC2インスタンスを使うため、以下のようなコストの節約を考える必要がある。[こちら](https://developers.cyberagent.co.jp/blog/archives/19150/)参照。マスタノードとコアノードは中断されては困るのでオンデマンドインスタンスで、タスクノードは別に中断されても良いのでスポットインスタンスで、という戦略が良い感じ。

> ## EMRでのスポットインスタンス
>
> AWSではスポットインスタンスという仕組みがあり、オンデマンドでの起動に備えて待機しているインスタンスを格安で利用することができます。待機しているインスタンスを借りるだけなので、オンデマンドインスタンスと違ってオンデマンドインスタンスとして割り当てられた等の理由で突然シャットダウンされる可能性があります(シャットダウンされる場合は2分前に通知を受け取ることもできます)。
> https://docs.aws.amazon.com/ja_jp/AWSEC2/latest/UserGuide/using-spot-instances.html
>
> 常時稼働していないといけない用途には向きませんが、障害耐性のある環境であればこれを許容する代わりに大幅なコスト削減が見込めるというわけです。Apache SparkはRDD(Resilient Distributed Dataset)という障害耐性のあるデータモデルを採用していて、**クラスタの一部のメンバーに障害が発生してもそれを検知して処理が継続できるようになっているので何かしらの理由で一部のスポットインスタンスが終了しても問題ありませんし、Amazon EMRはスポットインスタンスを使った構成の場合に、可能な場合はEMRからSparkへ停止予定のインスタンスが通知されるようになっています。そのため停止予定のインスタンスにはジョブを振らないようにして停止前にクラスタのメンバからはずしておくこともできるようになっています。**
> https://docs.aws.amazon.com/ja_jp/emr/latest/ReleaseGuide/emr-spark-configure.html
>
> スポットインスタンスの価格は需要と供給のバランスによって動的に変化しますが、1年以上前までは価格変動が激しく、瞬間的にオンデマンドの価格を上回ってインスタンスが終了されることがしばしば発生していましたが、1年前よりスポット価格の価格変動がかなり穏やかに変わりました。



### CloudFormation

要するにIaC。概要は[こちら](【CloudFormation入門】5分と6行で始めるAWS CloudFormationテンプレートによるインフラ構築 | DevelopersIO https://dev.classmethod.jp/articles/cloudformation-beginner01/)。[Black Belt](https://www.youtube.com/watch?v=Viyqh9fNBjw)も見ておくとよい。

基本的にはイミュータブルでリソースは不要になったら全体を破棄するのが基本だが、DeletionPolicyを利用してStackを削除してもリソースを残すなどすることもできる。

[こちら](https://dev.classmethod.jp/articles/how-to-keep-datas-when-deleting-stacks/)を参照。

> ## こんな事で困ったことないですか
>
> CloudFormationはAWSの構成管理ツール、という事で基本的には新規構築だけではなく、修正や変更も基本的にはテンプレートを変更してUpdate Stackを行うことが理想です。初期構築時等なるべくクリーンな環境を作りたい場合は今までのStackで環境を作って色々実験し、本番は本番用として別スタックを作成して、今までのStackは削除することもあるかと思います。 ですがDelete Stackすると**全てが削除される**わけなので、例えば一つのサーバーだけミドルウェアや新規ユーザーを入れていたとしてもDelete Stackしてしまえば**全てまとめてTerminateされてしまいます**。
>
> ## DeletionPolicy
>
> CloudFormationには[DeletionPolicy]という項目があります。[DeletionPolicy]はDelete Stackされた時にリソースがどのような動きをするかを定義する項目です。 [DeletionPolicy]は
>
> - Delete(削除)
> - Retain(保持)
> - Snapshot(スナップショット・対象リソースのみ)
>
> の3種類になります。Deleteはそのままなので残りの2つをサクッとご紹介します。
>
> ### Retain
>
> 例えばS3のバケットをCloudFormationで作成した場合
>
> ```plain
> "myS3Bucket" : {
>   "Type" : "AWS::S3::Bucket",
>   "DeletionPolicy" : "Retain"
> }
> ```
>
> とするとDelete Stackをした時にもバケットは**保持されてデータは残ります**。簡単ですね。
>
> ### Snapshot
>
> Snapshotを使えるのはリソース的にスナップショットが使えるAWS::EC2::Volume、AWS::RDS::DBInstance、AWS::Redshift::Clusterの3つのリソースに使えます。
>
> ```plain
> "MyDB" : {
>   "Type" : "AWS::RDS::DBInstance",
>   "Properties" : {
>     "DBName" : { "Ref" : "DBName" },
>     "AllocatedStorage" : { "Ref" : "DBAllocatedStorage" },
>     "DBInstanceClass" : { "Ref" : "DBInstanceClass" },
>     "Engine" : "MySQL",
>     "EngineVersion" : "5.5",
>     "MasterUsername" : { "Ref" : "DBUser" },
>     "MasterUserPassword" : { "Ref" : "DBPassword" },
>     "Tags" : [ { "Key" : "Name", "Value" : "My SQL Database" } ]
>   },
>   "DeletionPolicy" : "Snapshot"
> }
> ```
>
> 例えばこのようにRDBにつけるだけでDelete Stack時に**スナップショットが取れます**。簡単ですね。

#### CloudFormation StackSets

[こちら](https://zenn.dev/mn87/articles/479df996045a8d)を参照。 

> ## 概要
>
> - **複数のアカウントおよびリージョンのスタック**を 1 度のオペレーションで、作成、更新、削除できるようにすることで、スタックの機能を拡張
> - **管理者アカウント**を使用して、AWS CloudFormation テンプレートを定義および管理
> - 指定のリージョンの選択されたターゲットアカウントにスタックをプロビジョニングする基盤としてテンプレートを使用
>   ![image.png](https://res.cloudinary.com/zenn/image/fetch/s--T1To1OlK--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_1200/https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1162215/32bacea4-fc3e-f678-6930-ff29e1447d4a.png)
>
> スタックセットを使用することで、複数アカウントや複数リージョンにまたがってスタックの作成などができるようです。
> 作成条件は管理者アカウントであることみたいですね。
>
> ## 用語
>
> - 管理者アカウント
>   - スタックセットを作成する AWS アカウント
> - ターゲットアカウント
>   - スタックセットの 1 つ以上のスタックを作成、更新、削除するアカウント
>   - **スタックセット作成前に管理者アカウントとターゲットアカウント間で信頼関係の構築が必要**
> - スタックセット
>   - 1 つの AWS CloudFormation テンプレートを使用して、複数のリージョンの AWS アカウントにスタックを作成できる
>   - 各スタックに含まれるリソースはすべて、スタックセットの AWS CloudFormation テンプレートで定義
>   - スタックセットを定義したら、指定したターゲットアカウントやリージョンでスタックを作成、更新、削除できる
>   - スタックセットはリージョンのリソース
>   - 1 つのリージョンでスタックを作成した場合、他のリージョンでそのスタックを表示または変更することはできない
> - スタックセットのアクセス許可モデル
>   - スタックセットは、セルフマネージド型のアクセス許可またサービスマネージド型のアクセス許可のいずれかを使用して作成
>   - <u>**セルフマネージド型アクセス許可を使用する場合、アカウントとリージョン間でデプロイするために StackSets で必要な IAM ロールを作成**</u>
>   - <u>**サービスマネージド型のアクセス許可を使用する場合、AWS Organizations が管理するアカウントにスタックインスタンスをデプロイ**</u>
>   - サービスマネージド型の場合、ユーザーに代わって StackSets が IAM ロールを作成するため、IAM ロールの作成は不要
> - スタックインスタンス
>   - リージョン内のターゲットアカウントのスタックへのリファレンス
>   - スタックインスタンスは、スタックがなくても存在することができる
>   - スタックインスタンスに関連付けられるスタックセットは、1 つのみ
>     ![image.png](https://res.cloudinary.com/zenn/image/fetch/s--HyiUZq4D--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_1200/https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1162215/249356d6-291e-df23-b190-c433ca091a16.png)
>
> 管理者アカウントはOrganizationsのマスターアカウントとは限らないようですね。
> ある組織で複数のアカウントを管理するためのアカウントなので、必ずしもOrganizaionsを利用する必要はないようです。
>
> スタックインスタンスは、でテンプレートであるスタックセットが実際に展開されたスタックのことを指しているんでしょうか？
> リファレンス(参照)なので、そのスタックへのパスみたいな概念とも捉えられます。そうだとすれば、スタックがなくてもパスは存在するという説明も納得できます。

> ![スクリーンショット 2022-12-18 11.44.33](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-18 11.44.33.png)
>
> ![スクリーンショット 2022-12-18 11.44.51](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-18 11.44.51.png)
>
> ![スクリーンショット 2022-12-18 11.44.58](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-18 11.44.58.png)
>
> ![スクリーンショット 2022-12-18 11.45.05](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-18 11.45.05.png)
>
> ![スクリーンショット 2022-12-18 11.57.27](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-18 11.57.27.png)
>
> ![スクリーンショット 2022-12-18 11.57.39](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-18 11.57.39.png)
>
> ![スクリーンショット 2022-12-18 11.57.50](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-18 11.57.50.png)





### CloudFront

ACM(AWS Certificate Manager)を使って証明書を発行し、CloudFrontに設定することができる。

詳細な手順は[こちら]([ACM] AWS Certificate Manager 無料のサーバ証明書でCloudFrontをHTTPS化してみた | DevelopersIO https://dev.classmethod.jp/articles/acm-cloudfront-ssl/)参照。

- S3がオリジンの場合にS3への直接アクセスを拒否するには、以下の設定によりCloudFrontからのアクセスに絞ることができる

  - S3側の側の設定でPrincipalにOAIを設定する

  - CloudFrontオリジン設定でOAIを設定する

    > ![img](https://hacknote.jp/wp-content/uploads/2018/09/s3rest000.png)
    >
    > 
    >
    > 下記を組み合わせて制限。
    >
    > - ビューアーと CloudFront 間の制限: CloudFront の Behavior 設定にて、署名付き URL 、もしくは署名付き Cookie 限定のアクセス許可設定を施してアクセス制限
    > - CloudFront と S3 オリジン間の制限: CloudFront の オリジンアクセスアイデンティティ (OAI) 設定と S3 のバケットポリシーの組み合わせにより、CloudFront に対して限定的に S3 へのアクセスを許可
    >
    > 
    >
    > OAI は、特定 CloudFront ディストリビューション限定のアクセス許可を設定する際に、CloudFront ディストリビューションを識別するための ID。
    >
    > マネジメントコンソールの CloudFront 画面から作成できる。
    > 要はただの名前なので、その作成画面はすごくあっさり。




※CloudFrontの照明付きURLを利用したコンテンツ配布

[こちら]()を参照。S3の前にCloudFrontを置いて、そこからしかS3のコンテンツを取得できないようにしたり、期限付きで取得できるようにしたりできる。コンテンツの取得期間や対象となるコンテンツ、アクセス元のURLなどの制約が課せられる。ポリシーと署名が必要で、署名用のキーペアは以前はrootユーザーでのみ行えたが、今はIAMユーザーによるキーグループへのアップロードが可能であり、こちらが推奨なので、ローカルで作成したキーペアをアップロードする流れとなる。



- フィールドレベル暗号化

  - [こちら](https://dev.classmethod.jp/articles/cloudfront-field-level-encryption/)にあるように特定のフィールドに限定して暗号化することができる。

  - ![img](https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2017/12/cf-field-encryption01.png)

  - > 秘匿情報の保護は、Webシステムの設計においてしばしば課題になります。Web/APサーバーのサーバーサイドアプリケーションで暗号化を施し、データベースなどに格納するのが一般的だと思いますが、暗号キーの安全な管理やマイクロサービスアーキテクチャでのサービス間の秘匿情報の受け渡しなど、実装上の課題は様々です。Field-Level Encryptionはサーバーに届く手前の早い段階で暗号化を施せること、AWS Encryption SDKによる標準化された暗号/復号プロセスを踏めることで秘匿情報の安全な管理機能を提供します。



### Route53

- プライベートホストゾーン

  - VPC内で名前解決をしてくれるもの

- パブリックホストゾーン

  - VPC外でも名前解決してくれるもの

- Resolver

  - [こちら](Route53 Resolver とは - Qiita https://qiita.com/miyuki_samitani/items/3635efbad2c776ee9de6#:~:text=%E3%82%AA%E3%83%B3%E3%83%97%E3%83%AC%E7%92%B0%E5%A2%83%E3%81%A8VPC%E3%81%AE,%E3%82%88%E3%81%86%E3%81%AB%E3%81%AA%E3%82%8B%E3%82%B5%E3%83%BC%E3%83%93%E3%82%B9%E3%81%A7%E3%81%99%E3%80%82&text=Route53%20Resolver%E3%81%AB%E3%82%88%E3%81%A3%E3%81%A6%E3%83%97%E3%83%A9%E3%82%A4%E3%83%99%E3%83%BC%E3%83%88%E3%82%A2%E3%83%89%E3%83%AC%E3%82%B9,%E3%82%88%E3%81%86%E3%81%AB%E3%81%AA%E3%82%8A%E3%81%BE%E3%81%97%E3%81%9F%E3%80%82)参照

  - > オンプレ環境とVPCの間でDNSの名前解決ができるようになるサービスです。
    > 今まではVPNやDirect ConnectでつながっていてもDNSフォワーダー(別のフルサービスリゾルバへDNS要求を中継するDNSサーバ)がないと出来なかったですが、
    > Route53 Resolverによってプライベートアドレスの空間で相互利用ができるようになりました。



ルーティングポリシーについては[こちら](https://syuntech.net/aws/route53_routing/)が分かりやすい。

> ## **ルーティングポリシーとは**
>
> 負荷分散やDR対応などの観点で、複数のリージョンでサービスを展開させている場合など「適切なリソースにトラフィックをルーティングしたい」ことがあります。
>
> これを実現するのが**ルーティングポリシー**です。
>
> Route53のコンソールでは6つの方法が選択できますので、それぞれ紹介します。
>
> リソースによるルーティング
>
> ### シンプルルーティング
>
> まずは一番シンプルなルーティングです。
>
> ひとつのDNSレコードに対して１つのリソースが紐付きます。
>
> ![route53 シンプルなルーティングの解説](https://i0.wp.com/syuntech.net/wp-content/uploads/2022/07/8b806bf791591f9567e7fe8ad932d5a1.png?resize=519%2C486&ssl=1)
>
> ### 加重ルール
>
> リソースが複数存在しているときに、どのように分配するかを設定できます。
>
> 主に負荷分散に利用されます。
>
> ![route53 加重ルールによるルーティングの解説](https://i0.wp.com/syuntech.net/wp-content/uploads/2022/07/0cc6c1d778ca8095a51d9d47be12d149-1024x645.png?resize=750%2C473&ssl=1)
>
> 
>
> 
>
> ### レイテンシルール
>
> 複数のリソースへのレイテンシを計算して最もレイテンシの低い方にルーティングします。
>
> ユーザにとって最も早くアクセスできるリソースに割り振られるようになりますが、各リソースごとの負荷に偏りはでます。
>
> 
>
> ![route53 レイテンシルールによるルーティングの解説](https://i0.wp.com/syuntech.net/wp-content/uploads/2022/07/6287db1b72b5a59d7d1e9f5e85dc5b56-1024x579.png?resize=750%2C424&ssl=1)
>
> ### フェイルオーバールール
>
> ふたつ以上のリソースを準備しておき、プライマリが利用不可になったらセカンダリに振るためのルール。
>
> DRとかに使われます。
>
> 
>
> ![route53 フェイルオーバーによるルーティングの解説](https://i0.wp.com/syuntech.net/wp-content/uploads/2022/07/31634bbb6d3db420180b7530cffc942a-1024x636.png?resize=750%2C466&ssl=1)
>
> 
>
> 位置情報によるルーティング
>
> ### 位置情報ルール
>
> ユーザーの地理的場所、つまり DNS クエリの送信元の場所に基づいて、トラフィックを処理するリソースを選択できます。
>
> 位置情報ルーティングを使用する場合は、コンテンツをローカライズし、ウェブサイトの一部またはすべてをユーザーの言語で表示できます。また、位置情報ルーティングを使用して、コンテンツの配布を、配布の権利がある場所だけに制限することもできます。
>
> 
>
> 例えば、「東京リージョン」と「アメリカ（バージニア北部）リージョン」にそれぞれリソースがあるサイトだとすると
>
> - 日本地域には日本語で表示するために東京リージョンにルーティング
> - 日本地域以外は英語で表示するためにアメリカ（バージニア北部）リージョンにルーティング
>
> ![route53 位置情報ルールによるルーティングの解説](https://i0.wp.com/syuntech.net/wp-content/uploads/2022/07/f368c191b2f7b715541f0722ca840b71.png?resize=680%2C483&ssl=1)
>
> このような設定ができます。
>
> 左下のインドネシア辺りや、右下のブラジル辺りからアクセスしてもバージニア北部リージョンのリソースにルーティングされます。
>
> 日本リージョンにルーティングされるのは日本地域からのアクセスのみです。
>
> ### 地理的近似性ルール
>
> ユーザーとリソースの地理的場所に基づいてリソースのトラフィックをルーティングします。また、必要に応じて特定のリソースにルーティングするトラフィックの量を変更できます。
>
> 位置情報と同じように「東京リージョン」と「アメリカ（バージニア北部）リージョン」に設定することを例に挙げます。
>
> ![route53 地理的近似性によるルーティングの解説](https://i0.wp.com/syuntech.net/wp-content/uploads/2022/07/132f078211c5d8544a556e2d22ef88fc.png?resize=674%2C482&ssl=1)
>
> この場合はアクセスしているユーザから近いリソースにルーティングされますので、青い地域は東京リージョンにルーティングされ赤い地域はアメリカ（バージニア北部）リージョンにルーティングされます。
>
> 
>
> ## **位置情報ルールと地理的近似性の違い**
>
> 位置情報ルールと地理的近似性はかなり似たような設定になります。それぞれ同じような設定をすることもできます。
>
> ではどのような時に使い分けるのか？
>
> 下記に位置情報ルールと致死的近接ルールの設定を並べています。
>
> 前提は
>
> - 日本地域には日本語で表示するために東京リージョンにルーティング
> - 日本地域以外は英語で表示するためにアメリカ（バージニア北部）リージョンにルーティング
>
> このように並べてみると、左下の赤枠部分のルーティングが「位置情報ルール」の場合と「地理的近接ルール」の場合で異なっていますね。
>
> ![route53 位置情報ルールと地理的近似性ルールの違い](https://i0.wp.com/syuntech.net/wp-content/uploads/2022/07/5bd156fc0f4e676ff6934beaeca67492.png?resize=674%2C524&ssl=1)
>
> 使い分けとしては。このように覚えておきましょう。
>
> 位置情報ルールは『特定の地域に特定のリソースをルーティング』するために使う
>
> 地理的近接ルールは『近くのリソースにルーティング』させるために使う

### Cognito

- アプリケーションにサインインする際にMFAの実装が必要な場合はCognito ユーザープールでMFAを有効にする必要がある。
- エンドユーザーがアプリケーションにサインインしている場合のみ実行可能な保護されたAPIを開発することも可能。この場合、以下のようにする必要がある。
  - Cognitoユーザープールでエンドユーザーを認証する
  - API GatewayでCognitoオーソライザーを有効にする
- Cognito IDプールは、以下のような用途で使用するもの。
  - Amazon Simple Storage Service (Amazon S3) バケットや Amazon DynamoDB テーブルなどの [AWS リソースへのアクセス](https://docs.aws.amazon.com/cognito/latest/developerguide/iam-roles.html)をユーザーに許可する。
  - [未認証ユーザー用の AWS 認証情報](https://docs.aws.amazon.com/cognito/latest/developerguide/switching-identities.html)を一時的に生成する。



### SES

メール送れるサービス。

Kinesis Data FirehorseとS3, Athenaと組み合わせて、マーケティング的に送ったメールの開封率やクリック率等を調べることもできる。詳しくは[こちら](https://note.com/tyrwzl/n/n5678c80ff8e1)。

> SES は送信、配信、オープン、クリックなどといったタイプの E メール送信イベントを発行し、Amazon CloudWatch や Amazon Kinesis Data Firehorse にイベントを送信することができます [1]。
> 例えば、これを利用して開封数やクリック数といったメトリクスを CloudWatch メトリクスからグラフ化して確認することができます [2]。
> E メール送信イベントは、Configuration Set を作成して SES 経由でメールを送信する際に作成した Configuration Set を指定することでを発行できます。
> Configuration Set にはタグをつけられるので、タグに E メール種別を埋め込んでおくことで、下記のようにメール種別ごとのメトリクスを計測することが可能です。
>
> ただ、CloudWatch メトリクスは同一人物が開封、クリックを実施してもそれぞれのイベントをユニークなものとしてカウントされてしまいます [3]。
> 例えば example@pol.co.jp 宛に送ったメールに含まれる labbase.jp というリンクを別の時間帯に 2 回踏んだ場合は、それぞれの時間帯にクリック数のメトリクスが 1 カウントされてしまいます。
> したがって、メールアドレスごとの開封数やクリック率を計測したい、といったようなユースケースには不適切です。
>
> そこで、E メール送信イベントの発行先を Amazon Kinesis Data Firehose にして、Parquet 形式で S3 に保存し、保存した Parquet ファイルを Amazon Athena を用いて集計できるようにしました。

※SNSトピックのサブスクリプションにKinesis Data Firehorseは利用できない。



### SNS、SQS、EventBridge

SNSと比べるとEventBridgeが連携先が幅広く、1:Nで多くのサービスにメッセージを送付できる。APIもコールできるしCloudWatch Logsにも送れる。

EventBridgeは[BlackBelt](https://www.youtube.com/watch?v=H7641kZMghg)を見ておくと良い。

![スクリーンショット 2022-12-24 15.34.51](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 15.34.51.png)

![スクリーンショット 2022-12-24 15.32.24](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 15.32.24.png)

![スクリーンショット 2022-12-24 15.36.23](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 15.36.23.png)

![スクリーンショット 2022-12-24 15.38.41](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 15.38.41.png)

![スクリーンショット 2022-12-24 15.39.41](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 15.39.41.png)

![スクリーンショット 2022-12-24 15.45.22](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 15.45.22.png)



![スクリーンショット 2022-12-24 15.45.40](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 15.45.40.png)

![スクリーンショット 2022-12-24 15.47.56](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 15.47.56.png)

![スクリーンショット 2022-12-24 15.52.03](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 15.52.03.png)

機能比較については[こちら](AWSのメッセージングサービス SQS、SNS、EventBridge の主な機能比較 - Qiita https://qiita.com/okubot55/items/1987bbcfab99a4da24fb)を参照。

##### トピックポリシー

公式[参照](https://docs.aws.amazon.com/ja_jp/sns/latest/dg/sns-access-policy-use-cases.html)。

> ## トピックへの AWS アカウント アクセスの付与
>
> Amazon SNS システムにトピックがあるとします。最も簡単なケースとして、特定のトピックアクション (発行など) へのアクセスを 1 つ以上の AWS アカウント に許可するとします。
>
> これは、Amazon SNS API アクション `AddPermission` を使用して実行できます。これには、トピック、AWS アカウント ID リスト、アクションリスト、ラベルが必要ですが、トピックのアクセスコントロールポリシー内に新規ステートメントが自動的に作成されます。この場合、 Amazon SNS により新規ポリシーステートメントが自動的に作成されます。手動でポリシーを記述する必要はありません。ラベルと共に `RemovePermission` を呼び出すことによって、後日ポリシーステートメントを削除することができます。
>
> 例えば、トピック arn:aws:sns:us-east-2:444455556666:MyTopic を対象に `AddPermission` を呼び出す場合 (AWS アカウント ID 1111-2222-3333、`Publish` アクション、ラベル `grant-1234-publish` を使用)、Amazon SNS は次のアクセスコントロールポリシーステートメントを作成して挿入します。
>
> ```
> {
>   "Statement": [{
>     "Sid": "grant-1234-publish",
>     "Effect": "Allow",
>     "Principal": {
>       "AWS": "111122223333"
>     },
>     "Action": ["sns:Publish"],
>     "Resource": "arn:aws:sns:us-east-2:444455556666:MyTopic"
>   }]
> }
> ```
>
> 一度このステートメントが追加されてしまえば、AWS アカウント 1111-2222-3333 のユーザーはトピックへメッセージを発行することができます。



#### SQS

- エラーなどの発生時に処理内容を損なわないようにDLQ(Dead Letter Queue)に格納することができる。例えば[こちら](【これで理解できる】SQSのデッドレターキューを理解したかったのでSQS+Lambdaのリトライ処理を実装してみた - Qiita https://qiita.com/memomaruRey/items/af1cfa19a20071b48ffe)のように、複数回エラーを繰り返すとDLQにメッセージが移り、あとで再処理したりできる。

- 遅延キューは[こちら](https://qiita.com/maaaato/items/52181f7ef6262189d587#delayseconds%E9%81%85%E5%BB%B6%E3%82%AD%E3%83%A5%E3%83%BC)参照。

  > 遅延キューを使用すると、キューにある新しいメッセージの配信を一定の秒数延期することができます。遅延キューを作成した場合、そのキューに送信したすべてのメッセージが遅延期間の間コンシューマーに表示されなくなります。DelaySeconds 属性を 0 ～ 900（15 分）の任意の値に設定することで、CreateQueue を使用して遅延キューを作成できます。SetQueueAttributes を使用してキューの DelaySeconds 属性を設定することにより、既存のキューを遅延キューに入れることもできます。
  >
  > 遅延キューは、メッセージを一定の時間コンシューマーが使用できなくするという点で可視性タイムアウトと似ています。**遅延キューと可視性タイムアウトの違いは、遅延キューの場合、メッセージが最初にキューに追加されたときに非表示になるのに対して、可視性タイムアウトの場合、メッセージがキューから取得された後のみ非表示になるという点です。**次の図は、遅延キューと可視性タイムアウトの関係を示しています。

- SQSのメッセージが増えてきたときのEC2のAutoScalingについては、キューの**<u>ApproximateNumberOfMessagesをInService状態のEC2インスタンス数で割った数</u>**を、Lambda関数からPutMetricDataしたカスタムメトリクスをCloudWatchに送ることで制御すると良い。


##### 用語

- DLQ(Dead Letter Queue)

  - 想定外のエラーなどの発生時に情報が失わ割れないようにLamdaにSQSでメッセージを送信する際に使うことができる

    [参考](https://qiita.com/memomaruRey/items/af1cfa19a20071b48ffe)



### Cloud Watch

[こちら](https://qiita.com/moomindani/items/aef16aa93db56b071ba3)参照。

> CloudWatchはAWSが提供するモニタリングのためのマネージドサービスです。
> この記事で主に取り扱うメトリクスのほかに様々なサービスがあります。
> \- CloudWatch Metrics: メトリクス
> \- CloudWatch Alarms: アラーム（通知）
> \- CloudWatch Logs: ログ
> \- CloudWatch Events (現在は Amazon EventBridge): イベント契機の通知や処理
> \- CloudWatch Dashboards: ダッシュボード、コンソール画面
> \- CloudWatch Synthetics: 外形監視
> \- CloudWatch ServiceLens: X-Rayと連携したアプリケーション監視・分散トレーシング
> \- CloudWatch Contributor Insights: パフォーマンスに最も影響を及ぼしている要因の分析
> \- CloudWatch Container Insights: ECSとEKSのメトリクス・ログ収集
> \- CloudWatch Application Insights for .NET and SQL Server
> \- CloudWatch (unified) agent: 任意のサーバーで実行できるメトリクス・ログ収集エージェント
> \- CloudWatch SDK metrics for Enterprise Support: AWS APIをクライアントからコールした回数等の状況をSDKレベルでメトリクス化



よく行われるのはCloudWatchのCLIからget-metric-dataでメトリック情報を取得し、EventBridge等でどこかにログを送るなどでしょうか。

> ### get-metric-data
>
> 以下の`get-metric-data`コマンドでは、`Namespace=JawsCLI`、`Metric Name=TestMetrics`、`Dimensions=[TestKey=TestValue]`という識別値にひもづくメトリクスの平均値を60秒粒度で、15分前から現在の分まで取得しています。
>
> なお、今回はCLIの引数にJSON文字列を含めていますが、`file://`プレフィックスによりJSONファイルから読み取らせることもできます。
>
> ```
> $ aws cloudwatch get-metric-data --metric-data-queries '{"Id":"q1","MetricStat":{"Metric":{"Namespace":"JawsCLI","MetricName":"TestMetric","Dimensions":[{"Name":"TestKey","Value":"TestValue"}]},"Period":60,"Stat":"Average"}}' --start-time $(date -u +"%Y-%m-%dT%H:%M:%SZ" -d "15 min ago") --end-time $(date -u +"%Y-%m-%dT%H:%M:%SZ")
> {
>     "MetricDataResults": [
>         {
>             "Id": "q1",
>             "Label": "TestMetric",
>             "Timestamps": [
>                 "2020-03-02T07:56:00Z"
>             ],
>             "Values": [
>                 100.0
>             ],
>             "StatusCode": "Complete"
>         }
>     ],
>     "Messages": []
> }
> ```
>
> 上記のように、`GetMetricStatistics`と`GetMetricData`はいずれもメトリクスの取得に使用できます。
> 違いについては以下のドキュメントに記述があります。
> 基本的には何も考えずに`GetMetricData`を使えばOKです。



#### CloudWatch Synthetics

[こちら](CloudWatch SyntheticsでURL死活監視を試してみる | SunnyCloud https://www.sunnycloud.jp/column/20210909-01/)を参照。

> ウェブサイトや API のエンドポイントに対して、 SeleniumやPuppetterと同様に利用ユーザーと同じアクションを実行して、パフォーマンスや可用性をモニタリングできます。 CloudWatch Synthetics では、**Canary** を設定します。Canaryとは スケジュールに沿って実行されるスクリプトです。Canary では Node.js、Pythonのスクリプトや実行間隔、通知などの設定をします。 スクリプトの作成は、AWS が提供するブループリントを使用する方法やChromeの拡張機能を利用することで、 操作に応じたスクリプトが生成されます。また、CloudWatch Synthetics のライブラリを組み込んで作成する方法があります。



### KMS

[こちら](10分でわかる！Key Management Serviceの仕組み #cmdevio | DevelopersIO https://dev.classmethod.jp/articles/10minutes-kms/)が非常にわかりやすい。カスタマーマスターキーとデータキーがあり、実際にデータを暗号・復号化するのはデータキー。カスタマーマスターキーは外部にエクスポートしたりすることはできず、データキーの暗号/復号のために用いる。

カスタマーマスターキーはAWSに運用を任せられるマネージド型と自分で運用するカスタマー管理型のキーがある。また、キーポリシを設定でき、アクセス権を柔軟に設定できる(クロスアカウントのアクセスも可能)。

KMSの概念はけっこう難しい(私にとっては)。[公式](https://docs.aws.amazon.com/ja_jp/kms/latest/developerguide/concepts.html)も難解な文章ではあるが、一読しておくとよいと思われる。



[こちら](https://business.ntt-east.co.jp/content/cloudsolution/column-186.html)も参考に。

> ### AWS KMSの使い方とデータ暗号化／復号化の流れ
>
> それでは、AWS KMSの使い方について、データの暗号化／復号化の流れでみていきましょう。
>
> ##### 暗号化の流れ
>
> まずは、AWS KMSでデータを暗号化する流れです。
>
> \1. AWS KMS上にCMK（カスタマーマスターキー）を作成
>
> データを暗号化するときに利用するキーを生成するためのCMKを作成します。
>
> ![img](https://business.ntt-east.co.jp/content/cloudsolution/images/column/img_column186_02.jpg)
>
> \2. CMKのKeyIDからデータキーを作成
>
> ![img](https://business.ntt-east.co.jp/content/cloudsolution/images/column/img_column186_03.jpg)
>
> AWS KMS上にCMKを作成したら、CMKを元にしたKeyIDから「データキー」を作成します。ここでは、暗号化と復号化を行うためのペアとして、以下の２種類のキーが作成されます。
>
> - 暗号化用のデータキー：データを暗号化するためのキー
> - CMKを元に暗号化されたデータキー：データ復号化のために利用するキー
>
> データを暗号化するために利用するのは、「暗号化用のデータキー」です。
>
> \3. ローカル環境にてデータを暗号化
>
> ![img](https://business.ntt-east.co.jp/content/cloudsolution/images/column/img_column186_04.jpg)
>
> 「２．」で受け取った「暗号化用のデータキー」を使ってデータを暗号化します。
>
> 暗号化をするときには、AWS KMSへ何かをリクエストすることなく、ローカル環境のみで暗号化できます。
>
> \4. 暗号化されていないデータキーを破棄
>
> 暗号化が完了したら、暗号化に利用した「暗号化用のデータキー」をすぐに破棄します。これは、万が一「暗号化用のデータキー」が第三者の手に渡った場合、暗号化したデータを簡単に復号化できてしまうためです。
>
> これで、データの暗号化は完了です。
>
> ##### 復号化の流れ
>
> それでは、復号化の流れをみていきましょう。
>
> \1. データキーの復号化
>
> ![img](https://business.ntt-east.co.jp/content/cloudsolution/images/column/img_column186_05.jpg)
>
> まずは、「暗号化の流れ」の中でユーザーが受け取った「CMKを元に暗号化されたデータキー」を復号化します。
>
> ※このとき、データキーを復号化するために「KeyID」と「CMKを元に暗号化されたデータキー」をAWS KMSに渡して、「復号化されたデータキー」を受け取ります。
>
> \2. ローカル環境にてデータを復号化
>
> ![img](https://business.ntt-east.co.jp/content/cloudsolution/images/column/img_column186_06.jpg)
>
> 「１．」で復号化したデータキーで、「暗号化されているデータ」を復号化します。
>
> \3. 復号化したデータキーを破棄
>
> データの復号化に利用した「復号化されたデータキー」を破棄します。
>
> これで、データの復号化は完了です。
>
> ### AWS Secret Managerとの違い
>
> 前述の通り、AWS KMSは暗号化／復号化のためのCMKを管理しますが、同じようにAWSには認証情報を管理するサービス「AWS Secret Manager」があります。どちらも機密情報を保管するサービスという意味では共通していますが、両者には以下のような違いがあります。
>
> - AWS Secret Manager：認証情報などのシークレットを保管する
> - AWS KMS：データを暗号化／復号化するために利用するキーを作成するためのCMKを保管する
>
> データベースに接続するための認証情報であるシークレットを利用する場合はAWS Secret Managerを利用し、データの暗号化や復号化を安全に行いたい場合にはAWS KMSを利用するなど、利用シーンに合わせてサービスを選定できるということです。
>
> AWS Secrets Managerについては、「[AWS Secrets Managerによる機密情報の管理![別ウィンドウで開きます](https://business.ntt-east.co.jp/shared/images/icon_window_01.png)](https://business.ntt-east.co.jp/content/cloudsolution/column-84.html)」で詳しく解説していますので参考にしてください。



また、[こちら](https://ktrysmt.github.io/blog/difference-between-sse-s3-and-sse-kms/)にもあるとおり、SSE-S3とSSE-KMSの違いがわかりづらい。

> 結論言ってしまうとSSE-S3の場合は鍵を利用したかどうかの監査証跡が取れないことがネックになります。一方でSSE-S3は追加料金が発生せず、APIコールの制限を考慮する必要もないのがメリットです。
>
> ## SSE-KMSの特徴
>
> - キーポリシーでCMK(カスタマーマスターキー)への個別のアクセス制御ができる
> - KMSに対するAPIコールに当たるため、監査証跡(CloudTrail)を残すことが可能
> - 暗号化キーの作成および管理ができる
> - 当該AWSアカウントのリージョンごとに一意に作成されるデフォルトサービスキーを使用することもできる
> - KMS利用分の[追加料金](https://aws.amazon.com/jp/kms/pricing/)が発生
> - S3に対するPut/Getが非常に多くなる場合には KMS の [APIコールの制限](https://docs.aws.amazon.com/ja_jp/kms/latest/developerguide/limits.html) の考慮が必要
>
> ## SSE-S3の特徴
>
> - キーに対する個別アクセス制限は不可、実質的なアクセス制限は署名バージョン4による当該AWSアカウントID以外の拒否のみとなる
> - 監査証跡(CloudTrail)には残らない
> - KMSに比べキーの選択肢は無く提供されるもののみ使用できる
> - SSE-S3のための追加料金は発生しない
> - APIコールの制限に関して考慮は不要



SSE-S3の詳細と具体的な設定方法については[こちら](https://dev.classmethod.jp/articles/lim-s3-sse-2021/)も参照。

> ## 1. Amazon S3の暗号化とは？
>
> - 暗号化を使用することで転送時と保管時にデータをもっと安全に保護できる
>   - 転送時：Amazon S3 との間でデータを送受信するとき
>   - 保管時：Amazon S3 データセンター内のディスクに格納されているとき
> - 大きくサーバー側の暗号化とクライアント側の暗号化に分けている
>   - サーバー側の暗号化：SSE-S3、SSE-KMS、SSE-C
>     - データセンターのディスクに保存する前にオブジェクトを暗号化し、オブジェクトをダウンロードする際に解読するようAmazon S3に要請
>   - クライアント側の暗号化：クライアント側の暗号化
>     - クライアント側のデータを暗号化して暗号化されたデータをAmazon S3にアップロードすること
>     - ユーザーが暗号化プロセス、暗号化キー、関連ツールを管理する
>
> ## 2. Amazon S3の暗号化４種類
>
> ### SSE-S3
>
> ![img](https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2021/08/301-640x330.png)
>
> - Amazon S3によって処理、管理されるキーを使用
> - オブジェクトを固有のキーで暗号化
> - `AES-256`暗号化タイプを使用
> - `"x-amz-server-side-encryption":"AES256"`ヘッダーを設定して利用する
>
> ### SSE-KMS
>
> ![img](https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2021/08/302-640x347.png)
>
> - オブジェクトを作成する際にAWS Key Management Service(AWS KMS)の顧客マスタキー(CMK)を使用するサーバ側の暗号化によりデータを暗号化するように指定
> - `"x-amz-server-side-encryption":"aws:kms"`ヘッダーを設定して利用する
>
> ### SSE-C
>
> ![img](https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2021/08/303-640x255.png)
>
> - サーバ側の暗号化を使用して独自の暗号化キーを設定
> - リクエストの一部として用意された暗号化キーで、Amazon S3 は、ディスクに書き込む際の暗号化、オブジェクトにアクセスする際の復号を管理
> - `AES-256`暗号化タイプを使用
> - HTTPSだけサポートする
>
> ### クライアント側の暗号化
>
> ![img](https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2021/08/304-640x239.png)
>
> - クライアント側の暗号化でAmazon S3に送る前にデータを暗号化する方法
> - クライアント側暗号化ライブラリ（AWS Encryption SDK）を使用すると暗号化をより容易に実装可能
> - AWS Encryption SDKとAmazon S3 暗号化クライアントは、異なるデータ形式で暗号テキストを生成するため互換できない



### QuickSight

[こちら](https://www.sunnycloud.jp/column/20210930-01/)参照。

> QuickSightはAWSで簡単に分析環境を作ることができるBIサービスです。
>
> ![img](https://www.sunnycloud.jp/wp-content/uploads/2021/09/01-13.png)https://pages.awscloud.com/rs/112-TZM-766/images/%5B%E3%82%A4%E3%83%B3%E3%83%88%E3%83%AD%5DAmazonQuickSight%E3%83%8E%E3%82%A6%E3%83%8F%E3%82%A6%E7%B7%8F%E3%81%BE%E3%81%A8%E3%82%81%E3%82%BB%E3%83%9F%E3%83%8A%E3%83%BC_1014.pdfより引用
>
> どのような特徴があるのか概要をお伝えします。



### App Runner

[こちら](https://dev.classmethod.jp/articles/re-introduction-2022-app-runner/)を参照。

> > コンテナ化されたウェブアプリケーションや API を開発者が簡単かつ迅速にデプロイできるフルマネージド型サービスです。
>
> とある様に、アプリケーションコンテナひとつ用意すればあとのインフラはAWSにおまかせでWEBアプリケーションを公開できる便利なサービスです。
>
> AWSでコンテナを扱うサービスは他に[Amazon ECS](https://aws.amazon.com/jp/ecs/)や[Amazon EKS](https://aws.amazon.com/jp/eks/)がありますが、App Runnerはインフラ管理をよりマネージドにし利用者はアプリケーション開発に集中できる様になっています。
> 実際App Runnerの内部実装はAWS管理のAmazon ECS + AWS Fargateとなっています。



[こちら](https://iridge-tech.hatenablog.com/entry/2022/08/09/120000)も参考に。

> ## App Runnerってどんなサービス？
>
> App Runnerは、コンテナを実行できるサービスの一つです。EC2やECS、Lambdaと同じコンピューティングサービスに分類されるサービスですね。AWSにはコンテナを実行できるサービスとしてECS、EKSがすでに存在しています。App RunnerはECSやEKSの仲間として新たに加わったサービスとなります。
>
> App RunnerがECSやEKSと違うのは特に以下の点です。
>
> #### ソースコードのみからでもコンテナを展開できる
>
> App Runnerでは、コンテナイメージからコンテナを展開するだけではなく、GitHub上にあるソースコードから自動的にソースコード実行に必要なコンテナをビルドして、展開することも可能です。これにより、利用者はDockerコンテナのメンテナンス作業から解放されます。
>
> #### コンテナ実行インフラは完全に隠蔽されている
>
> ECSやEKSでは、コンテナの実行・アクセスに必要な以下のインフラを明示的に作成する必要があります。
>
> - VPC、サブネット、インターネットゲートウェイ
> - ECS、EKSクラスタ
> - コンテナを実行するEC2インスタンス (EC2タイプを選択する場合)
> - ALBなどのロードバランサ
>
> App RunnerですとこれらのリソースはAWSでの管理となり、ユーザはこれらのリソースを作成、管理する必要はありません。
>
> これは実行インフラやその管理を意識しなくていいというメリットがある反面、細かい融通を利かせることができないというデメリットもはらんでいます。
>
> ## App RunnerとECS for Fargateとの比較
>
> さて、AWSに極力コンテナ実行基盤の管理を任せる方法ですと、従来ではECS for Fargateという選択肢が有力だったのですが、これとApp Runnerとの違いはどうなっているでしょうか。違いをまとめた表は以下の通りです。
>
> | 要件                                                   | App Runner                              | ECS for Fargate |
> | ------------------------------------------------------ | --------------------------------------- | --------------- |
> | パスベースルーティング可能か                           | ×                                       | 〇              |
> | タスクの概念があるか                                   | ×                                       | 〇              |
> | Private ECRレポジトリからのプルが可能か                | 〇                                      | 〇              |
> | VPC内リソースとの通信が可能か                          | 〇                                      | 〇              |
> | オートスケールが可能か                                 | △(スケール用のメトリクスはAWS任せ)      | 〇              |
> | VPC・ECSクラスタの準備が不要か                         | 〇                                      | ×               |
> | ジョブスケジューリング可能か                           | ×                                       | 〇              |
> | NATゲートウェイによる固定IP設定が可能か                | 〇                                      | 〇              |
> | カスタムドメインが利用可能か                           | △(デフォルトで自動化はサポートされない) | 〇              |
> | X-Rayとの連携が可能か                                  | 〇                                      | 〇              |
> | セキュリティグループによるアクセスコントロールが可能か | △(outboundのみ可能)                     | 〇              |





### Kinesis Data Firehorse/Streams/Analytics

[このあたり](https://www.youtube.com/watch?v=QY98zxAJLqk)に軽く目を通しておくと良い。

> ![スクリーンショット 2022-12-18 12.27.03](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-18 12.27.03.png)
>
> ![スクリーンショット 2022-12-18 13.43.18](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-18 13.43.18.png)

Kinesis Data Firehorseでは大量のデータを送信先に取り込むことに適している。Streamsに比べマネージドでOSの管理等の手間がない。

[こちら](https://www.acrovision.jp/service/aws/?p=1779)がわかりやすいです。

> **コンピュータから送られてくる大量のデータを高速に別のサービスに転送するためのサービスです。**
>
> 【特徴】
>
> ・Amazon Kinesis Data Streamsのほうが速い。
>
> ・Amazon Kinesis Data Firehoseのほうが設定が少ない。
>
> <中略>
>
> **Amazon Kinesis Video Streamsは次々と送られる大量のデータをリアルタイムに収集、次のサービスに配信するためのサービスです。**
>
> 「Amazon Kinesis Video Streams」の最大の特徴は「レイテンシの速さ」です。
> 「Amazon Kinesis Data Firehose」がデータロードまで60秒を見ているのに対し、Amazon Kinesis Video Streamsはsub-1、1秒以下でのデータロードにて設計されています。
>
> <中略>
>
> **Amazon Kinesis Data Firehose は、ストリーミングデータをデータレイクやデータストア、分析ツールへ簡単に送信する方法です。**
>
> ストリーミングデータをキャプチャして変換し、**「Amazon S3」、「Amazon Redshift」、「Amazon Elasticsearch Service」、「Splunk」などへ送信**し、お使いのビジネスインテリジェンスツールやダッシュボードでほぼリアルタイムに分析できます。
> 完全マネージド型サービスのため、データスループットに応じて自動的にスケールされますので、継続的な管理は不要です。

Kinesis Data Streamsはシャードと呼ばれる道を持ちます。

[公式](https://docs.aws.amazon.com/ja_jp/streams/latest/dev/key-concepts.html)の絵と説明がわかりやすいです。

![kinesis](https://docs.aws.amazon.com/ja_jp/streams/latest/dev/images/architecture.png)

> *シャード*は、ストリーム内の一意に識別されたデータレコードのシーケンスです。ストリームは複数のシャードで構成され、各シャードが容量の 1 単位になります。各シャードは、読み取りに対して最大 5 つのトランザクションをサポートできます。最大総データ読み取りレートは 2 MB /秒、書き込みの場合は最大 1,000 レコード/秒、最大 1 MB /秒（パーティションキーを含む）のデータ書き込みレート（パーティションキーを含む）です。ストリームのデータ容量は、ストリームに指定したシャードの数によって決まります。ストリームの総容量はシャードの容量の合計です。



> - Kinesis Data Analytics
>
> コンピュータやAmazon Kinesis Data Streams、Amazon Kinesis Data Firehoseから送信されてくるデータをSQLを使って処理できるサービスです。
>
> 本サービスを使用するとストリーミングデータを1秒未満のレイテンシで処理できる。



#### シャードの計算

某問題集に「1デバイスあたり100kbのデータを毎秒送信しているIoTセンサーがあります。15デバイスが同時に稼働しています。Kinesis Data Streamsのシャードはいくつ必要ですか?」という問題がありました。答えは2とのことでどのような計算になっているか調べましたが、恐らくは[公式](https://aws.amazon.com/jp/kinesis/data-streams/faqs/)にのっている以下の計算式で、

```
number_of_shards = max (incoming_write_bandwidth_in_KB/1000
```

incoming_write_bandwidthが100kb × 15デバイス=1,500kbということで、max(1,500/1,000)=2ということなんでしょう。

間違ってたらご指摘ください。



[このあたり](https://poota.net/archives/587)も詳しく書いてあるので必要に応じて参照。

### Elemental MediaLive/Elemental MediaStore

リアルタイム動画配信を実現するサービス。Elemental MediaLiveとElemental MediaStore、CloudFrontでリアルタイム配信を可能とする。

[公式](https://aws.amazon.com/jp/medialive/)から概要を押さえておけば良い。

> AWS Elemental MediaLive は、ブロードキャストグレードのライブ動画処理サービスです。テレビ放送やインターネット接続のマルチスクリーンデバイス (インターネット接続対応の TV、タブレット、スマートフォン、セットトップボックス) での配信用に、高品質なビデオストリームを作成できます。このサービスでは、ライブ動画ストリーミングをリアルタイムでエンコードし、大きいサイズのライブ動画のソースを取得して視聴者に配信するために小さいサイズに圧縮します。AWS Elemental MediaLive を使用すると、高度なブロードキャスティング機能と高可用性を実現しながら、ライブイベントにも 24 時間年中無休のチャネルにも適したストリームを従量課金制の料金体系で簡単にセットアップできます。AWS Elemental MediaLive によって、ブロードキャスティンググレードのビデオ処理インフラストラクチャを構築および運用する複雑な作業から解放され、視聴者にとって魅力的なライブ動画サービスを作り上げることに集中できます。
>
> ![img](https://d1.awsstatic.com/awselemental/v2diagrams/product-page-diagram-Elemental-MediaLive%402x.2570dba1da7763ff116d3dc2897e772ff238b63e.png)

Elemental MediaConvertという動画変換サービスもある。



### CI/CD

全体像は[こちら](https://qiita.com/leomaro7/items/41cbe8aa7c32298ec665)がわかりやすいです。

![](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.amazonaws.com%2F0%2F280929%2Fd28a875d-6e6e-23eb-09a4-feb036b43695.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=c898e9c4c118046963929ab6aaf35479)

- CodeBuildの処理を記述するファイルはbuildspec.yml、CodeDeployの処理を記述するファイルはappspec.ymlです。



[こちら](https://youtu.be/68UZucvq8Ok)の動画も非常にわかりやすい。

![スクリーンショット 2022-10-30 16.22.16](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-10-30 16.22.16.png)

Blue-Greenデプロイで現環境と新環境を同時に動かす。一般ユーザーは現環境にトラフィックを流し、特定のSourceIPやアクセスポートなどで新環境を試すことができる。

CodeDeployでECSの設定にLoadBalancerターゲットを複数設定できる。ECSAllAtOnceはそれぞれのターゲットグループへのデプロイ方法を指定できる。CodePipelineデプロイステージでECS(ブルー/グリーン)を選択すると上図のようにブルーグリーンデプロイが実施可能。

Blue-Greenデプロイはさらに以下のように分かれるらしい。[こちら](https://qiita.com/sugimount-a/items/b7bce32531947e80abe3)を参照。

> Blue/Green Deployment の中でも、更に詳細な方式があります。CodeDeploy 側で用意されている5つのデプロイ方式の中で自分たちに合うものをチョイスできます。
>
> | デプロイ設定                                        | 説明                                                         |
> | :-------------------------------------------------- | :----------------------------------------------------------- |
> | `CodeDeployDefault.ECSLinear10PercentEvery1Minutes` | すべてのトラフィックを移行するまで、1 分ごとにトラフィックの 10% を移行します。 |
> | `CodeDeployDefault.ECSLinear10PercentEvery3Minutes` | すべてのトラフィックを移行するまで、3 分ごとにトラフィックの 10% を移行します。 |
> | `CodeDeployDefault.ECSCanary10percent5Minutes`      | 最初の増分でトラフィックの 10% を移行します。残りの 90% は 5 分後にデプロイします。 |
> | `CodeDeployDefault.ECSCanary10percent15Minutes`     | 最初の増分でトラフィックの 10% を移行します。残りの 90 パーセントは 15 分後にデプロイされます。 |
> | `CodeDeployDefault.ECSAllAtOnce`                    | すべてのトラフィックを同時に更新済み Amazon ECS コンテナに移行します。 |



#### CodeDeploy

- EC2にアプリをデプロイする直前にOSレベルで処理したい場合にはappspec.ymlのBeforeInstallに処理を記述する



#### コード更新時の自動テスト実行について

- CodePipelineでCodeBuildを実行して、コマンドの戻り値がエラーの場合はパイプラインが停止する。CodeBuildで「Buildspecはソースコードのルートディレクトリのbuildspec.ymlを使用」を選択しておくと、buildspec.ymlをソースコードのリポジトリに含むことができ、ソースコード開発時に変更することもでき、あわせてバージョン管理が可能になる。
- このbuildspec.ymlにテストコマンドの実行を記述して、CodeCommitリポジトリに含める。CodePipelineでCodeDeployとも連携させる。



注意

- buildspec.ymlはCodeBuildのビルド仕様。紛らわしいので注意する。



##### ちなみにデプロイの方法はいろいろある

- 既存環境のクローンを作成してのブルーグリーンデプロイ
- カナリア
- ローリング
  - 単純ローリング
  - パッチ適用してのローリング
- All at onceデプロイ



コストが低いのは、

単純ローリングとAll at once < パッチによるローリング <ブルーグリーン

ダウンタイム

コストが低いものだけで比べると、少ないのは単純ローリング。All at onceは同時にサービス停止して作業するためダウンタイムが大きい。

デプロイの戦略と方法は[こちら](https://garafu.blogspot.com/2018/11/release-strategy.html)を参照。

> ## デプロイ/リリース方法を分類してみる
>
> クラウドサービスがあたりまえに使われるようになって種類が増えているため、ここでは「手法」「戦略」「対象」の3つの視点で分類してみました。 分類方法は整理するためにあくまで本ブログ上で便宜的に分けているだけで一般的に呼ばれているわけではない点にご注意ください。
>
> 「手法」「戦略」「対象」の概念は、「戦略」または「対象」が上位概念（全体に対してどうするか）で、「手法」が下位概念（個別サーバーに対してどうするか）になっています。 また、「手法」「戦略」「対象」は独立した考え方になっているので、それらは組み合わせが可能です。 例えば、「戦略は "ローリング（デプロイ）" で、手法は "イミュータブル（デプロイ）" なデプロイ」や「カナリアデプロイ を インプレース な ローリングデプロイ で実現する」といった組み合わせ方です。
>
> **デプロイ手法 (Method)**
>
> 各サーバーに対してどのようにデプロイを行っていくか、といった視点で分類しています。
>
> | 名称                       | デプロイ先     | ダウンタイム                 |
> | -------------------------- | -------------- | ---------------------------- |
> | サービス停止 & デプロイ    | 稼働中サーバー | 閉塞期間                     |
> | シンボリックリンク切り替え | 稼働中サーバー | ほぼゼロ（最大で再起動時間） |
> | インプレースデプロイ       | 稼働中サーバー | デプロイ＋再起動時間         |
> | ブルー/グリーンデプロイ    | 新しいサーバー | ほぼゼロ                     |
> | イミュータブルデプロイ     | 新しいサーバー | ほぼゼロ                     |
>
> **デプロイ戦略 (Strategy)**
>
> 複数サーバーに対してどのような順でリリースするか、といった視点で分類しています。
>
> | 名称               | デプロイ順         | ダウンタイム           |
> | ------------------ | ------------------ | ---------------------- |
> | ローリングデプロイ | ブロック単位で実施 | ゼロ                   |
> | 一括デプロイ       | 全台まとめて実施   | （デプロイ手法に依存） |
>
> **デプロイ対象 (Target)**
>
> デプロイを行う台数で分類しています。
>
> | 名称             | デプロイ対象台数 | ダウンタイム                 |
> | ---------------- | ---------------- | ---------------------------- |
> | カナリアデプロイ | 一定台数のみ     | ゼロ                         |
> | 一括デプロイ     | 全台             | （デプロイ戦略、手法に依存） |
>
>  
>
> ## サービス停止 & デプロイ
>
> 提供中のサービスを一時的に停止(外から見て停止なので実際は閉塞)し、ユーザーからアクセスがない状態でデプロイおよびテストを行った後、再度サービス提供を開始する方法です。 分かりやすいリリース方法ですが、サービス停止が発生するのでユーザーへの影響があります。
>
> [![img](https://2.bp.blogspot.com/--SFBf2mbM9E/W_jILuSa-WI/AAAAAAAAEWo/lZKGNB5-NukYx3Lb_kx2HxASWo1D4zvjwCPcBGAYYCw/s640/deploy-release-01.png)](https://2.bp.blogspot.com/--SFBf2mbM9E/W_jILuSa-WI/AAAAAAAAEWo/lZKGNB5-NukYx3Lb_kx2HxASWo1D4zvjwCPcBGAYYCw/s1600/deploy-release-01.png)
>
> ## シンボリックリンク切り替え
>
> 稼働中サーバーに新しいアプリケーションを別フォルダで配置し、提供中サービスが利用しているシンボリックリンクを切り替えることで新しいアプリケーションをリリースする方法です。 リリースするものや状況によっては再起動が発生することになります。
>
> [![img](https://4.bp.blogspot.com/-ebgdam6cezU/W_jILowPlcI/AAAAAAAAEWg/YEhOA_kLJNAWT9kzsnECs0UhXygI0mWKwCPcBGAYYCw/s640/deploy-release-02.png)](https://4.bp.blogspot.com/-ebgdam6cezU/W_jILowPlcI/AAAAAAAAEWg/YEhOA_kLJNAWT9kzsnECs0UhXygI0mWKwCPcBGAYYCw/s1600/deploy-release-02.png)
>
> ## インプレースデプロイ (In-Place Deployment)
>
> 稼働中サーバーに対して直接新しいアプリケーションを配置、再起動してしまう方法です。
>
> [![img](https://1.bp.blogspot.com/-h1f9nH22N_M/W_jILpJJWhI/AAAAAAAAEWk/RGA657OuzosXKHdUk7oNj12NpPXKEXMqACPcBGAYYCw/s640/deploy-release-03.png)](https://1.bp.blogspot.com/-h1f9nH22N_M/W_jILpJJWhI/AAAAAAAAEWk/RGA657OuzosXKHdUk7oNj12NpPXKEXMqACPcBGAYYCw/s1600/deploy-release-03.png)
>
> ## ブルー/グリーンデプロイ (Blue/Green Deployment)
>
> 稼働中サーバー（ブルー）とは別のサーバー（グリーン）に対して新しいアプリケーションを展開し、動作確認を行います。 動作確認が問題なければ
>
> [![img](https://2.bp.blogspot.com/-TkwOa41aA0U/W_jIMnA3LaI/AAAAAAAAEWs/p3bn8pTgzsEPaW65CDcK5ySfiX_DwOskgCPcBGAYYCw/s640/deploy-release-04.png)](https://2.bp.blogspot.com/-TkwOa41aA0U/W_jIMnA3LaI/AAAAAAAAEWs/p3bn8pTgzsEPaW65CDcK5ySfiX_DwOskgCPcBGAYYCw/s1600/deploy-release-04.png)
>
> ## イミュータブルデプロイ (Immutable Deployment)
>
> ブルー/グリーンデプロイに似ていますが、リリース後に旧環境を消してしまう点が異なります。 稼働中サーバーとは別の新しい環境に新しいアプリケーションをデプロイしてテストし、問題なければ新環境に切り替えを行い、旧環境は削除してしまいます。 ロールバックする場合も新環境に古いアプリケーションをリリースして切り替える方法を取ります。
>
> [![img](https://2.bp.blogspot.com/-5tlB8_R7tyU/W_jIMmsmS_I/AAAAAAAAEWw/VOQ-t8Lp4qoiBKVra9hyqgaNWYKNnPZiQCPcBGAYYCw/s640/deploy-release-05.png)](https://2.bp.blogspot.com/-5tlB8_R7tyU/W_jIMmsmS_I/AAAAAAAAEWw/VOQ-t8Lp4qoiBKVra9hyqgaNWYKNnPZiQCPcBGAYYCw/s1600/deploy-release-05.png)
>
> ## ローリングデプロイ (Rolling Deployment)
>
> 複数の稼働中サーバーに対して一定数づつ新しいアプリケーションをデプロイ、リリースしていく方法です。 デプロイする方法は、「稼働中サーバーを一部切り離してデプロイを行い、再びオンラインに戻すを繰り返す方法（インプレースデプロイ）」と 「新しい環境にデプロイして古い環境から切り替え、古い環境は削除するを繰り返す方法（イミュータブルデプロイ）」があります。
>
> [![img](https://4.bp.blogspot.com/-hIpckI88Bmc/W_jIMwHc6GI/AAAAAAAAEW0/vWlSMbc_Ha8kdXS1J-17VxFqDg1RP-2nACPcBGAYYCw/s640/deploy-release-06.png)](https://4.bp.blogspot.com/-hIpckI88Bmc/W_jIMwHc6GI/AAAAAAAAEW0/vWlSMbc_Ha8kdXS1J-17VxFqDg1RP-2nACPcBGAYYCw/s1600/deploy-release-06.png)
>
> ## カナリアデプロイ (Canary Deployment)
>
> 稼働中サーバーの一部だけに新しアプリケーションをデプロイ、リリースする方法です。 特定のユーザーだけに新しいアプリケーションを利用してもらうことで新サービスの検証ができます。 デプロイする方法は問わず、デプロイ先の数だけに注目したデプロイ方法です。
>
> [![img](https://2.bp.blogspot.com/-9cdU-sVVNHM/W_jINJCfiLI/AAAAAAAAEW4/BiZKzjtRAloWsy2EBamY8BifQdlEkWVagCPcBGAYYCw/s640/deploy-release-07.png)](https://2.bp.blogspot.com/-9cdU-sVVNHM/W_jINJCfiLI/AAAAAAAAEW4/BiZKzjtRAloWsy2EBamY8BifQdlEkWVagCPcBGAYYCw/s1600/deploy-release-07.png)
>
> 今回は「アプリケーションのデプロイ・リリース手法」についてまとめました。 ポイントは以下の通りです。
>
> - 「手法」「戦略」「対象」に整理してデプロイ方法を考える



#### CloudFormation

- カスタムリソース
  - スタック作成時にLambda関数を実行して追加の処理を入れることができる

- ヘルパースクリプト

  - スタック内のEC2インスタンスの構築・変更等を便利にする機能

  - 以下の4種類がある

    - > **cfn-init**: リソースメタデータの取得と解釈、パッケージのインストール、ファイルの作成、およびサービスの開始で使用します。
      > **cfn-signal**: CreationPolicy または WaitCondition でシグナルを送信するために使用し、前提となるリソースやアプリケーションの準備ができたときに、スタックの他のリソースを同期できるようにします。
      > **cfn-get-metadata**: 特定のキーへのリソースまたはパスのメタデータを取得するために使用します。
      > **cfn-hup**: メタデータへの更新を確認し、変更が検出されたときにカスタムフックを実行するために使用します。

    - [参考](AWS CloudFormation cfn-init を使ってみる https://www.ecomottblog.com/?p=9275)

- Lambdaによるカスタムリソースの作成

  - [こちら](CloudFormationで提供されていない処理をカスタムリソースで作ってみた。 | DevelopersIO https://dev.classmethod.jp/articles/cfn-api-custom/)が分かりやすい。要するに提供されていないリソース操作等をLambda使って自由にできるよってこと。

- StackSets

  - [こちら](https://zenn.dev/mn87/articles/479df996045a8d)を参照

  > ## 概要
  >
  > - 複数のアカウントおよびリージョンのスタックを 1 度のオペレーションで、作成、更新、削除できるようにすることで、スタックの機能を拡張
  > - 管理者アカウントを使用して、AWS CloudFormation テンプレートを定義および管理
  > - 指定のリージョンの選択されたターゲットアカウントにスタックをプロビジョニングする基盤としてテンプレートを使用
  >   ![image.png](https://res.cloudinary.com/zenn/image/fetch/s--T1To1OlK--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_1200/https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1162215/32bacea4-fc3e-f678-6930-ff29e1447d4a.png)
  >
  > スタックセットを使用することで、複数アカウントや複数リージョンにまたがってスタックの作成などができるようです。
  > 作成条件は管理者アカウントであることみたいですね。
  >
  > ## 用語
  >
  > - 管理者アカウント
  >   - スタックセットを作成する AWS アカウント
  > - ターゲットアカウント
  >   - スタックセットの 1 つ以上のスタックを作成、更新、削除するアカウント
  >   - スタックセット作成前に管理者アカウントとターゲットアカウント間で信頼関係の構築が必要
  > - スタックセット
  >   - 1 つの AWS CloudFormation テンプレートを使用して、複数のリージョンの AWS アカウントにスタックを作成できる
  >   - 各スタックに含まれるリソースはすべて、スタックセットの AWS CloudFormation テンプレートで定義
  >   - スタックセットを定義したら、指定したターゲットアカウントやリージョンでスタックを作成、更新、削除できる
  >   - スタックセットはリージョンのリソース
  >   - 1 つのリージョンでスタックを作成した場合、他のリージョンでそのスタックを表示または変更することはできない
  > - スタックセットのアクセス許可モデル
  >   - スタックセットは、セルフマネージド型のアクセス許可またサービスマネージド型のアクセス許可のいずれかを使用して作成
  >   - セルフマネージド型アクセス許可を使用する場合、アカウントとリージョン間でデプロイするために StackSets で必要な IAM ロールを作成
  >   - サービスマネージド型のアクセス許可を使用する場合、AWS Organizations が管理するアカウントにスタックインスタンスをデプロイ
  >   - サービスマネージド型の場合、ユーザーに代わって StackSets が IAM ロールを作成するため、IAM ロールの作成は不要
  > - スタックインスタンス
  >   - リージョン内のターゲットアカウントのスタックへのリファレンス
  >   - スタックインスタンスは、スタックがなくても存在することができる
  >   - スタックインスタンスに関連付けられるスタックセットは、1 つのみ
  >     ![image.png](https://res.cloudinary.com/zenn/image/fetch/s--HyiUZq4D--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_1200/https://qiita-image-store.s3.ap-northeast-1.amazonaws.com/0/1162215/249356d6-291e-df23-b190-c433ca091a16.png)
  >
  > 管理者アカウントはOrganizationsのマスターアカウントとは限らないようですね。
  > ある組織で複数のアカウントを管理するためのアカウントなので、必ずしもOrganizaionsを利用する必要はないようです。
  >
  > スタックインスタンスは、でテンプレートであるスタックセットが実際に展開されたスタックのことを指しているんでしょうか？
  > リファレンス(参照)なので、そのスタックへのパスみたいな概念とも捉えられます。そうだとすれば、スタックがなくてもパスは存在するという説明も納得できます。



### AWS Organization

SCPとOUの概念はざっくり把握すること。以下がおすすめ。

- https://youtu.be/PYuuzbtT9tw
- [AWS Organizations] SCP(サービスコントロールポリシー)の継承の仕組みを学ぼう | DevelopersIO https://dev.classmethod.jp/articles/organizations-scp-inheritance/



メリット

- SCPによるOU単位のセキュリティ設定
- 一括請求による請求管理の簡易化とディスカウントオプションの適用



- SCPを使用するためには、<u>Organizationで**すべての機能を有効にする必要がある**。</u>一括請求のみが必要な場合はすべての機能を有効にする必要はない。OUには継承以外に1つ以上のSCPを直接アタッチするすることが必要。例えば、AWSFullAccessの直接アタッチがあったが、それを外して予約拒否ポリシーのみにした場合、検証OUは何もできないアカウントのためのOUになる。継承は上位で許可されている権限範囲で、その範囲のうち<u>**何を許可するかをOUへの直接アタッチで定義する**</u>。

- **<u>Firewall Managerでは、Organizationsですべての機能を有効化し、管理者アカウントを設定し、Configを有効化することが必要。</u>**そして、WAFポリシー、Shield Adbancedポリシー、セキュリティグループポリシー、Network Firewallポリシー、DNSファイアウォールポリシーをそれぞれ必要に応じて設定する。



※SCPとIAMポリシーって何が違うねん、みたいな感じになりますが、SCPは権限をあたえるというよりは、権限の境界を指定するもので、以下のようにSCPで設定した境界でポリシーは制約を受けることになります。

![img](https://cdn-ak.f.st-hatena.com/images/fotolife/g/guri2o1667/20210808/20210808143258.png)



### AWS Control Tower

[こちら](https://www.ragate.co.jp/blog/articles/9061)がわかりやすい。

[AWS公式の動画](https://www.youtube.com/watch?v=doF6NTgnBCE)もおすすめ。



> ## はじめに
>
> ### AWS Control Towerとは
>
> AWS Control Tower とは、AWS のマルチアカウントの環境を一元的にセットアップ・管理するサービスです。マルチアカウント管理に必要なランディングゾーン（AWS Control Tower が設定する総合的なマルチアカウント環境）の構築や各種ガードレールの展開、権限のセットアップなどを行います。
>
> ### AWS Control Towerで自動構築されるAWSリソースとその概要
>
> AWS Control Tower は、下記のような設計図を利用し、ランディングゾーンを自動化します。
>
> - AWS Organizations を使用したマルチアカウント環境
> - AWS Single Sign-On (SSO) のデフォルトのディレクトリを使用したID管理
> - AWS SSO を使用してアカウントにフェデレーティッドアクセスを提供
> - AWS CloudTrail のログや、Amazon S3 に保存される AWS Config のログの集中管理
> - AWS IAM および AWS SSO を使用してクロスアカウントセキュリティ監査を有効化
>
> ## AWS Control Towerのメリットとユースケース
>
> ### AWS Control Towerのメリット
>
> AWS Control Tower のメリットは、マルチアカウントの統制を簡単かつ安全に行えることです。アカウントを複数管理する際に問題となるのが、アカウントの統制方法。設定をマルチアカウントに適用させようとすると、コストやセキュリティ面でさまざまな課題が生まれるため、エンジニアが頭を抱えることも多いです。
>
> しかし、AWS Control Tower では AWS 環境の管理を自動化できます。手間を省いて簡単にアカウントを管理できることから、エンジニアの中で注目を集めています。
>
> また、AWS Control Tower では「ガードレール（セキュリティ、オペレーション、コンプライアンス向けにパッケージ化されたガバナンスルール）」の設定により、違反行為の検出が可能です。これらの機能はアカウントの新規作成時や既存のアカウント変更時にも常に有効化されるため、設定変更等の面倒な手間なく利用することができます。
>
> このように、AWS Control Tower は従来のマルチアカウント統制における課題を解決することができます。AWS Control Tower の使用によって、簡単かつ安全なマルチアカウント統制を実現できます。特にガードレールによる違反予防・検出はかなり強力なため、エンジニアからもリスク軽減に役立つとの声が上がっています。
>
> ### AWS Control Tower のユースケース
>
> - マルチアカウント環境の設定と管理
>
> ベストプラクティスの設計図に基づき、マルチアカウント構造を設定します。
>
> - 事前設定されたガードレールで大規模なガバナンス
>
> 選別されたガバナンスルールを有効化します。セキュリティ、オペレーション、コンプライアンスに関するポリシーを、アカウントに適用することができます。



予防ガードレールと検出ガードレール、ログ集約アカウント、監査アカウント、AWS SSO連携などマルチアカウントの組織におけるベストプラクティスを自動でかんたんに作成できるOrganizationと連携したサービス。



##### ガードレールとは?

利⽤者を守るためのメカニズム、やってはいけない操作を未然に防ぐ（予防的統制）や逸脱を検知する（発⾒的統制）から構成される。

- 予防的ガードレール
  - 対象の操作を実施できないようにするガードレール
  - Organizations Service Control Policy(SCP) で実装
- 発⾒的ガードレール
  - 望ましくない操作を⾏なった場合、それを発⾒するガードレール
  - 管理しつつ開発のスピードを上げるために効果的
  - AWSConfigRulesで実装



#### Service Catalog

[こちら](AWS Service Catalogってなんだろ？ https://zenn.dev/mn87/articles/bae96f423a94f5)を一読すると良い。

システム管理者が使っていいよっていうサービス(例えばCloud Formation のテンプレ)をシステム管理者が設定した権限(IAM)で起動することができる。



4つの概念

- 製品
  - CloudFormationテンプレートをパッケージ化したもの
  - EC2やストレージ、DBなどの1つ以上のAWSリソースからなる
  - バージョン管理が可能
- ポートフォリオ
  - 製品の集合
  - ポートフォリの単位でユーザーに製品の仕様を許可
  - 製品の使用方法の管理も可能
  - ポートフォリオを他のAWSアカウントに共有することも可能
- 制約
  - 製品のデプロイ方法を制御
  - 3つの制約
    - テンプレート制約
    - 起動制約
    - 通知制約
- プロビジョニングされた製品
  - サービスカタログからデプロイされたインスタンスの実態

Service Catalogを使用することでエンドユーザーにはService Catalogのポートフォリオ製品の利用権限だけとなり、それにより起動するリソースへの直接的な権限は適用されない。EC2やRDS等をコントロールしたいわけではないのであれば最小権限でアドバイスレポートなどの作成が可能となる。



#### 特定用途向けサービス

##### Outposts

データを特定の場所に保存する必要があり、そのデータに最も近い場所でサービスを実行しなければならない場合に使われる。



[こちら]()では以下のように書かれています。

> AWS Outpostsとは、自社のデータセンターや自社拠点にAWSのラック、またはサーバーを設置して、AWSを自社のオンプレミスサーバーのように拡張して使えるというサービスです。
>
> このサービスを利用することによって、AWSのクラウドと超低レイテンシーで接続できるなどのメリットが生まれます。一言でいえば、”オンプレミス版のAWS”です。
>
> ![aws outposts イメージ図](https://atbex.attokyo.co.jp/files/news2/Blog/aws_outposts/outposts.png)

##### Wavelength

5Gネットワークの通信事業者のネットワークへの直接送受信が可能。

##### Local Zones

リージョンの拡張でユーザーに近い場所を選択できる可能性がありますが、番地などはリージョン同様に更改されません。

[こちら](https://dev.classmethod.jp/articles/aws-local-zones-feature/)では以下のように記載があります。

>上記の通り、このサービスは AWS に対して超低レイテンシ通信を実現するものです。
>
>そのため、**レイテンシに敏感なアプリケーションやサービス、ワークロードがターゲット**となります。
>
>
>
>## Outposts との違いは？
>
>似たサービスとして、同様にAWS re:Invent 2019 のキーノートにて発表された [Outposts](https://dev.classmethod.jp/cloud/aws/aws_outpost_launch_partner_reinvent2019/) があります。
>
>Local Zones との大きな違いは、「**インフラをユーザが管理するかどうか**」になります。
>
><u>**Outposts は AWS から提供されるハードウェアを自社施設に配置する事に対し、Local Zones は AWS が展開しているインフラを使用するため、従来と同じような感覚で使う事が出来ます。**</u>
>
>ハードウェアを自社施設に配置できない場合などに Local Zones が選択されることになるかと思います。





### 耐障害性

#### マイクロサービスのエラーやボトルネックの抽出

X-Rayが最適。サービスマップで指定した期間のエラー、スロットリング、呼び出し平均時間を確認できる。個別のトレース情報へのドリルダウンも可能。監視対象のアクションが厳密に限定されていなくても、SDKのパッチ適用を使用することでサポートしている呼び出しやライブラリに対応できるので、AWSサービスの呼び出し、AWS外のAPI呼び出し、SQLリクエストなどのトレースをプログラムからX-Rayに送信して統計情報を確認できる。	



#### EC2のリタイアについて

- リタイアとは、[こちら]()に記載のあるとおり。

  > リタイア通知とは、インスタンスをホストしている基盤のハードウェアで回復不可能な障害が検出されたときに通知されます。
  > 予定されたリタイア日になると、インスタンスは AWS によって停止または削除されますので、対応は必須になります。

- 対応としては対象インスタンスを停止して起動し直す。

- 自動化する場合、
  - **<u>EventBridgeのイベントルールでeventTypeCodeにAWS_EC2_PERSISTENT_INSTANCE_RETIREMENT_SCHEDULEDを設定する</u>**
  - <u>**対象にSystem Manager AutomationのAWS-RestartEC2Instanceを指定する**</u>
    - パラメーターのInput Transformerに{"Instances": "$.resources"}, {"InstanceId": <Instances>}を指定する
  
- ステートフルなアプリでは、EBSボリュームを保持しなければならないため、EC2インスタンスを停止、開始することで対応できる。AMIから起動できればよいので、Auto Scalingグループで必要数のインスタンスを保持する構成も考えられる。



#### EC2のバックアップとリカバリ

[こちら](https://docs.aws.amazon.com/ja_jp/prescriptive-guidance/latest/backup-recovery/restore.html)を参照。

> リカバリ時間を短縮し、依存するアプリケーションやプロセスへの影響を軽減するには、リストアプロセスで置き換えるリソースを考慮する必要があります。最良の結果を得るには、低い環境（非実稼働環境など）でリストアプロセスを定期的にテストし、プロセスが目標復旧時点（RPO）と目標復旧時間（RTO）を満たしていること、およびリストアプロセスが期待どおりに機能することを確認します。リストアプロセスが、リストアするインスタンスに依存するアプリケーションおよびサービスにどのように影響するかを検討し、必要に応じてリストアを調整してください。リストアプロセスの失敗や実装の一貫性のないリスクを軽減するために、リストアプロセスを可能な限り自動化してテストしてください。
>
> Amazon EBS スナップショットからのデータは、EBS ボリュームに非同期的にロードされます。データがロードされていないボリュームにアプリケーションがアクセスすると、Amazon S3 からデータがロードされる間、通常よりも長いレイテンシーが発生します。レイテンシの影響を受けやすいアプリケーションでこの影響を回避するために、スナップショットからデータを事前ウォーミングして EBS ボリュームにすることができます。追加料金については、Amazon EBS がサポートしています。[高速スナップショット復元](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-fast-snapshot-restore.html)。これにより、データの事前ウォーミングの必要性が軽減されます。



#### 会社を跨いだDBデータの受け渡し

A(事業会社)のシステムをB(開発・運用会社)が運用している。システムのRDB(Aurora DB)のデータをBの検証環境に移したい場合、Aurora MySQLのスナップショットを取得し、BのAWSアカウントに共有する。KMSマスターキーのキーポリシーでBが複合を行えるように権限設定する。





### 運用管理、セキュリティ

全体像は[こちら](https://pages.awscloud.com/rs/112-TZM-766/images/20210224_2th_ISV_DiveDeepSeminar_Security.pdf)を一読ください。

![スクリーンショット 2022-12-12 14.26.17](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-12 14.26.17.png)

- VPCフローログとトラフィックミラーリングの違いは[こちら](【AWS入門】仮想ネットワークのAmazon VPCとは？アクセス制御の仕組みと料金 | よくわかるAWS・クラウド https://cloudnavi.nhn-techorus.com/archives/3893)。

  - > VPCフローログ
    > VPCフローログとは、VPCのデータトラフィックを監視する機能です。VPC内のネットワークインターフェイスとの間のIP トラフィックに関する情報をキャプチャできます。VPCフローログを取るには、ログを作成したいリソース、キャプチャするトラフィックの種類（許可、拒否、もしくはすべてのトラフィック）、フローログデータを発行する送信先（Amazon CloudWatch LogsまたはAmazon S3）を設定します。VPCフローログを参照すると、セキュリティグループのルールの制限が厳しすぎないか、適切かなどの判断が容易になります。
    >
    > Amazon VPC トラフィックミラーリング
    > Amazon VPC トラフィックミラーリングとは、Amazon VPC内のAmazon EC2インスタンスからのネットワークトラフィックを複製し、そのトラフィックをセキュリティおよび監視アプライアンスに転送できる機能です。これによってコンテンツ検査、脅威の監視、トラブルシューティングといった作業が容易になります。

  - VPCフローログはTCP/IP層。それ以上の層はトラフィックミラーリング。

  - トラフィックミラーリングはIDSとかIPSにパケットをコピーして流しセキュリティを高めることができる。

  - EC2作成時にタグ付けを強制する方法は[こちら](EC2作成時、タグ付けを強制する方法 - サーバーワークスエンジニアブログ https://blog.serverworks.co.jp/2019/11/22/000000)。
  
    > # 結論
    >
    > 結論から先に書くとIAMポリシーを利用することで
    > EC2へのタグ付けを強制することができます！
    > （タグを付与しないとEC2を作成できないようにする感じです。）
    >
    > ◆参考）
    > [　https://aws.amazon.com/jp/premiumsupport/knowledge-center/iam-policy-tags-restrict/](https://aws.amazon.com/jp/premiumsupport/knowledge-center/iam-policy-tags-restrict/)
    >
    > # 検証
    >
    > ここからは、実際に検証していきます。
    > 検証の流れは、以下の通りです。
    >
    > ◆流れ
    > 　①IAMポリシーの作成
    > 　②IAMユーザの作成＆ポリシーのアタッチ
    > 　③動作確認
    > 　　パターン１）タグを付与して、EC2を作成
    > 　　パターン２）タグを付与せずに、EC2を作成
    >
    > # 前提条件
    >
    > ・EC2を展開するサブネットが用意されていること
    > ・セキュリティグループが作成されていること
    > ・キーペアが作成されていること
    > ・AWS CLIが利用できること
    >
    > # ①IAMポリシーの作成
    >
    > AWSマネジメントコンソールからIAMポリシーを作成します。
    > まずは、IAMの画面を開き、左側のナビゲーションペインで「ポリシー」を選択します。
    > その後、「ポリシーの作成」を選択します。
    >
    > ポリシーの作成画面が表示されたら、以下のイメージでポリシーを定義します。![img](https://cdn-ak.f.st-hatena.com/images/fotolife/s/serverworks/20200712/20200712003433.png)
    >
    > ### ポリシー定義
    >
    > ```
    > {
    >     "Version": "2012-10-17",
    >     "Statement": [
    >         {
    >             "Sid": "AllowRunInstancesWithRestrictions",
    >             "Effect": "Allow",
    >             "Action": [
    >                 "ec2:CreateVolume",
    >                 "ec2:RunInstances"
    >             ],
    >             "Resource": [
    >                 "arn:aws:ec2:*:*:volume/*",
    >                 "arn:aws:ec2:*:*:instance/*"
    >             ],
    >             "Condition": {
    >                 "ForAnyValue:StringEquals": {
    >                     "aws:TagKeys": [
    >                         "Name"
    >                     ]
    >                 }
    >             }
    >         },
    >         {
    >             "Sid": "VisualEditor1",
    >             "Effect": "Allow",
    >             "Action": "ec2:CreateTags",
    >             "Resource": [
    >                 "arn:aws:ec2:*:*:instance/*",
    >                 "arn:aws:ec2:*:*:volume/*"
    >             ],
    >             "Condition": {
    >                 "StringEquals": {
    >                     "ec2:CreateAction": "RunInstances"
    >                 }
    >             }
    >         },
    >         {
    >             "Sid": "VisualEditor2",
    >             "Effect": "Allow",
    >             "Action": "ec2:Describe*",
    >             "Resource": "*"
    >         },
    >         {
    >             "Sid": "VisualEditor3",
    >             "Effect": "Allow",
    >             "Action": "ec2:RunInstances",
    >             "Resource": [
    >                 "arn:aws:ec2:*:*:subnet/*",
    >                 "arn:aws:ec2:*:*:key-pair/*",
    >                 "arn:aws:ec2:*::snapshot/*",
    >                 "arn:aws:ec2:*:*:security-group/*",
    >                 "arn:aws:ec2:*:*:network-interface/*",
    >                 "arn:aws:ec2:*::image/*"
    >             ]
    >         }
    >     ]
    > }
    > ```
    >
    > ポリシーを定義できたら、ポリシーの「名前」と「説明」を入力して、ポリシーを作成します。
    > 今回は、「test-policy」にしました。
    >
    > ![img](https://cdn-ak.f.st-hatena.com/images/fotolife/s/serverworks/20200712/20200712003438.png)
    >
    > # ②IAMユーザの作成＆ポリシーのアタッチ



- LinuxでのSSHをやめてSSMにする場合。
  - [こちら](https://dev.classmethod.jp/articles/session-manager-launches-tunneling-support-for-ssh-and-scp/)参照。EC2インスタンスにSSMエージェントがインストールされている必要がある。またEC2インスタンスがSSMサービスへ通信出来る必要がある。またIAMロールにAmazonSSMManagerInstanceCoreポリシーをアタッチし、IAMユーザーはセッションマネージャを使用できるようにポリシー追加する。



#### そもそもSSM(AWS Systems Manager)とは

公式には以下のように記載がある。

> AWS Systems Manager は、ハイブリッドクラウド環境のための安全なエンドツーエンドの管理ソリューションです。
>
> [![img](https://d1.awsstatic.com/AWS%20Systems%20Manager/product-page-diagram-AWS-Systems-Manager_how-it-works.e9ba8cbeff1249c8cc24db4737d03648a1a073f6.png)](https://aws.amazon.com/jp/systems-manager/#)

[こちら](https://blog.serverworks.co.jp/tech/2020/04/16/systems_manager_yattemiyou/)がわかりやすかった。

> AWS SSMを用いることで、オンプレミス／AWS両環境で運用に必要な作業を、実施することができます。
>
> ・リソース状況の可視化
>
> ・定型作業の実施
>
> ・インタラクティブな操作
>
> ・アプリケーションの設定管理

> SSMでやれること
>
> 大きく6つに分かれています。
>
> [全体]
>
> - 高速セットアップ：インスタンスをSSMで管理するよう自動構成
>
> [運用管理]
>
> - エクスプローラー(Explorer)：運用アイテム情報のダッシュボード
> - OpsCenter：運用アイテム（対応が必要なイベント）の管理
> - CloudWatch ダッシュボード：CloudWatch用のダッシュボードをカスタマイズ
> - Trusted Advisor と PHD：Trusted Advisor と Personal Health Dashboard のダッシュボード
>
> [アプリケーション管理]
>
> - リソースグループ(Resource Groups)：タグによるサーバー群のグループ管理
> - AppConfig：アプリケーション設定（機能グラフ等）の管理
> - パラメータストア：設定パラメータの集中管理用データストア
>
> [アクションと変更]
>
> - 自動化(Automation)：AWS環境全体に対する自動化処理の実行
> - カレンダーの変更(Change Calendar)：実行可否を制御するカレンダー
> - メンテナンスウィンドウ：自動化処理のスケジュールと順序の管理
>
> [インスタンスとノード]
>
> - コンプライアンス(Configuration Compliance)：コンプライアンスの適合状態ダッシュボード
> - インベントリ(Inventory Management)：サーバー構成情報のインベントリを閲覧する
> - マネージドインスタンス(Managed Instance)：SSM管理対象のサーバー群
> - ハイブリッドアクティベーション(Activations)：オンプレミスサーバーをSSM管理下に入れる
> - セッションマネージャー(Session Manager)：SSMを使ったサーバーへリモートアクセスする
> - Run Command：サーバー群の上でコマンドを実行する
> - ステートマネージャー(State Management)：サーバー群の構成を指定した状態に維持する
> - パッチマネージャー(Patch Mangement)：サーバー群に指定ルールに基づきパッチを適用する
> - ディストリビューター(Distributor)：サーバー群にパッケージをインストールする
>
> [共有リソース]
>
> - ドキュメント(System Manager Documents)：SSMで実行する処理を記述したドキュメント

> SSMを使うためには、当該リソースを「マネージドインスタンス」(SSMで管理されたインスタンスのこと)にする必要があります。そのためには、以下の3 Stepが必要です。
>
> - SSM Agentの導入
> - SSM AgentからSSM APIへの経路確保
> - IAMロールの付与



特定のEC2インスタンスに特定のパッチを除外して、他の必要なパッチを適用する場合は、パッチマネージャでベースラインを設定し、対象のEC2インスタンスにタグを設定しRunCommandを実行することで対応できる。



[BlackBelt](https://www.youtube.com/watch?v=UXSbh4Wsp7c)にも目を通しておくと良い。

> ![スクリーンショット 2022-12-24 21.23.34](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.23.34.png)
>
> ![スクリーンショット 2022-12-24 21.25.23](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.25.23.png)
>
> ![スクリーンショット 2022-12-24 21.26.55](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.26.55.png)
>
> ![スクリーンショット 2022-12-24 21.27.21](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.27.21.png)
>
> ![スクリーンショット 2022-12-24 21.28.45](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.28.45.png)
>
> ![スクリーンショット 2022-12-24 21.30.05](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.30.05.png)
>
> ![スクリーンショット 2022-12-24 21.30.41](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.30.41.png)
>
> ![スクリーンショット 2022-12-24 21.34.37](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.34.37.png)
>
> ![スクリーンショット 2022-12-24 21.41.35](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.41.35.png)
>
> ![スクリーンショット 2022-12-24 21.42.09](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.42.09.png)
>
> ![スクリーンショット 2022-12-24 21.42.57](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.42.57.png)
>
> ![スクリーンショット 2022-12-24 21.44.02](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.44.02.png)
>
> ![スクリーンショット 2022-12-24 21.48.33](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.48.33.png)
>
> ![スクリーンショット 2022-12-24 21.50.51](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.50.51.png)
>
> ![スクリーンショット 2022-12-24 21.52.00](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.52.00.png)
>
> ![スクリーンショット 2022-12-24 21.52.37](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.52.37.png)
>
> ![スクリーンショット 2022-12-24 21.53.29](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-24 21.53.29.png)

##### オンプレとクラウドのハイブリッド運用におけるEFSのセキュアな共有について

オンプレミスのLinuxサーバーとVPC内のEC2で共通のファイルシステムを使う場合において、オンプレからはデータ転送を暗号化する必要がある際には、

- データの暗号化は amazon-efs-utils(EFSマウントヘルパー)をインストールして、マウントヘルパーコマンドに -o tls オプションをつけてマウントする
  - この際、ファイルシステムIDを指定するので、名前解決ができている必要がある
  - マウントヘルパーではIPアドレスの指定はできない
  - efs-utils.confを調整する必要がある
  
    - 以下を[参照](https://dev.classmethod.jp/articles/efs-mount-helper/)。
  
    - > マウントヘルパーには、EFSのログ記録が組み込まれています。
      >
      > ```bash
      > $ ll /var/log/amazon/efs
      > total 4
      > -rw-r--r--. 1 root root 921 Oct 25 02:27 mount.log
      > ```
      >
      > なお、ログの出力先やサイズの指定は`/etc/amazon/efs/efs-utils.conf`で設定が可能です。 設定を確認してみると、ログの最大サイズが制限されているようなので、ログローテ等でケアする必要がなさそうです。



##### オンプレとクラウドのハイブリッド運用で、オンプレ側の監視システムでパフォーマンスの統合管理がしたい、監視システムはクラウド側からは特定の1つのIPアドレスからのみアクセスできるといった状況の場合

クラウド側はLambdaからNATゲートウェイのElastic IPでIPを固定して、そこ経由でオンプレの監視システムにデータを送信する。EC2のステータス変更は、EventBridgeのルールで設定する。パフォーマンス情報はCloudWatchメトリクスデータをGetMetricData APIアクションを実行して送信する。

EC2のステータス変化に対するCloudWatchアラームは存在しない。



#### GuardDuty

[こちら](https://www.wafcharm.com/blog/amazon-guardduty-for-beginners/)参照。

> Amazon GuardDutyの特徴を簡単にまとめると以下のとおりです。
>
> 1. AWS環境やAWSアカウントのセキュリティ状況をモニタリングおよび通知してくれるサービス
> 2. 複雑な設定は不要。AWS上で有効化するだけでOK
> 3. 機械学習で分析されたログから攻撃と思われる状況を検知してくれる
> 4. 安価な課金制で、気兼ねなく利用できる
>
> つまり、AWS環境やAWSアカウントのセキュリティ全般の攻撃を検知してくれるソリューションがGuardDutyということなのです。



##### GuardDutyでルートユーザーの認証が行われた際に通知する

[こちら](https://dev.classmethod.jp/articles/guardduty-rootaccount/)を参照。

> [GuardDutyを有効](https://dev.classmethod.jp/cloud/aws/guardduty-cfn-template-set-sns/)にし、ルートアカウントでAWSコンソールに接続します。GuardDutyコンソールをみると、「Policy:IAMUser/RootCredentialUsage」が作成されたことがわかります。

> GuardDutyで検知すると、CloudWatch Eventsが発火するため、SNSで通知したり、LambdaでSlackに通知できます。
>
> ルートアカウントの利用が認められた場合、どのような操作が行われたのか確認したくなるかと思います。CloudTrailログをS3に出力している場合は、Athenaで解析できます。まずは、Athenaのテーブルを作成します。CloudTrailコンソール＞イベント履歴＞"Amazon Athena で高度なクエリを実行します"を選択します。

CloudTrailのログ集約と迅速な検索に対応するためには、ログを1つのアカウントに集約し、Athenaでデータのパーティションを分割するのがよい。

CloudTrailのログ改ざんを検知するためには、整合性検証オプションを有効にする。



#### AWS Shield

- Shield Advancedでは24H365DのDDoSレスポンスチーム(Shield Response Team: SRT)がいる



#### Amazon Inspector

脆弱性の検査が可能。(Inspcetorに限らずだが)大量のインスタンスにエージェントをインストールする場合はRun Commandで一気にインストールするのがおすすめ。検査結果をSNSトピックに通知し、Lambda関数で判定してからSSM Run CommandでOSの修復を行うことができる。



#### Cognitoで認証に成功したユーザーのみAPIの実行を許可する

API Gatewayにて実行の認可を与える仕組みはいくつがあるが、CognitoオーソライザーやLambdaオーソライザーを使うことで実現することができる。詳しくは[こちら](CognitoでAPI Gatewayのオーサライザーを作成しよう - Qiita https://qiita.com/tamura_CD/items/af9d732710436fc6de09)。

Lambdaオーソライザーは[こちら](API Gateway の Lambda オーソライザーをやってみた - Qiita https://qiita.com/sugimount-a/items/0079a79b94e442204d6f)参照。

> ![](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F1002774%2F82802855-87a5-3ed8-f3ed-e54ba02155b8.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&w=1400&fit=max&s=193c80b5583085948f5ef144d978ddd3)



#### AWS WAF、Network Firewall、Shiledの違い

[こちら](https://www.youtube.com/watch?v=f2UcwkGYUMQ)の動画がわかりやすい。

![スクリーンショット 2022-11-13 12.14.12](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-11-13 12.14.12.png)

セキュリティグループはENIにアタッチしてステートフル。ネットワークACLはVPNサブネットにアタッチしてステートレス。



Network Firewallについては[こちら](AWS Network Firewallのデプロイモデル | Amazon Web Services ブログ https://aws.amazon.com/jp/blogs/news/networking-and-content-delivery-deployment-models-for-aws-network-firewall/)を一読しておくとよい。

> Network Firewallを正しく動作させるためには、トラフィックをNetwork Firewallのエンドポイントに対称的にルーティングする必要があります。このエンドポイントは、AWS PrivateLink のInterface型エンドポイントに似ています。主な違いは、ルートテーブルのターゲットになることができるということです。Network Firewallのエンドポイントは、専用のサブネットにデプロイします。このサブネットをNetwork Firewall サブネットまたは単にFirewallサブネットと呼びます。ユースケースと展開モデルに応じて、Firewallサブネットはパブリックまたはプライベートのいずれかになります。高可用性（HA）およびマルチAZ展開の場合、アベイラビリティーゾーン（AZ）ごとにサブネットを割り当てます。ベストプラクティスとして、Firewallサブネットには他のサービスをデプロイしないでください。Firewall サブネット内にあるサービスに関連したトラフィックは、Network Firewallを通して検査することができません。
>
> ファイアウォールエンドポイントは、AWSコンソール上のVPCルートテーブルのターゲット選択画面においてvpce-idで表示されます。ファイアウォールエンドポイントはAWS Gateway Load Balancerを利用しているため、エンドポイントのElastic Network Interface（ENI）は「gateway_load_balancer_endpoint」タイプとなります。Network Firewallでネットワークトラフィックを検査するには、VPCのルートテーブルを適切に設定してトラフィックをファイアウォールエンドポイントに転送する必要があります。図1では、VPC Ingress Routing機能を使用して、ワークロードがあるサブネットとInternet Gateway（IGW）の間のパスにファイアウォールエンドポイントを挿入しています。この設定については、こちらの記事もご覧ください。

Suricata互換ルールでの検査をマネージドで提供するサービスはNetwork Firewall。例えば、VPCにパブリックサブネット、プライベートサブネットがあり、プライベートサブネットにアウトバウンドリクエストを実行しているEC2、パブリックサブネットにNATゲートウェイがある状況で追加の運用をなるべく抑えて検査を実施したいとう要件がある場合は以下のような手順となる。

- Network Firewallを作成し、VPCにFIrewallサブネットを追加して、FirewallエンドポイントをFirewallサブネットに配置する。Firewallサブネットに関連づくルートテーブルは送信先0.0.0.0/0をインターネットゲートウェイで設定する。
- インターネットゲートウェイにイングレスルートテーブルを設定して、送信先にパブリックサブネットのCIDR、ターゲットにFirewallエンドポイントを指定する。
- **<u>パブリックサブネットに関連づくルートテーブルの送信先0.0.0.0/0のターゲットにFirewallエンドポイントを指定する。</u>**



#### SSHの脆弱性による不正アクセス対策

- そもそも素の?SSHでのアクセスをやめる
- アクセスキーを直接使うことをやめる



セッションマネージャーを使ってアクセスキーを用いずにアクセスすることでセキュリティを高めることが可能。

[こちらを参照](セッションマネージャー越しにSSHアクセスすると何が嬉しいのか | DevelopersIO https://dev.classmethod.jp/articles/ssh-through-session-manager/)

> ## セッションマネージャーのメリットって何？
>
> 色々あります。
>
> ### IAMで認証・認可ができる
>
> セッションマネージャーはSSMの機能の一つなので、もちろんIAMによる権限制御ができます。以下が今回の構成を利用できるIAM Policyの一例です。
>
> ```javascript
> {
>     "Version": "2012-10-17",
>     "Statement": [
>         {
>             "Effect": "Allow",
>             "Action": "ssm:StartSession",
>             "Resource": [
>                 "arn:aws:ec2:*:*:instance/(インスタンスID)",
>                 "arn:aws:ssm:*:*:document/AWS-StartSSHSession"
>             ]
>         }
>     ]
> }
> ```
>
> そして今回の構成の場合、前述のとおり従来の鍵認証もそのまま使えます。IAM認証と鍵認証、二重で認証が可能です。
>
> 複数人の間での使いまわしを抑止するために、鍵認証に使うキーペアは人数分用意して設定するべきです。が、人の出入りの度に鍵の設定を変更するのは煩雑です。この構成ならIAM認証もできるので、（セキュリティポリシーによりますが、）キーペアは共有しても良いかもしれません。
>
> ### SSHポートへのインバウンドアクセス許可設定（いわゆるポート空け）が不要
>
> セッションマネージャーなしでSSHする場合、クライアントからインスタンスまでの経路を確保する必要があります。インスタンスへの22番ポートへのインバウンドアクセスをセキュリティグループなどで許可する必要があります。
>
> 今回のこのセッションマネージャー越しのSSHですと、クライアントとインスタンス間の通信は前述のとおりセッションマネージャーで行ないます。その際、インスタンスのインバウンドアクセス許可設定は何も必要ありません。（443番アウトバウント許可のみ必要です。SSM AgentがSSMエンドポイントに対してポーリング行なう際に使用します。）
>
> #### クライアントのIPを限定したい場合はどうするの？
>
> セッションマネージャーなしでSSHする場合、インバウンドセキュリティグループルールの送信元でCIDRを指定して、特定のIPからのみ接続許可できます。この方法は今回の構成では使えません。IP制限したい場合はどのようにすれば良いでしょうか？
>
> 前項の「IAMで認証・認可ができる」で書いたとおり、IAMで細かな認可設定ができます。Condition句でIPの条件をつければ良いです。
>
> ```javascript
> {
>     "Version": "2012-10-17",
>     "Statement": [
>         {
>             "Effect": "Allow",
>             "Action": "ssm:StartSession",
>             "Resource": [
>                 "arn:aws:ec2:*:*:instance/(インスタンスID)",
>                 "arn:aws:ssm:*:*:document/AWS-StartSSHSession"
>             ],
>             "Condition": {
>                 "IpAddress": {
>                     "aws:SourceIp": [
>                         "147.xx.xx.xx/32"
>                     ]
>                 }
>             }
>         }
>     ]
> }
> ```



##### IMDSとは

- Instance Metadata Serviceの略

- v1とv2がある

- [こちら](https://blog.serverworks.co.jp/tech/2019/11/27/imdsv2/)参照

- > - デフォルトではIMDSv1とIMDSv2の両方が使える状態
  >   - v1を無効化、またはv1とv2の両方を無効化することもできる
  > - IMDSv2ではメタデータへのアクセスの前に**セッショントークン**を取得する必要がある
  > - セッショントークンの取得はメタデータへの**HTTP PUT**リクエストで行う
  > - これにより以下の攻撃のリスクを下げられる
  >   - **設定に穴のあるWAF経由**での、メタデータを利用した攻撃
  >   - **設定に穴のあるリバースプロキシ経由**での、メタデータを利用した攻撃
  >   - **SSRF脆弱性を突いた**、メタデータを利用した攻撃
  >   - **設定に穴のあるL3ファイアウォール又はNAT経由**での、メタデータを利用した攻撃

  



##### そもそもインスタンスメタデータとは

[こちら](https://qiita.com/miyuki_samitani/items/be36df3ff41da4e3016a#:~:text=EC2%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%82%BF%E3%83%B3%E3%82%B9%E5%86%85%E3%81%8B%E3%82%89,%E3%81%99%E3%82%8B%E3%81%93%E3%81%A8%E3%81%8C%E5%87%BA%E6%9D%A5%E3%81%BE%E3%81%99%E3%80%82)参照

> EC2のインスタンス内からのみアクセスが可能なインスタンスに関するデータです。
> アクセスできるユーザであれば誰でも確認することが出来ます。



#### クロスドメイン対応

例えば、S3でWebホスティングしたページからAPI Gatewayをキックする場合、ドメインが異なることによってCORSポリシーに違反した旨のエラーがでることがある。

```
has been blocked by CORS policy: No ‘Access-Control-Allow-Origin’ header is present on the requested resource.
```

この場合、API Gateway側でCORSポリシーを有効にする必要がある。要するにこのURLからはリクエストに対するレスポンス返してもOKよ!と設定する。[こちら](https://noitalog.tokyo/api-gateway-cross-domain/#toc2)を参考に。



#### Security Hub

[こちら](https://dev.classmethod.jp/articles/lets-learn-aws-security-hub/)を参照。

> Q: AWS Security Hub とは何ですか?
>
> AWS Security Hub は、 **AWS 内のセキュリティの状態と、セキュリティ標準およびベストプラクティスに準拠しているかどうかを、包括的に把握** できるようにします。 Security Hub は、AWS のアカウント、サービス、サポート対象のサードパーティーパートナーの全体にわたって **セキュリティの検出結果を一元化および優先順位を設定** することで、セキュリティの傾向を分析し、最も重要なセキュリティの問題を特定します。

> Security Hub は以下を実施できるサービスです。
>
> - **セキュリティサービスの検出結果を一元管理**
> - **AWS内のセキュリティの状態を把握・評価**
>
> Security Hub は多くの AWSサービスと連携しています。図で表すと以下になります。
>
> ![img](https://d1tlzifd8jdoy4.cloudfront.net/wp-content/uploads/2020/08/blog.org_20200810_160057_HrLHOf.png)
>
> GuardDutyの脅威検知の結果や、Config ルールの準拠/非準拠の情報を 検出結果(Findings)という「統一されたフォーマットのデータ」に集約 します。 検出結果を Security Hub コンソールで確認できます。



#### git-secrets

[こちら](https://qiita.com/jqtype/items/9196e047eddb53d07a91)を参照。

> A: gitのcommit/commit message等をスキャンし、その中に事前設定した秘密情報が含まれていたら、そのcommitをリジェクトします。
>
> より正確には、
>
> - `git commit`時にそのcommitの中に、
> - 任意のタイミングで過去のgit historyの中に、
> - あるいは任意のタイミングで任意のファイルの中に、
>
> 事前設定された正規表現にマッチする情報が存在するか否かを検査します。awslabsが中心で開発しているだけあって、何よりもまず、AWSのcredentialの含まれたcommitを弾くのに非常に向いています。





### 節約

[AWS公式動画](https://www.youtube.com/watch?v=kCokuedsX0g)がおすすめ。

> ![スクリーンショット 2022-12-25 11.43.40](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 11.43.40.png)
>
> ![スクリーンショット 2022-12-25 11.50.27](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 11.50.27.png)
>
> ![スクリーンショット 2022-12-25 11.51.05](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 11.51.05.png)
>
> ![スクリーンショット 2022-12-25 11.51.20](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 11.51.20.png)
>
> ![スクリーンショット 2022-12-25 11.51.35](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 11.51.35.png)
>
> ![スクリーンショット 2022-12-25 11.51.50](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 11.51.50.png)
>
> ![スクリーンショット 2022-12-25 11.53.33](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 11.53.33.png)
>
> ![スクリーンショット 2022-12-25 11.54.18](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 11.54.18.png)
>
> ![スクリーンショット 2022-12-25 11.54.48](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 11.54.48.png)

#### リザーブドインスタンス(RI)

- キャパシティを事前予約する。前払いありにするとイニシャルコストが発生。スポットインスタンスと異なり停止することはない。

- もともとは購入するとすぐに有効になってしまったが、今は購入日指定(CLIだと日時も指定可能)でキューイング可能。[こちら](https://dev.classmethod.jp/articles/ec2-reserved-instance-on-future-date/)参照。

  > 通常のRIは購入するとすぐに有効化されますが、購入をキューイングして未来日時に有効化することができるようになりました。そのためRIの有効期限が切れるタイミングに有効化することで切れ目なくRIを適用することができます。
  >
  > マネージメントコンソールから購入する場合は日付のみで時刻を指定できない模様ですが、AWS CLIを使用して購入する場合は秒まで指定可能です。また、有効化する時刻より以前であればキャンセルが可能です。

- 買い方は[こちら](https://dev.classmethod.jp/articles/how-to-buy-reserved-instances/)を参照。

  > 購入時に以下を選択する必要があります。
  >
  > | 項目                                      | 選択肢                                                       |
  > | ----------------------------------------- | ------------------------------------------------------------ |
  > | プラットフォーム(Platform)                | Linux/UNIX / SUSE Linux / Red Hat Enterprise Linux / Windows / Windows with SQL Server Standard / Windows with SQL Server Web |
  > | アベイラビリティゾーン(Availability Zone) | ap-northeast-1a, ap-northeast-1c など                        |
  > | 借り方(Tenancy)                           | default(共有) / dedicated(専有)                              |
  > | インスタンスタイプ(Instance Type)         | t1.micro など                                                |
  > | 契約期間(Term)                            | 1month - 12month(1年) / 13month - 36month(３年)              |
  > | 支払方法(Offering)                        | No Upfront(前払いなし) / Partial Upfront(一部前払い) / All Upfront(全前払い) |

#### スポットインスタンス

- 使用料金を入札して安価に使用可能。需要に応じて値段が変わる。入札できないとインスタンスは停止する。
- 終了する2分前にメタデータに通知される。crontabなどでこれを監視し、アプリケーションの終了に備えることができる。



#### Saving Plans

[公式](https://aws.amazon.com/jp/savingsplans/compute-pricing/)に詳しい記載があります。

> Savings Plans は、1 年または 3 年の期間で、一貫したコンピューティング使用量 (USD/時間で測定) を契約する代わりに、Amazon EC2、AWS Lambda、AWS Fargate の低額の使用料金がオファーされる柔軟な料金モデルです。Savings Plan にサインアップすると、契約量までの使用料金は割引された Savings Plans 料金で課金されます。AWS が提供する Savings Plans には 2 つのタイプがあります。
>
> Compute Savings Plans
>
> Compute Savings Plans は、最も優れた柔軟性を提供し、コストを最大 66% 削減するために役立ちます。これらのプランは、インスタンスファミリー、サイズ、アベイラビリティーゾーン、リージョン、OS、またはテナンシーに関わらず EC2 インスタンスの使用に自動で適用されます。また、Fargate や Lambda を使用する場合にも適用されます。 例えば、Compute Savings Plans では、C4 インスタンスから M5 インスタンスへの変更、欧州 (アイルランド) から欧州 (ロンドン) へのワークロードのシフト、または EC2 から Fargate またはLambda へのワークロードの移動をいつでも行えます。Savings Plans の料金は、引き続き自動的に支払うことができます。
>
> EC2 Instance Savings Plans
>
> EC2 Instance Savings Plans は料金が最も低く、リージョン内の個々のインスタンスファミリーの契約 (例: バージニア北部で M5 の使用量) と引き換えに、最大 72% の節約を提供します。これは、アベイラビリティーゾーン、サイズ、OS、またはテナンシーに関わらず、そのリージョン内で選択されたインスタンスファミリーのコストを自動的に削減します。EC2 Instance Savings Plans は、そのリージョンのファミリー内におけるインスタンス間で使用量を変更する柔軟性を提供します。例えば、Windows を実行する c5.xlarge から Linux を実行する c5.2xlarge に移動しても、自動で Savings Plan 料金の恩恵を受けることができます。



#### S3オブジェクトに対してリクエストしたアカウントに請求する

- リクエスト側はx-amz-request-payerをリクエストに含める。リクエスト料金とデータ転送料金が請求される。
  - ストレージ料金はバケット所有アカウントに請求されることに注意
  - S3バケットでリクエスタ支払いを有効にしてもらうだけで良い
    - リクエストヘッダに上述の値が含まれない場合はリジェクトされる



#### コスト分析

##### Budgets

月ごとに予算が設定でき、着地予測ができる。コスト配分タグを使用することで施策ごとのBudgetsでのフィルタリングができる。タグ付けルールをAWS Configルールにすることで非準拠リソースの監視ができる。



※Configsでコスト配分タグ、施策ごとのタグキーを強制することができる。[こちら](AWS Config を使ってTagのチェックを行う。 - Qiita https://qiita.com/kooohei/items/2d42017f7e734e22aac4)や[こちら](AWSのコスト配分タグを正しく理解する - サーバーワークスエンジニアブログ https://blog.serverworks.co.jp/tech/2019/07/29/cost-alloc-tags-basic/)を参考に。



- コスト配分タグをリソースに設定し、コスト分析機能でりようできるようにアクティブ化する。これにより部門やプロジェクトなど独自のカテゴリでコスト分析ができるようになる。
- Cost Explorerで未来日を選択すると日時ベースでコスト予測を見ることができる。
  - Cost Anomaly Detectionでコストモニターを作成することでコストの異常検知をすることが出来る。
- コスト予算の月次予算設定で初期予算と成長率を記入することで月ごとに増加する予算を管理することができる。
- ランディングサイトを運営していて、マーケティングチームは部門予算をフル活用したPR施策を行っており、AWSの請求料金に余裕がありそうな場合は早めにその状況をキャッチして、マーケのコストにあてたい。ランディングサイトは同時に複数サイトを運用する期間もあり、半年先までのコスト計画を立てている。
  - 「期間毎に異なる計画予算」に対して「早めに予算に対しての請求料金を知る」ことと「施策ごとい発生状況」を確認する必要がある場合、AWS Budgetsを使用すれば月ごとに予算が設定でき、着地予測が確認できる。コスト配分タグを使用することで施策毎のBudgetsでのフィルタリングが可能。タグ付ルールをAWS Configルールにすることで非準拠リソースの監視ができる。



#### 最適なコンピューティングプランを知る

- AWS Compute Optimizerを使って最低なコンピューティングリソースを知ることが出来る。概要は[こちら](https://www.skyarch.net/column/aws-compute-optimizer/)を参照。

  - >AWS Compute Optimizerとは、AWSを利用しているユーザー環境を機械学習を利用して分析し、**ユーザーにとって最適なパフォーマンスや環境を行うコンピューターリソースを提案してくれるもの**です。
    >
    >AWS Compute Optimizerが行う分析は「**Amazon Elastic Compute Cloud (Amazon EC2) インスタンス**」「**Amazon EC2 Auto Scaling グループ**」「**Amazon Elastic Block Store** **(Amazon EBS)** **ボリューム**」「**AWS Lambda 関数**」と4つのリソースに対してです。
    >
    >これらの分析を自動的に行ってくれるため、**専門的な知識がなくても運用が行えます。**





### サーバー種別

#### 専有ホスト

[公式](https://aws.amazon.com/jp/ec2/dedicated-hosts/faqs/)に詳しい記載がある。

> Q: EC2 専有ホストとは何ですか?
>
> A: Amazon EC2 専有ホスト (「専有ホスト」または「ホスト」) は、EC2 インスタンスキャパシティーを利用したお客様専用の物理サーバーです。専有ホストはさまざまな構成 (物理コア、ソケット、VCPU) をサポートしており、ビジネスニーズに応じてさまざまなファミリーとサイズのインスタンスを選択して実行できます。
>
> Q: 専有ホストはベアメタル製品とどのように異なりますか?
>
> A: 専有ホストには仮想化ソフトウェア (Xen または Nitro Hypervisor) が事前インストールされていますが、ベアメタルサーバーには仮想化ソフトウェアが事前インストールされていません。ベアメタルサーバーは、独自のハイパーバイザーを使用したいお客様、または仮想化されていない環境で実行する必要のあるアプリケーションを対象としています。



特定の期間に1つの物理サーバーに接続することもできる模様。

> A: 専有ホストでは、ライセンス条項の範囲で、ソケット単位、コア単位、または VM ソフトウェア単位の既存のライセンスを利用できます。これには、VM、ソケット、または物理コアにバインドされた Windows Server、SQL Server、SUSE Linux Enterprise Server、Red Hat Enterprise Linux などのソフトウェアライセンスが含まれます。これにより、既存の投資を活用してコストを削減できます。専有ホストは、組織が特定の企業コンプライアンスおよび規制要件を満たすために単一のテナントインフラストラクチャで特定のアプリケーションを実行することを検討している場合のオプションとしても機能します。Dedicated Hosts は AWS License Manager と統合されており、ライセンスの使用状況を追跡し、ホストの割り当て、リリース、リカバリなどのホスト管理タスクを自動化できます。
>
> 
>
> Q: 特定の期間に 1 つの物理サーバーに接続する必要があるライセンスを管理するにはどうすればよいですか?
>
> A: 特定のシナリオは、特定の期間、同じ物理サーバーにライセンスを割り当てたままにする必要があります。たとえば、Microsoft は、Windows Server ライセンスを少なくとも 90 日間同じ物理サーバーに割り当てたままにすることを要求しています。AWS License Manager を使用すれば、License Affinity ルールを設定して、指定した日数の間ライセンスの使用を制限できます。



Dedicated Instance(ハードウェア専用インスタンス)だとアフィニティは設定できず、自動配置となる。

→1つのアカウントでサーバーを専有することはできても、同一サーバーを稼働し続けるとは限らないことを言っている。インスタンス配置の自由度はDedicated Host > Dedicated Instance。[こちら](https://qiita.com/miyuki_samitani/items/b1ab1b1e8ce759636fb2)を参照。

> ### Dedicated Instance とは
>
> EC2インスタンスはAWS側で任意の物理サーバの上で起動する、
> その為、物理サーバ上のインスタンスには別アカウントのインスタンスも存在する。
> しかし、ソフトウェアのライセンス等で物理サーバを専有したい場合があり、その際に使用する。
> `別アカウントのEC2インスタンスが同じサーバ上で起動しないことを保証する` のが Dedicated Instance です。
>
> ### Dedicated Hosts とは
>
> Dedicated Hosts は Dedicated Instance の上位版なやつです。
> Dedicated Instance では、`別アカウントのEC2インスタンスが同じサーバ上で起動しないことを保証する` が、同じアカウントのインスタンスを同じ物理サーバ上で起動させることができなかったが、
> Dedicated Hosts は `物理サーバでのインスタンスの配置を制御する` ことができます。
>
> ### Dedicated Instance と Dedicated Hosts の違い
>
> `Dedicated Instance` では、`別アカウントのインスタンスが同じ物理サーバ上で起動しないこと` だけを保証しますが、
> `Dedicated Hosts` では、`別アカウントのインスタンスが同じ物理サーバ上で起動しないこと` だけでなく、 `同じアカウントのインスタンスを配置させることが可能` になります。 (アカウントはIAM別ではなく、Rootアカウントが違えば違うアカウントとなる)
>
> [![Untitled Diagram.drawio - diagrams.net 2020-12-29 15-47-50.png](https://qiita-user-contents.imgix.net/https%3A%2F%2Fqiita-image-store.s3.ap-northeast-1.amazonaws.com%2F0%2F129517%2Fa2902f41-a45f-ac66-edab-550b21bb22f1.png?ixlib=rb-4.0.0&auto=format&gif-q=60&q=75&s=8ef87dcbbbb40f42afef1840ebc952ec)](https://camo.qiitausercontent.com/8cea3d9a2e6419d080c159aa4f49c52725de00ed/68747470733a2f2f71696974612d696d6167652d73746f72652e73332e61702d6e6f727468656173742d312e616d617a6f6e6177732e636f6d2f302f3132393531372f61323930326634312d613435662d616336362d656461622d3535306232316262323266312e706e67)
>
> ## [ ](https://qiita.com/miyuki_samitani/items/b1ab1b1e8ce759636fb2#勉強後イメージ)



### 暗号化系

#### KMS(Key Management Service)

データ暗号化に使用されるカスタマーキーを作成、管理できるマネージド型サービスのこと。

[こちら](https://www.fenet.jp/aws/column/aws-beginner/686/#:~:text=AWS%20KMS%E3%81%A7%E3%83%A6%E3%83%BC%E3%82%B6%E3%83%BC%E3%81%8C,%E5%88%A9%E7%94%A8%E6%96%99%E3%81%8C%E3%81%8B%E3%81%8B%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82)

> **AWS KMSでユーザーが作成したCMK（マスターキー）はカスタムキーストアで作成したもの、またはインポートしたものを問わず、月々1USDのストレージ利用料がかかります。**
>
> (中略)
>
> AWS KMSと統合するAWSサービスのリソースを暗号化する場合は、自動的にキーが作成されますが、このキーの作成料金とストレージ料金はかかりません。

対象暗号化(共通鍵)と非対称暗号化(公開鍵・秘密鍵)がある。CloudHSMなどを使ってもどちらも実現可能だが(あたりまえだが)割高。



#### SSE、CSE

SSE(Server Side Encryption)は暗号化・復号をサーバー側で行う暗号化方式のこと。逆にCSE(Client Side Encryption)は暗号化・復号をクライアント側で行う暗号化方式のこと。暗号化・復号のキーには、クライアント側で管理するキーだけでなく、KMSのカスタマー管理キーを使用することもできる。



#### CMK

**Customer Master Key**の略。CDKを暗号化するキーです。CMKは、KMS上では暗号化された状態で管理されています。

CMKには「**カスタマー管理型CMK**」と「**AWS管理型CMK**」の2種類があります。

- カスタマー管理型CMKは、KMSのコンソール画面からユーザーが作成できるCMK
- AWS管理型は、エイリアス名が`aws/サービス名`（例「aws/ebs」）の、KMSビルトインのCMK

また、ローテーションができ、CloudTrailでリクエストのログを残すことも可能です。



#### CDK

**Customer Data Key**の略。データの暗号化・復号時に実際に使用するキーのこと。

CSE-KMSで暗号化キーを取得する際、KMS上でCDKが生成され、クライアント側に「**CMKで暗号化されたCDK**」と「**平文のCDK**」が払い出される。

- この平文のCDKを使用して、クライアント側でデータを暗号化する
- 復号時は、暗号化されたCDKをCMKで復号して平文のCDKを取得し、この平文のCDKを使用して復号化する



暗号化方式は、「**どこで暗号化・復号するか(サーバー/クライアント)**」と「**暗号化のキーはどこで管理するか(S3/KMS/Client)**」の組合せによって、以下の5パターンに分かれる。

|              |   S3   |   KMS   | Client |
| :----------- | :----: | :-----: | :----: |
| サーバー     | SSE-S3 | SSE-KMS | SSE-C  |
| クライアント |   －   | CSE-KMS | CSE-C  |

以下は、各暗号化方式について**暗号化・復号の場所**と**キーの管理者**を一覧化したもの。

|  #   | 方式              | 暗号化・復号の場所 |      経路の暗号化       |    キーの管理者    | デフォルトの暗号化(※1) |
| :--: | :---------------- | :----------------: | :---------------------: | :----------------: | :--------------------: |
|  1   | SSE-S3            |      サーバー      |           TLS           |         S3         |           ○            |
|  2   | SSE-KMS           |      サーバー      |           TLS           |        KMS         |        ○（※2）         |
|  3   | SSE-C（※3）（※4） |      サーバー      |           TLS           | クライアント（※5） |           ×            |
|  4   | CSE-KMS           |    クライアント    |   CDKでの暗号化＋TLS    |        KMS         |           －           |
|  5   | CSE-C（※6）       |    クライアント    | クライアント暗号化＋TLS |    クライアント    |           －           |

※1 … バケットのプロパティの「デフォルトの暗号化」の「暗号化キータイプ」で選択可能かを示す。これはサーバーサイドの暗号化方式に関する設定であるため、クライアントサイドの暗号化方式（CSE-xx）については「－」としている。
※2 … **対称暗号のCMK**のみ指定可能です。非対称暗号（RSA、ECC）のCMKは指定できない。
※3 … 表にある通り、**SSE-C**ではKMSは使用されない。
※4 … **SSE-C**で暗号化されたファイルをマネージメントコンソールからダウンロードしようとするとエラーメッセージが返される。マネージメントコンソールでは暗号化キーを指定できないためです。



### シークレットマネージャーとパラメーターストアの違い

それぞれ何者かは[こちら](https://qiita.com/tomoya_oka/items/a3dd44879eea0d1e3ef5)の説明がわかりやすいです。

また、よく問われるところとして、パラメーターストアは4KBまでの標準利用であれば無料という点を意識しておくと良いかもしれません。

> AWS Systems Managerの一機能として、**パラメータストア機能**が提供されており、
> パスワードのような秘密データや、
> その他の設定データを一元管理する機能が提供されています。
>
> 2018年初頭までは、
> AWSの機能を活用したアプリコードとID/パスワード情報の分離の有力な方法は、
> パラメータストア機能の利用でした。
>
> しかし、2018年4月のAWS Summits 2018 | San Franciscoにおいて、
> ID/パスワードや認証情報の管理サービスとして、
> **AWS Secrets Manager**が発表されました。

また同ページに使い分けが結論づけられています。

> - シンプルな3-Tierの小規模WebシステムやDWH等、DBへの接続情報がプーリングされ、パラメータへのアクセスが少ない環境であれば、アプリの利用する情報の外部化にはParameter Storeの利用がコスト的にもリーズナブルである。
> - パラメータやシークレット情報に対するスパイクアクセスが予想されるEC2やECSのAuto Scaling環境、Labmda等では、Parameter Storeではパラメータ情報取得のAPIリクエストを捌ききれない可能性がある。
> - シークレット情報の取得リクエストが700 Req/secに収まるのであれば、Secrets Managerを試してみる価値あり。ただし有料なのでコスト試算を。



### サービスカタログ

AWS上で構築・展開したサービスを組織内で使える形にして公開したもの、という理解です。

[こちら](AWS Service Catalogとは – Amazon Web Service(AWS)導入開発支援 https://www.acrovision.jp/service/aws/?p=1032#:~:text=AWS%20Service%20Catalog%E3%81%A8%E3%81%AF%E3%80%81%E7%B5%84%E7%B9%94%E3%81%A8%E3%81%97%E3%81%A6%E7%AE%A1%E7%90%86%E3%81%97%E3%81%A6,%E6%A9%9F%E8%83%BD%E3%82%92%E6%8F%90%E4%BE%9B%E3%81%97%E3%81%BE%E3%81%99%E3%80%82)あたりを参考に。BlackBeltも参考になります。

> ![スクリーンショット 2022-12-25 10.27.01](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 10.27.01.png)
>
> ![スクリーンショット 2022-12-25 10.27.15](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 10.27.15.png)
>
> ![スクリーンショット 2022-12-25 10.27.32](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 10.27.32.png)
>
> ![スクリーンショット 2022-12-25 10.28.10](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 10.28.10.png)
>
> ![スクリーンショット 2022-12-25 10.28.20](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 10.28.20.png)



### 移行

全体像は[BlackBelt](https://www.youtube.com/watch?v=KonZEchQXvg)にて。

> ![スクリーンショット 2022-12-25 10.35.45](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 10.35.45.png)
>
> ![スクリーンショット 2022-12-25 10.32.52](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 10.32.52.png)
>
> ![スクリーンショット 2022-12-25 10.43.34](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 10.43.34.png)
>
> ![スクリーンショット 2022-12-25 10.44.33](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 10.44.33.png)

#### CART(AWS Cloud Adoption Readiness Tool)

質問に答えることで、今の状態と対応するべき準備について指標レポートを作成できる。

Cloud Adoption Readiness Tool をそのまま日本語に訳すと、クラウド採用準備ツール、といったところか。Readinessの呼び方はレディネス。

#### Server Migration Service

仮想サーバーを移行するサービス。増分レプリケーションが可能。

[こちら](https://www.niandc.co.jp/sol/tech/date20211129_2106.php)が詳しかった。

> クラウド環境へ移行する際に現在稼働しているサーバをそのままの状態で、手をかけずに移行できればという要望を持っている方は多いと思います。
> AWS SMSでは以下のようなメリットがあり、そのような要望を満たしてくれる移行サービスとなっています。
>
> ・エージェントレス型
> 移行対象サーバへ追加でモジュールをインストールする必要がありません。
> 代わりに移行用のツールとしてAWSが提供しているSMS Connectorというサーバを移行元の仮想基盤で稼働させる必要があります。
>
> ・AWS SMS利用は無料
> AWS SMSの利用については無料となっておりますのでAWSへ仮想マシンを移行する際に費用を検討する必要がありません。
> ぜひ活用したいサービスですね！
>
> ・ダウンタイムの最小化
> 増分レプリケーションが可能なので、切り替えをする際のダウンタイムを最小限に抑えることができます。
>
> ・同時移行が可能
> 50台の仮想マシンを同時に移行することが可能です。
> ただし複数台を同時に移行する際にはネットワーク帯域や仮想基盤のパフォーマンス低下が懸念されます。
> そのため本番移行前にAWS SMSによる移行検証を行い、ご使用の環境では何台まで同時移行が可能か確認されるのがよいでしょう。

#### AWS Application Discovery Service

オンプレミスのサーバーの設定や情報を自動収集するサービス。移行の判断や移行の計画を立てる際に役立つ。サーバーにエージェントをインストールして情報を収集するエージェント型とVMware向けのコネクタ型がある。

#### CART

AWS Cloud Adoption Readiness Toolの略。Webフォームで質問に答えるだけで移行準備に役立つレポートが提供される。

#### DMS

Database Migration Service。名前のとおりデータベースの移行サービス。

[BlackBelt](https://www.youtube.com/watch?v=Od83ySfrzGc)も軽く見ておくと良い。

> ![スクリーンショット 2022-12-25 11.01.59](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 11.01.59.png)
>
> ![スクリーンショット 2022-12-25 10.47.23](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 10.47.23.png)
>
> ![スクリーンショット 2022-12-25 10.48.07](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 10.48.07.png)
>
> ![スクリーンショット 2022-12-25 11.03.27](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-12-25 11.03.27.png)

#### SCT

Schema Conversion Tool。名前のとおり異なるデータベースエンジン間のスキーマ変換に用いる。

#### Glue

ETLサービス。データの変換を行うことで移行にも用いられる。

#### Snowball

オンプレミスの大容量のデータを1週間程度でAWSに移行することができる。

#### Transfer Family

[こちら](https://qiita.com/sugimount-a/items/2d643d5435d5845cc815)参照。

> Transfer Family は、AWS で提供されている SFTP, FTPS, FTP のプロトコルが使える安全なファイル転送のサービスです。転送先は、S3 と EFS を選べます。オンプレミスで FTP などを利用しているシステムがある場合、マネージドサービスとして AWS に管理負担を任せられます。

#### キューの移行

オンプレミスでApach Active MQを使っている場合、Amazon MQに移行できる。



#### AWS以外でAPIを固定IPで提供しており、顧客がアウトバウンド送信先のIPアドレスをファイアーウォールで許可している場合、顧客への影響を最小限に抑えたAWSへの移行方法法

BYOIPとして所有しているIPアドレスをElastic IPアドレスで使用することが可能。BYOIPはBring Your Own IPの略で、オンプレミスのIPアドレス範囲をAWSに持ち込むことができる。



#### DBのデータ変換移行

SCTデータ抽出エージェントは、ソースデータベースとターゲットデータベースが大きく異るケースでの追加の変換をサポートしている。膨大なサイズのデータを短期間で移行させる必要がある場合は、SCTデータ抽出エージェントを使用してSnowball Edgeにデータを保管して送信することで要件を満たすことができる。

DMS(Data Migration Service)というサービスもあるが、VPC-データセンタ間を接続できない。DMSの詳細は[こちら](https://aws.amazon.com/jp/dms/)。

> AWS Database Migration Service (AWS DMS) は、データベースを AWS に迅速かつ安全に移行するのに役立ちます。移行中でもソースデータベースは完全に利用可能な状態に保たれ、データベースを利用するアプリケーションのダウンタイムは最小限に抑えられます。AWS Database Migration Service は、広く普及しているほとんどの商用データベースとオープンソースデータベース間のデータ移行でご利用いただけます。
>
> AWS Database Migration Service では、Oracle から Oracle のような同種のデータベース間の移行も、Oracle または Microsoft SQL から Amazon Aurora といった異なるデータベースプラットフォーム間の移行もサポートされます。また、AWS Database Migration Service を使用すると、サポートされているあらゆるソースからサポートされているあらゆるターゲットに、低レイテンシーで継続的にデータをレプリケートすることができます。例えば、複数のソースから Amazon Simple Storage Service (Amazon S3) にレプリケートすることで、高可用性のスケーラブルなデータレイクソリューションを構築することができます。また、Amazon Redshift にデータをストリーミングすることで、データベースをペタバイト規模のデータウェアハウスに統合することもできます。サポートされるソースデータベースとターゲットデータベースの[詳細](https://docs.aws.amazon.com/dms/latest/userguide/CHAP_Endpoints.html)。



SCTデータ抽出エージェントの詳細は[こちら](https://docs.aws.amazon.com/ja_jp/SchemaConversionTool/latest/userguide/agents.html)。

> 一部の移行シナリオでは、ソースデータベースとターゲットデータベースは相互に大きく異なるため、追加のデータ変換が必要になります。AWS Schema Conversion Tool (AWS SCT) は拡張可能であるため、エージェントを使用してこれらのシナリオに対応することができます。*エージェント*は AWS SCT と統合されている外部プログラムですが、データ変換は他の場所 (Amazon EC2 インスタンスなど) で実行されます。さらに、AWS SCT エージェントは、ユーザーに代わって、他の AWS のサービスと相互作用し、例えば AWS Database Migration Service タスクの作成や管理を行います。



#### CassandraクラスタからDynamoDBへの移行

SCTデータ抽出エージェントによる移行が必要。DMSだけでは移行できない。スキーマの移行もCasssandra→DynamoDBはサポートされていない。

[参考](https://frontse.hatenablog.jp/entry/2022/02/14/003230#AWS-SCTDMS%E3%81%A8%E3%81%AF)

>異なる[DBMS](http://d.hatena.ne.jp/keyword/DBMS)間でデータベース[スキーマ](http://d.hatena.ne.jp/keyword/%A5%B9%A5%AD%A1%BC%A5%DE)やコード（ビュー、ストアドプロシージャ、ファンクションなど）の大部分を自動的に変換し移行してくれるツールです。ローカルPCにインストールして使用します。
>
>**[AWS](http://d.hatena.ne.jp/keyword/AWS) DMS**とは**Database Migration Tool**の略称で、異なる[DBMS](http://d.hatena.ne.jp/keyword/DBMS)間（同種でもOK）でデータそのものを移行できるサービスです。こちらは[AWS](http://d.hatena.ne.jp/keyword/AWS)マネジメントコンソールから使用する[Webサービス](http://d.hatena.ne.jp/keyword/Web%A5%B5%A1%BC%A5%D3%A5%B9)です。
>Migrationと名前はついていますが、検証目的でのデータ[レプリケーション](http://d.hatena.ne.jp/keyword/%A5%EC%A5%D7%A5%EA%A5%B1%A1%BC%A5%B7%A5%E7%A5%F3)や遠隔地バックアップなどにも活用できるサービスです。
>
>異なる[DBMS](http://d.hatena.ne.jp/keyword/DBMS)間で移行を行う際、まずSCTでテーブル定義などの[メタデータ](http://d.hatena.ne.jp/keyword/%A5%E1%A5%BF%A5%C7%A1%BC%A5%BF)やストアドプロシージャなどのコードを移行し、その後にDMSでデータ移行を行うというステップが定石です。



#### オンプレミスでTDE(透過的データ暗号化)を実現しているOracleの移行

[こちら](Oracle Database の透過的なデータ暗号化 (TDE) に対応AWS CloudHSM - AWS CloudHSM https://docs.aws.amazon.com/ja_jp/cloudhsm/latest/userguide/oracle-tde.html)を参考。TDEはデータをDBに保存する前に暗号化することをいう。暗号化にはマスターキーが必要だが、そのキーをHSMで管理することで高いセキュリティを実現可能。この場合、OracleはEC2にインストールする必要がある。



透過的データ暗号化とは

[こちら](https://atmarkit.itmedia.co.jp/ait/articles/1710/24/news053.html)を参照。

> 一番の特徴は、「透過的」という名前の通り、**アプリケーションの書き換えを行わなくてもよい**ことです。暗号化／復号、暗号鍵の管理は全てユーザーやアプリケーションから透過的に行われます。



#### VMwareからの仮想マシンの移行、移行したEC2が問題なく起動するかの確認を行う場合

仮想マシンをAMIにレプリケーションする必要がある場合は、Server Migration ConnectorをVMwareにインストールすることと、レプリケーションジョブの作成が必要。レプリケーションジョブが完了するとAMI IDがイベントで送信できるので、それをLambdaで受け取ってEC2を起動するところまで自動化できる。

CloudFormationでやろうとすると、先にAMI IDを知っておく必要があり、不可能。



### データ分析

#### AWS Glue

データ変換を担うETLサービス。

CSVに独自の区切り文字が使用されている場合でも、CSVカスタム分類子を追加することでデータカタログテーブルを定義可能。



### Amazon App Stream

[こちら](https://dev.classmethod.jp/articles/re-introduction-2020-appstream2/)を参照。

> > Amazon AppStream 2.0 は、完全マネージド型のアプリケーションストリーミングサービスです。
>
> とある様にフルマネージドなアプリケーションストリーミングサービスです。
>
> アプリケーションストリーミングが何かというと「アプリケーションの実体はリモート環境のサーバーで動作しているが、画面の描画をストリーミング転送してあたかもローカルでアプリケーションが動作している様に見せるアレ」です。
> Windows Serverに標準搭載されているMicrosoft RemoteAppやCitrix社のCitrix Virtual Apps(旧称XenApp)などと同様のやつと言うほうがこれらの製品を知っている方にはわかりやすいかもしれません。
>
> 完全マネージド型とある様にその基盤はAWSによって管理されユーザーはアプリケーションの利用に注力することができます。
>
> ### Amazon WorkSpacesとの違い
>
> AWS内の類似のサービスに[Amazon WorkSpaces](https://aws.amazon.com/jp/workspaces/)がありますが、Amazon WorkSpacesは「仮想デスクトップ」という形でユーザーに仮想マシン全体を公開するのに対し、AppStream 2.0は「アプリケーションストリーミング」という形で特定のアプリケーションのみを公開する違いがあります。
>
> より詳細な両者の差異とそれぞれのユースケースについては以下の記事をご覧いただくとよいでしょう。



## 試験テクニック

- 「単一Webサーバーのローカルに保存されているデータを複数サーバーから連携できるように」といった文脈がきたら

  - EBSは特定のインスタンスにアタッチするものなので✗
  - S3かEFSなど共有型のストレージが正解となる

- なんらかの操作を「アカウント内の特定のユーザーに対して」許可し、一方で「特定の操作を制限」する場合、SCPというキーワードを含む選択肢は誤りになる

  - SCPはアカウント全体に影響する

  - 特定のエンティティに対し、アクセス権の境界設定ポリシーを設定することで、制限を越えた権限を持つIAMロールをEC2にアタッチしても境界以上の権限は拒否できる

  - [こちら]()参照

    > ![                             リソースベースのポリシー、アクセス許可の境界、およびアイデンティティベースのポリシーの評価                         ](https://docs.aws.amazon.com/ja_jp/IAM/latest/UserGuide/images/EffectivePermissions-rbp-boundary-id.png)



- 疎結合アーキテクチャにおいて

  - 「想定外のエラーなどの発生により情報が失われないようにする」ときたらSQSのDLQ

  - 「順番に処理する」ときたらFIFO

- 「バッチでRPO24時間」ときたら日時バッチ

- 紛らわしいService Health DashboardとPersonal Health Dashboardを区別すること
  - SHD：[ログインしなくても誰でも見えれるサービスの稼働状況](AWS Health Dashboard - Nov 05, 2022 https://health.aws.amazon.com/health/status)
  - PHD：ログインしないと見れない

- ライセンスの都合上、「ホストを専有」して「サーバーを停止してもアクティベートしたホストで起動し続ける」ことが条件の場合、Dedicated Hostsのアフィニティオプションが必要 ※affinity とは「**密接な関係、類似性、姻戚関係、好み、相性、親近感、親和力**」という意味があることから、停止して再開してもホストが「同じ」という意味で使われている用語と思われる

- 「リクエスタ支払い」はリクエストにx-amz-request-payer:requesterをヘッダーに含めるだけでよく、S3のconditionなどは変更する必要はない

- 会社を跨いで(異なるAWSアカウント間で)「すばやく安全にRDBのコピーを渡す」必要がある場合、RDBの暗号化されたスナップショットを取得してクロスアカウントで共有し、KMSのキーポリシで別会社がカスタマーマスターキーにアクセスできるよう設定し、復号化する。

- 「本番環境と検証環境があり、本番環境は1年以上稼働させる必要があり、毎日止められず、月間○○時間程度使っている。検証環境は常時稼働しない。」という旨の問題があった場合、本番環境用にはリザーブドインスタンスを○○時間に相当する数量で購入し、検証環境用にはスポットインスタンスを購入するといった節約術が正解になる場合が多い。

- Elastic IPを設定したい場合、API GatewayやALBには設定できない。NLBを選ぶこと。

- オンプレで使っていた固定IPをAWS移行時にも使いたい場合、BYODIPというサービスがあり、ElasticIPとしてオンプレで使っていた固定IPを持ち込むことができる。

- Teradata→Redshiftなどで、オンプレからAWSへテラバイトレベルのデータ移行を行う場合、VPNやDirectConnectでのデータ転送も可能だが時間がかかるため、Snowball Edgeなど用いて物理的にデータを運ぶことも検討する。また、データフォーマットの変換が必要になるため、異なるDB間のフォーマット変換が可能なSCT(Schema Conversion Tool)データ抽出エージェントも必要となる。

- 「すばやく簡単にコストをかけずにIPアドレスをブロック」したい場合、ネットワークACLで十分。

- キャッシュを使って高速化する場合、「暗号化、マルチAZにようる高可用性、パフォーマンス一定」などの要件が来た場合はRedisを選択すること。Memchachedでは実現できない。パフォーマンス一定は、Redisのライトスルー戦略により実現する。

  - [こちら](https://zenn.dev/hi_ka_ru/articles/9fc8546a1e354e)を参照。

  - > # キャッシュ戦略
    >
    > ElastiChaceには、２種類のキャッシュ方法があります。
    >
    > ## 遅延読み込み
    >
    > 遅延読み込みは、アプリケーションがデータをリクエストするときは、常にElastiCacheに最初にリクエストします。ElastiCacheにデータが存在する場合は、そのままアプリケーションにデータを返却します。ElastiCacheにデータが存在しない場合は、データストアにデータをリクエストし、アプリケーションにデータを返却します。その後、アプリケーションからElastiCacheに対してデータを書き込みます。
    >
    > - メリット
    >   - リクエストされたデータのみキャッシュするため、キャッシュがデータでいっぱいになることを回避できます。
    > - デメリット
    >   - データが更新された場合に、キャッシュミスが起こらないとキャッシュされたデータは更新されないため、データが古くなる可能性があります。
    >   - キャッシュミスした場合は、データの取得に時間がかかります。（キャッシュへのリクエスト、DBへのリクエスト、キャッシュへの書き込みが行われるため）
    >
    > ![img](https://storage.googleapis.com/zenn-user-upload/5c610549a3337b7ff479c596.png)
    >
    > ## ライトスルー
    >
    > ライトスルーは、データがデータベースに書き込まれるときや、更新される時に常に、ElastiCacheにもデータを書き込みます。
    >
    > - メリット
    >   - キャッシュのデータが古くならなく、常に最新のデータの状態になります。
    > - デメリット
    >   - すべてのデータをキャッシュに書き込みために、キャッシュがデータでいっぱいになり、そのほとんどのデータがアクセスされない可能性があります。
    >
    > ![img](https://storage.googleapis.com/zenn-user-upload/01fb2c844415310649d1ed6c.png)

- 既存のActive Directoryをそのまま使ってAWSアカウントとBoxなどのSaaS製品へのシングルサインオン環境を構築するには、AWS SSOとAD Connectorを使用する。各アカウントに追加のIAMロールを作成し、一元管理するにはCloudFormation StackSetsが最適。

- 3つのアベイラビリティゾーンで稼働しているEC2インスタンスで処理したデータを外部に送信し、集計するが、「1/3しか処理できていない」みたいな問題はネットワーク経路を疑う。この場合はNATインスタンスが3つあるため、これを疑う。

- 「すべてIAMロールを使用してリクエスト」「MFA必須」ときたらIAMロールの信頼ポリシーでConditionを追加してMFAを必須にする。初回ログイン時にパスワード設定とMFAデバイスの設定が必要になるので、権限をIAMポリシーで許可しておくが、自分以外は変更できないようにaws:usernameポリシー変数で制御する。

  - こちらを[参考](多要素認証(MFA)するまで使えません！なIAMユーザを作成してみた | DevelopersIO https://dev.classmethod.jp/articles/forced_mfa/)に。

    - > ```javascript
      >         {
      >             "Sid": "AllowIndividualUserToManageTheirOwnMFA",
      >             "Effect": "Allow",
      >             "Action": [
      >                 "iam:CreateVirtualMFADevice",
      >                 "iam:DeleteVirtualMFADevice",
      >                 "iam:DeactivateMFADevice",
      >                 "iam:EnableMFADevice",
      >                 "iam:ResyncMFADevice",
      >                 "iam:ListMFADevices"
      >             ],
      >             "Resource": [
      >                 "arn:aws:iam::*:mfa/${aws:username}",
      >                 "arn:aws:iam::*:user/${aws:username}"
      >             ]
      >         },
      > ```
      >
      > 自分自身のMFAデバイスを管理するために必要なポリシーです。
      > 登録だけではなく削除やリスト参照なども入ってます。


- プライベートサブネットのEC2からKinesis Data Streamsに可用性を保ちつつコスパよくセキュアにデータを転送する場合、NATゲートウェイではなく、Kinesis Data Streamsのインターフェースエンドポイントをプライベートサブネットに配置してそのエンドポイント経由でデータを転送すると良い。
- CloudFormationで最新のAMIを取得する場合

  - CloudFormationからLambdaファンクションを作成し、AMI IDでフィルタリングして最新のAMIをGETする手法が有効
- レポート作成のためなどでログなどが格納されたRDSのデータをエビデンスとして一定期間保持したあとにデータを削除する場合、RDSのDeletionPolicy: Snapshot が使える。





## AWS Certified Solutions Architect - Professional Official Practice Question Set (SAP-C02 - Japanese)

1. ある企業は、AWS インフラストラクチャを大規模に使用しています。同社は、いくつかの新しい Amazon EC2 インスタンスと Amazon S3 バケットを作成する必要があります。同社は、EC2 インスタンスと S3 バケットの間で 1 秒未満のレイテンシー通信を必要としています。同社が保存する情報には機密性があるため、データとアプリケーションは会社の物理的な制御下にあるハードウェア上に存在する必要があります。同社は、AWS Management Console と AWS CLI を使用してすべてのリソースを管理したいと考えています。

   これらの要件を満たす構成はどれですか。

   1. AWS Outposts ラックを注文して設置するOutpost ラックにプライベートサブネットを作成する新しいプライベートサブネットで必要な EC2 インスタンスを起動するOutposts に S3 バケットを作成するプライベートエンドポイント接続を使用して、EC2 インスタンスと S3 バケット間の安全な通信を設定する

      正解です。Outposts は、AWS のインフラストラクチャ、サービス、API、ツールをお客様の構内に拡張するフルマネージドサービスです。Outpost ラックは、ハードウェアに対する制御を保持するという会社の要件を満たします。低レイテンシーの通信のために、S3 バケットと EC2 インスタンスを Outpost ラックにデプロイすることができます。このソリューションはすべての要件を満たします。

      Outposts の詳細については、「[What Is AWS Outposts? (AWS Outposts とは?)](https://docs.aws.amazon.com/outposts/latest/userguide/what-is-outposts.html)」を参照してください。

      Outposts での Amazon S3 のネットワークの詳細については、「[S3 on Outposts のネットワーキング](https://docs.aws.amazon.com/AmazonS3/latest/userguide/S3OutpostsNetworking.html)」を参照してください。

      (メモ)

      Outpostの詳細は[こちら](https://docs.aws.amazon.com/outposts/latest/userguide/what-is-outposts.html)を参照。

      > ## 重要な概念
      >
      > これらは、AWS Outposts の主要な概念です。
      >
      > - **Outpost サイト**– AWS が Outpost を設置する、お客様が管理する物理的な建物。サイトは、Outpost の施設、ネットワーク、および電源の要件を満たしている必要があります。
      > - **Outpost 構成**– Amazon EC2 コンピューティング容量、Amazon EBS ストレージ容量、およびネットワーク サポートの構成。各構成には、固有の電力、冷却、および重量サポートの要件があります。
      > - **Outpost の容量**– Outpost で利用可能なコンピューティング リソースとストレージ リソース。AWS Outposts コンソールから Outpost の容量を表示および管理できます。
      > - **Outpost 機器**– AWS Outposts サービスへのアクセスを提供する物理ハードウェア。ハードウェアには、AWS が所有および管理するラック、サーバー、スイッチ、ケーブルが含まれます。
      > - **Outpost ラック**– 業界標準の 42U ラックである Outpost フォーム ファクター。Outpost ラックには、ラックマウント可能なサーバー、スイッチ、ネットワーク パッチ パネル、電源シェルフ、およびブランク パネルが含まれます。
      > - **Outpost サーバー**– 業界標準の 1U または 2U サーバーである Outpost フォーム ファクターで、標準の EIA-310D 19 準拠の 4 ポスト ラックに設置できます。Outpost サーバーは、スペースが限られているサイトや容量要件が小さいサイトにローカル コンピューティング サービスとネットワーク サービスを提供します。
      > - **サービスリンク**– Outpost と関連する AWS リージョン間の通信を可能にするネットワークルート。各 Outpost は、アベイラビリティーゾーンとそれに関連付けられたリージョンの拡張です。
      > - **ローカル ゲートウェイ**– Outpost ラックとオンプレミス ネットワーク間の通信を可能にする論理相互接続仮想ルーター。
      > - **ローカル ネットワーク インターフェイス**– Outpost サーバーとオンプレミス ネットワークからの通信を可能にするネットワーク インターフェイス。

      またネットワークについては[こちら](https://docs.aws.amazon.com/AmazonS3/latest/userguide/S3OutpostsNetworking.html)を参照。

      > ## ネットワーキング アクセス タイプの選択
      >
      > VPC 内またはオンプレミス ネットワークから Outposts の S3 にアクセスできます。アクセス ポイントとエンドポイント接続を使用して、Outpost バケットと通信します。この接続により、VPC と S3 on Outposts バケットの間のトラフィックが AWS ネットワーク内に保持されます。エンドポイントを作成するときは、エンドポイント アクセス タイプを `Private`(VPC ルーティングの場合) または`CustomerOwnedIp`(顧客所有の IP アドレス プール [CoIP プール] の場合) として指定する必要があります。
      >
      > - `Private`(VPC ルーティング用) – アクセス タイプを指定しない場合、Outposts の S3 は`Private`デフォルトで使用します。アクセス タイプを使用する `Private`と、VPC 内のインスタンスは、Outpost 内のリソースと通信するためにパブリック IP アドレスを必要としません。VPC 内から Outposts で S3 を操作できます。このタイプのエンドポイントには、オンプレミス ネットワークからアクセスできません。
      > - `CustomerOwnedIp`(CoIP プールの場合) –`Private`アクセス タイプをデフォルトに設定せずに を選択`CustomerOwnedIp`した場合は、IP アドレス範囲を指定する必要があります。このアクセス タイプを使用して、オンプレミス ネットワークと VPC 内の両方から Outposts で S3 を操作できます。VPC 内の Outposts で S3 にアクセスする場合、トラフィックはローカル ゲートウェイの帯域幅に制限されます。

      ![スクリーンショット 2022-11-27 21.41.04](/Users/okazaki/Dropbox/typora/AWS Solution Architect Professional一発合格までの道のり.assets/スクリーンショット 2022-11-27 21.41.04.png)

   2. 不正解です。Local Zones は、コンピューティング、ストレージ、データベース、およびその他の特定の AWS のサービスを大規模な人口および産業センターの近くに配置するインフラストラクチャデプロイの一種です。ただし、会社が Local Zones を使用している場合、ハードウェアとリソースは会社の直接制御下にはありません。このソリューションは要件を満たしません。

      Local Zones の詳細については、「[VPC をローカルゾーン、Wavelength Zone、または Outpost に拡張する](https://docs.aws.amazon.com/vpc/latest/userguide/Extend_VPCs.html)」を参照してください。

2. ある会社は VPC 内の Amazon EC2 インスタンスで機密性の高いアプリケーションを実行しています。この会社は、ネットワークトラフィックをモニタリングし、潜在的な脅威について分析したいと考えています。このソリューションは、大量のネットワークトラフィックに対応できるようにスケールする必要があります。さらに、このソリューションは、データのクエリと視覚化機能を提供する必要があります。運用諸経費を最小限に抑えながら、これらの要件を満たすソリューションはどれですか。

   1. VPCフローログを作成する。フローログをS3バケットに発行する。Athenaで外部テーブルを作成し、ログファイルをクエリする。QuickSightからAthenaに接続してデータを視覚化する。

      正解です。このソリューションでは、運用諸経費を削減する AWS マネージドサービスとサーバーレスコンポーネントを使用します。さらに、このソリューションは自動的にスケーラブルです。

      不正解です。このソリューションの目標の 1 つは、運用諸経費を最小限に抑えることです。ログが DynamoDB に発行され、Lambda がログを Aurora に転送する場合、ログをクエリ可能な状態にするための運用諸経費が高くなります。Amazon S3 に直接発行し、Athena を使用してファイルをクエリするソリューションは、運用諸経費を削減します。

      不正解です。Amazon S3 にログをプッシュするために Kinesis Data Streams と Kinesis Data Firehose を使用する必要はありません。**<u>VPC フローログは Amazon S3 に直接発行できます。</u>**このソリューションにより、運用諸経費が増えます。

3. ある企業は、3 つの異なるアプリケーションのデータをホストするために、複数の Amazon DynamoDB テーブルを使用しています。セキュリティ管理者は、アプリケーション管理者にテーブルのアクセス許可を管理する機能を提供したいと考えています。管理するテーブルは、各管理者のアプリケーションにのみ関連付けられているものです。アプリケーション管理者は現在、すべてのテーブルに対する権限を持つ DynamoDBAdmins と呼ばれる IAM グループの一員です。同社は今後、新しいアプリケーション用の追加の管理者とテーブルを作成する予定です。

   しかし最近、アプリケーション管理者の 1 人が、自身のアプリケーションに関連付けられていないテーブルへのアクセス許可を持つ IAM ロールを作成できてしまいました。そこでセキュリティ管理者は、アプリケーション管理者がアプリケーションに関連付けられていないテーブルに対するアクセス許可を取得できないようにする、新しいソリューションを作成する必要があります。継続的な管理作業が最も少なく、この要件を満たすソリューションはどれですか。

   1. 正解です。アクセス許可の境界は、マネージドポリシーを使用して、アイデンティティベースのポリシーが IAM エンティティ (ユーザーまたはロール) に付与できる最大アクセス許可を設定できるようにする高度な機能です。アクセス許可の境界を使用して、アプリケーション管理者が付与できる権限を制限できます。アプリケーション管理者は、アクセス許可があるテーブル以外のテーブルへのアクセス許可を持つ IAM ロールを作成することはできません。単一のアクセス許可の境界ポリシーでは、複数のポリシーよりも管理作業は少なくて済みます。

      アクセス許可の境界の詳細については、「[IAM エンティティのアクセス許可境界](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_policies_boundaries.html)」を参照してください。

      IAM ポリシーを作成して、各管理者からの特定のテーブルへのアクセスを拒否するポリシーを適切な管理者にアタッチする

      不正解です。アプリケーション管理者のために複数の IAM ポリシーを作成して管理するには、多大な管理作業が必要になります。会社が将来新しいアプリケーションを作成し、新しい管理者を追加するときは、既存の拒否ポリシーをすべて更新し、新しい拒否ポリシーを作成する必要があります。より良いソリューションは、単一のアクセス許可の境界を使用して、アプリケーション管理者の権限を制限することです。

4. あるウェブデザイン会社が、顧客製品を別々の AWS アカウントで構築し、管理しています。同社は独自の AWS アカウントを持ち、顧客に代わって AWS アカウントを管理するためのフルアクセス許可を持っています。会社の顧客数が増えるにつれて、会社のセキュリティチームは大量のインシデントレポートに対応できなくなっています。セキュリティチームは、次の 2 つの点を判断するための効率的な方法を必要としています。外部 IAM ID に付与されるリソースへのアクセスと、Amazon S3 に保存されているどの機密情報に公的にアクセス可能であるかです。

   オペレーションのオーバーヘッドを最小限に抑えながら、これらの要件を満たすソリューションはどれですか。	

   1. このソリューションは 2 部に分かれます。IAM Access Analyzer は CloudTrail ログを分析して、外部アクセスが許可されているかどうかを判断します。Macie は S3 バケットを分析して、パブリックオブジェクト、パブリックバケット、または機密情報が Amazon S3 にあるかどうかをチェックします。IAM Access Analyzer と Macie の調査結果は両方とも Security Hub で報告できます。Security Hub は Organizations と統合されているため、単一の Security Hub ダッシュボードを使用して、両方のセキュリティ問題を 1 か所でモニタリングできます。

      正解です。この予算は管理アカウントにあるため、開発者はそれを変更できません。アカウント内のユーザーが管理者権限を持っている場合でも、SCP を上書きすることはできません。

      AWS Budgets の詳細については、[AWS Budgets](https://aws.amazon.com/aws-cost-management/aws-budgets/) を参照してください。

5. ある企業が AWS クラウドで複数のパブリックウェブアプリケーションをホストしています。同社は、従業員の在宅勤務を可能にしたいと考えています。従業員は会社のアプリケーションにアクセスできる必要があります。また、従業員は、仕事で日常的に使用する自宅のコンピュータから、さまざまな Microsoft Windows デスクトップアプリケーションにアクセスする必要があります。

   オペレーションのオーバーヘッドを最小限に抑えながら、これらの要件を満たすソリューションはどれですか。

   1. Amazon WorkSpaces を実装して、各ユーザーの Windows デスクトップをホストする必要なデスクトップソフトウェアをインストールするユーザーに自宅のデバイスの Amazon Workspaces クライアントからデスクトップにアクセスすることを要求する

      正解です。WorkSpaces を使用して、ユーザーに仮想デスクトップをプロビジョンできます。WorkSpaces では、ハードウェアを調達してデプロイしたり、複雑なソフトウェアをインストールしたりする必要をなくします。ユーザーは、複数のデバイスまたはウェブブラウザから仮想デスクトップにアクセスできます。OS パッチを含むソフトウェアを自動的に更新するように WorkSpaces を設定できます。これは、オペレーションのオーバーヘッドが最も少ないソリューションです。

   2. 不正解です。Amazon EC2 を使用するには、Windows やその他のソフトウェアにセキュリティパッチと更新を個別に適用する必要があります。さらに、デスクトップの高可用性を確保するには、多大な労力が必要です。WorkSpaces は、最小限のオペレーションのオーバーヘッドでこれらのタスクを自動化できます。

6. ある動画共有モバイルアプリケーションは、10 GB を超えるファイルを Amazon S3 バケットにアップロードします。ただし、S3 バケットが存在する AWS リージョンから遠く離れた場所でユーザーがアプリケーションにアクセスすると、アップロードに時間がかかります。場合によっては、アップロードが完了する前に失敗することがあります。

   アプリケーションのアップロードパフォーマンスを向上させるために、ソリューションアーキテクトが取るべきステップの組み合わせはどれですか。 (2 つ選択してください。)

   1. S3 バケットで S3 Transfer Acceleration を有効にする。アップロードに S3 Transfer Acceleration のエンドポイントを使用するようにアプリケーションを構成する。

      正解です。**<u>S3 Transfer Acceleration は、CloudFront エッジロケーションと最適化されたネットワークパスを使用して、オブジェクトの転送を高速化します。</u>**

      S3 Transfer Acceleration の詳細については、[Amazon S3 Transfer Acceleration を使用した高速かつ安全なファイル転送の構成](https://docs.aws.amazon.com/AmazonS3/latest/dev/transfer-acceleration.html)を参照してください。

   2. ビデオファイルをチャンクに分割するようにアプリケーションを構成する。マルチパートアップロードを使用して Amazon S3 にファイルを転送する。

      正解です。マルチパートアップロードは、チャンクを並列にアップロードすることで、大きなファイルを高速に転送します。この方法では、アップロードのスピードが向上し、失敗したアップロードの回復性が向上します。

      S3 マルチパートアップロードの詳細については、[マルチパートアップロードを使用したオブジェクトのアップロードとコピー](https://docs.aws.amazon.com/AmazonS3/latest/dev/uploadobjusingmpu.html)を参照してください。

7. ある企業が、いくつかの AWS リージョンに取引アプリケーションをデプロイしました。このアプリケーションは、取引アプリケーションと同じリージョンの AWS にもデプロイされているサードパーティーの REST サービスを使用します。セキュリティ上の理由から、アプリケーションは AWS PrivateLink VPC エンドポイントを使用してサードパーティーのサービスに接続します。最近、サードパーティーサービスの 1 つが内部エラー応答を送信し始めました。エラー応答により、そのリージョンの取引アプリケーションが不安定になりました。その結果、その会社は多額の経済的損失を被りました。同社は、サードパーティーサービスがいずれかのリージョンで適切に応答しない場合に、セカンダリリージョンにフェイルオーバーするソリューションを求めています。

   1. API カナリア設計図を使用して、サードパーティーアプリケーションにアクセスする Amazon CloudWatch Synthetics カナリアを作成する毎分失敗した試行回数に基づいて、カナリアに CloudWatch アラームを作成するアラームステータスを追跡し、セカンダリリージョンにフェイルオーバーするために、ヘルスチェックで Amazon Route 53 DNS を設定する

      正解です。**<u>CloudWatch Synthetics を使用して、エンドポイントと API をモニタリングするために、スケジュールに従って実行される設定可能なスクリプトであるカナリアを作成できます。GET メソッドで API カナリアを作成して、サードパーティーサービスが期待どおりに応答しているかどうかを判断できます。Route 53 はアラームステータスを追跡でき、必要に応じてセカンダリリージョンにフェイルオーバーできます。</u>**

      模擬モニタリングの詳細については、「[模擬モニタリングの使用](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Synthetics_Canaries.html)」を参照してください。

      Canary 設計図の詳細については、「[Canary 設計図の使用](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch_Synthetics_Canaries_Blueprints.html)」を参照してください。

      Route 53 ヘルスチェックの詳細については、「[Amazon Route 53 ヘルスチェックの種類](https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/health-checks-types)」を参照してください。

8. ある小売企業は、Amazon EC2 インスタンスで実行される MySQL データベースに、何百万もの製品の販売データを保存しています。製品の数が増えるにつれ、同社はデータベースのパフォーマンスの低下に気が付いています。需要予測が不十分なため、同社は頻繁に製品不足に陥っています。製品不足による売上の損失を防ぐために、同社は分析を使用して需要予測の作成を自動化したいと考えています。同社は他の AWS マネージドデータベースオプションを評価しています。同社には次の要件があります。

   - 受信データの分析を毎分実行する
   - 集計関数、派生関数、相関関数に基づいて、毎日のページビュー、買い物かご放棄率、週次注文などの消費者行動の傾向を認識する
   - 現在および過去のデータを含む数百テラバイトのデータを効率的に保存して、パフォーマンスを最適化する

   オペレーションのオーバーヘッドを最小限に抑えながら、これらの要件を満たすソリューションはどれですか。

   1. 現在のデータと履歴データの両方に対して 1 つの Amazon Timestream テーブルを作成する

      正解です。Timestream は、高速でスケーラブルな、サーバーレスの時系列データベースです。Timestream には、時系列関数をサポートし、消費者行動の傾向を特定するのに役立つ組み込みの時系列分析があります。Timestream は数百テラバイトのデータを保存できます。Timestream は、最新データのメモリストアと履歴データの磁気ストアにより、データライフサイクル管理を簡素化します。Timestream は、受信データに対してリアルタイム分析を実行するために、クエリを定期的かつ自動的にスケジュールできます。このソリューションはすべての要件を満たしています。

      Timestream の詳細については、「[What Is Amazon Timestream? (Amazon Timestream とは)](https://docs.aws.amazon.com/timestream/latest/developerguide/what-is-timestream.html)」を参照してください。

   2. Amazon Elastic Container Service (Amazon ECS) にコンテナ化して、アプリケーションレイヤーをリプラットフォーム化するデータベースレイヤーを Amazon Timestream にリファクタリングする

      正解です。Amazon ECS は、長時間実行されるプロセスをサポートするコンテナ管理サービスです。このタイプの IoT の気象データとアクセスパターンは、時系列データベースに適しています。Timestream は、高速でスケーラブルかつフルマネージドの専用時系列データベースであり、毎日何兆もの時系列データポイントを保存して分析することができます。Timestream は、リレーショナルデータベースよりも最大 1000 倍高速になることがあります。

9. ある企業は AWS Organizations を使用してアカウントを管理しています。この会社は、本番環境の AWS アカウントで、未承認のサービスの使用を禁止したいと考えています。また、アカウント数が増えるにつれて、追加の管理諸費用を最小限に抑えたいと考えています。

   これらの要件を満たすアプローチはどれですか。

   1. すべての機能を有効にした新しい組織を作成する。2 つの新しい OU を作成する。1 つの OU は本番稼働用アカウント用で、もう 1 つの OU は非運用アカウント用とする。新しい組織で、承認されていないサービスへのアクセスを拒否する SCP を作成する。SCP を実稼働 OU に適用する。

      正解です。本番稼働用アカウントを含む OU に SCP を適用すると、OU 内のすべてのアカウントのサービスを拒否できます。

      **<u>※ SCP を使用できるようにするには、組織内のすべての機能を有効にする必要があります。</u>**

   2. 一括請求 (コンソリデーティッドビリング) のみを有効にした、新しい組織を作成する。2 つの新しい OU を作成する。1 つの OU は本番稼働用アカウント用で、もう 1 つの OU は非運用アカウント用とする。新しい組織で、本番環境の各サブアカウントに適用される IAM ロールを作成し、承認されていないサービスへのアクセスを拒否する。

      不正解です。アカウント間の IAM ロールの管理には時間がかかる場合があります。新しいサービスを追加するたびに、許可リストにそのサービス追加する必要があります。さらに、IAM の編集を許可するロールを持つユーザーは、IAM ロールをオーバーライドできます。

10. ある会社が、単一の AWS リージョンの AWS にアプリケーションをデプロイしました。Application Load Balancer の背後にある Amazon EC2 インスタンスで実行されるのは、Windows アプリケーションです。EC2 インスタンスは Amazon EC2 Auto Scaling グループで実行され、アプリケーションはマルチ AZ Amazon RDS DB インスタンスを使用してデータを保存します。ソリューションアーキテクトは、ビジネス継続性を確保するために、クロスリージョン災害対策 (DR) シナリオを策定する必要があります。同社では、目標 RTO を 3 分、RPO を30秒にする必要があります。同社は、アプリケーションに変更を加えたくありません。

    これらの要件を満たすソリューションはどれですか。

    1. 
       少数のインスタンスと RDS DB インスタンスのリードレプリカを含む EC2 Auto Scaling グループを別の AWS リージョンにデプロイするEC2 インスタンスをスケールアップし、必要に応じてリードレプリカをプライマリ DB インスタンスに昇格させて、ビジネスの継続性を確保する新しいプライマリ DB インスタンスを参照するようにアプリケーションを更新する

       正解です。ウォームスタンバイ DR ソリューションは、RPO を数秒で、RTO を数分以内に達成するように設計されています。このアプローチは会社の要件を満たします。

       不正解です。マルチリージョン (マルチサイト) の Active-Active DR ソリューションは、ほぼゼロの RTO と RPO を達成するように設計されています。このアプローチは、ほとんどの要件を満たします。ただし、このシナリオには 2 つの独立した DB インスタンスがあります。**<u>DB インスタンスを Active-Active にするには、アプリケーションコードを大幅に変更する必要があります。同社はこれらの変更を行うつもりはありません。</u>**

11. ある会社の処理チームは、本番アプリケーションのある AWS アカウントを持っています。アプリケーションは、ネットワークロードバランサー (NLB) の背後にある Amazon EC2 インスタンスで実行されています。EC2 インスタンスは、eu-west-1 リージョンの VPC のプライベートサブネットでホストされます。VPC には、10.0.0.0/16 の CIDR ブロックが割り当てられました。この会社の請求チームは最近、新しい AWS アカウントを作成し、eu-central-1 リージョンの VPC のプライベートサブネットでホストされている EC2 インスタンスにアプリケーションをデプロイしました。新しい VPC には、10.0.0.0/16 の CIDR ブロックが割り当てられます。

    この処理アプリケーションは、独自の TCP ポートを介して課金アプリケーションと安全に通信する必要があります。

    ソリューションアーキテクトは、最小限の運用労力でこの要件を満たすために何をすべきですか。

    1. 請求チームのアカウントで、192.168.0.0/16 の CIDR ブロックを使用する新しい VPC とサブネットを、eu-west-1 に作成する。処理チームのアカウントで、AWS PrivateLink による VPC エンドポイントサービスを作成する。新しい VPC にインターフェイス VPC エンドポイントを作成する。2 つの VPC 間の請求チームのアカウントで、リージョン間 VPC ピアリング接続を構成する。

       正解です。このソリューションは、2 つの VPC 内のクライアントとサーバーの IP アドレスが重複している場合に適しています。PrivateLink は、クライアント VPC 内で Elastic Network Interface を使用するため、サービスプロバイダーとの IP アドレスの競合はありません。VPC ピアリング、VPN、および AWS Direct Connect 接続を介して PrivateLink エンドポイントにアクセスできます。

       PrivateLink の詳細については、[AWS PrivateLink](https://docs.aws.amazon.com/whitepapers/latest/building-scalable-secure-multi-vpc-network-infrastructure/aws-privatelink.html) を参照してください。

       参考： https://blog.denet.co.jp/aws-privatelink-connection/#AWS_PrivateLink%E3%81%A8%E3%81%AF

       > AWS PrivateLinkとは
       > お客様のVPCとサービスの間でトラフィックをインターネットに公開することなく、プライベート接続を実現するサービスになります。
       > 簡単に言えば、VPC内に作成したEC2インスタンス等からAPIサービス等への接続が、パブリックなインターネットトラフィックを経由することなく、AWSサービス内で留めることが可能になります。
       > これによって、通信内容が第三者に暴露される可能性を下げることが出来ますし、APIサービス側はDDoS攻撃等から守ることが出来ます。
       >VPCピアリングと何が違うの？
       > <u>**大きく違う部分としては、VPCピアリングは、VPC間を接続するためVPCのネットワーク(CIDR)の重複を気にする必要がありますが、独自のエンドポイントサービスを作成してAWS PrivateLink接続する場合、CIDRの重複を気にする必要はありません。</u>**
       > VPC間を接続しない代わりに、AWS PrivateLinkでVPCからのトラフィックを処理するためのElastic Network Interface(ENI)がVPC内にあるサブネット上で作成されます。

12. ある企業は、長期にわたる分析プロセスをオンプレミスで実行しています。現在のインフラストラクチャは、低レイテンシーのファイバーネットワークを介して接続された高性能サーバーのクラスターで構成されています。現在のインフラストラクチャでは、大規模なハードウェアアップグレードが予定されており、大幅な予算の増額が必要になります。同社は、分析プロセスを AWS に移行することを検討しています。ソリューションアーキテクトは、AWS でオンプレミスアーキテクチャをレプリケートするソリューションを推奨する必要があります。

    これらの要件を最もコスト効率に優れた方法で満たすソリューションはどれですか。

    1. リザーブドインスタンスを含むクラスタープレイスメントグループに Amazon EC2 Fleet を作成する

       正解です。クラスタープレイスメントグループは、必要な低レイテンシーの通信を提供します。リザーブドインスタンスは、長時間にわたって実行される一貫性のある分析処理のための最もコスト効率の高い選択肢です。

       **<u>パーティション配置グループは、必要な低レイテンシーの通信を提供しません。クラスタープレイスメントグループの方が良いソリューションです。</u>**

13. ある企業には、複雑な一連の処理アクティビティを実行する一連の AWS Lambda 関数があります。関数は特定の順序で実行する必要があります。通常、ワークフロー全体は数秒で終了し、ワークフローは常に 20 秒未満で終了します。単一の Amazon API Gateway REST API コールが処理リクエストを処理します。REST API は、リクエストが完了したときにレスポンスを要求します。複数のリクエストを同時に処理することは可能です。API Gateway コードは、ワークフローが呼び出されるたびに同じ実行名を再利用します。同社は、ワークフローを作成および管理するためのソリューションとして AWS Step Functions を検討しています。

    これらの要件を満たすソリューションはどれですか。

    1. Step Functions エクスプレスワークフローステートマシンを作成する同期実行を使用してステートマシンを起動する

       正解です。Step Functions は、Lambda 関数と他の AWS のサービスを組み合わせてビジネスアプリケーションを構築するサーバーレスサービスです。**<u>エクスプレスワークフローでは、複数の同時リクエストが許可されます。同期実行は、ワークフローが完了するのを待って、API Gateway に応答を返します。</u>**

       **<u>スタンダードワークフローステートマシンは、同じ名前の複数の同時実行をサポートしていません。このシナリオでは、複数の要求を同時に処理するために複数の同時実行が必要になります。</u>**

       また、非同期実行では、API Gateway が必要とする即時の応答は提供されません。

14. ある企業が、データセンターから AWS Cloud にアプリケーションを移行しています。このアプリケーションは現在、サードパーティーサービスへのアクセスに使用される API キーをローカルファイルに保存しています。アプリケーションが AWS にデプロイされると、アプリケーションは Amazon EC2 インスタンスで実行されます。移行の一環として、アプリケーションは API キーのセキュリティを強化する必要があります。具体的には、アプリケーションには次の要件があります:

    - 各環境 (開発、テスト、本番環境など) には独自の API キーが必要です。
    - すべての API キーアクセス要求は、監査目的でログに記録する必要があります。
    - API キーは、カスタマーマネージドキーを使用して保管時に暗号化する必要があります。
    - アクセス許可はきめ細かいものでなければなりません。例えば、開発環境は本番 API キーにアクセスできない、などです。

    これらの要件を満たす最も安全な方法は何ですか。

    1. 各 API キーに対して AWS Systems Manager Parameter Store の安全な文字列を作成する。カスタマーマネージド AWS Key Management Service (AWS KMS) CMK を使用して、安全な文字列を暗号化する。CMK の kms:Decrypt アクション、および適切な API キーの ssm:GetParameter アクションに対するアクセス許可を持つ各環境の IAM ロールを作成する。適切な IAM ロールで各 EC2 インスタンスを起動する。

       正解です。シークレットはパラメータストアに再配置できます。**<u>パラメータストアでは、階層、アクセス制御、およびアクセスの監査ができます。</u>**永続的な認証情報を使用するよりも、IAM ロールの方が適しています。

       不正解です。**<u>EC2 インスタンスの認証情報ストアのアクセスキーはプレーンテキストであり、永続的です。アクセスキーは、一時的な認証情報である IAM ロールよりも公開されるリスクが高くなります。</u>**認証情報のローテーションはロールのローテーションよりも難しく、ローテーションの頻度は低くなる可能性があります。

15. あるソリューションアーキテクトは、調査会社向けのアプリケーションを設計しています。そのアプリケーションは、夜間に複数の複雑な数学的計算を実行するものです。各計算は、他の計算とまったく関係なく独立して実行されます。それぞれの計算の実行が完了するまでに数時間かかることがあります。

    このアプリケーション設計では、コストと相互依存性を最小限に抑える必要があります。計算は並行して実行する必要があります。

    これらの要件を満たすために、ソリューションアーキテクトは何をすればよいですか。

    1. 計算をジョブとして AWS Batch に送信する。Amazon Elastic Container Service (Amazon ECS) 内の個別のコンテナでジョブを実行する。

       正解です。AWS Batch は必要なリソースを自動的にプロビジョンし、ジョブが終了するとリソースを終了します。

    2. 各計算を Amazon API Gateway API に送信する。AWS Lambda 関数を使用して計算を実行する。

       不正解です。<u>**Lambda 関数は 15 分後にタイムアウトします。この計算の実行が完了するまでに数時間を要する場合があります。**</u>タイムアウトのため、このソリューションでは要件を満たしません。

    3. 各計算をプライマリ Amazon EC2 インスタンスに送信する。計算を適切な EC2 ノードに転送するように EC2 インスタンスを設定する。

       不正解です。この設計では、インスタンスを継続的に実行する必要があります。このソリューションは、最もコスト効率に優れた選択肢ではありません。

16. ある企業が、オンプレミスのデータセンターから AWS Cloud へのシステムの完全な移行を実行しています。この会社は、オンプレミスで保存されているすべてのデータを 4 週間以内に Amazon S3 に移動する必要があります。現在、オンプレミスストレージは 900 TB のデータを保持し、100 Mbps 接続でインターネットに接続されています。既存のシステムは、接続のスループットの最大 20% をリアルタイムで使用します。

    要求された期間内に移行を完了できるソリューションはどれですか。

    1. データを出荷するのに十分な数の AWS Snowball Edge Storage Optimized デバイスを注文する。

       正解です。これは、要求された期間内に要件を満たせる唯一のソリューションです。この会社には十分な数のデバイスが必要ですが、移行を完了するには 4 週間は十分な時間です。

       Snowball Edge のデータ移行の詳細については、[AWS Snowball Edge のデータ移行](https://d1.awsstatic.com/whitepapers/snowball-edge-data-migration-guide.pdf)を参照してください。

17. ある会社の各開発チームは、AWS Organizations に独自の非本番環境の AWS アカウントを持っています。これらの各アカウントでは、開発者の IAM グループに IAM ユーザーがいて、ユーザーに管理権限とコストアクセス許可を付与しています。各開発チームは、月次予算を超過してしまうのが常態化しています。この会社では、開発チームに制約を設け、支出を削減したいと考えています。

    開発チームが月次予算を超えた場合、新しいリソースを立ち上げられないようにするソリューションはどれですか。

    1. <u>**管理アカウントで、リンクされた各開発アカウントの AWS Budgets を使用して予算を作成する。予測予算が月次予算額の 100% に達したら、Amazon Simple Notification Service (Amazon SNS) トピックに発行する。アカウントの新しい SCP を作成する AWS Lambda 関数をトピックにサブスクライブして、新しいインフラストラクチャの起動を拒否する。Amazon EventBridge (Amazon CloudWatch Events) を使用して、月初にこれらの SCP を削除する Lambda 関数をスケジュールする。**</u>

       正解です。この予算は管理アカウントにあるため、開発者はそれを変更できません。アカウント内のユーザーが管理者権限を持っている場合でも、SCP を上書きすることはできません。

    2. 管理アカウントで、リンクされた各開発アカウントの AWS Budgets を使用して予算を作成する。予測予算が月次予算額の 100% に達したら、Amazon Simple Notification Service (Amazon SNS) トピックに発行する。ポリシーを開発者 IAM グループに追加する AWS Lambda 関数のトピックをサブスクライブして、新しいインフラストラクチャの起動を拒否する。Amazon EventBridge (Amazon CloudWatch Events) を使用して、月初にこれらのポリシーを削除する Lambda 関数をスケジュールする。

       不正解です。**<u>開発者は管理者権限を持っているため、IAM グループから新しいポリシーを削除して、引き続き利用することができます。</u>**

    3. 各開発アカウントで、AWS Budgets を使用して予算を作成する。予測予算が月次予算額の 100% に達したら、Amazon Simple Notification Service (Amazon SNS) トピックに発行する。ポリシーを開発者 IAM グループに追加する AWS Lambda 関数のトピックをサブスクライブして、新しいインフラストラクチャの起動を拒否する。Amazon EventBridge (Amazon CloudWatch Events) を使用して、月初にこれらのポリシーを削除する Lambda 関数をスケジュールする。

       不正解です。管理者権限で、開発者は AWS Budgets が開発アカウント内にある場合、AWS Budgets をオフにすることができます。

18. ある企業には、Application Load Balancer の背後にある Amazon EC2 インスタンスで実行される、3 層のウェブアプリケーションがあります。ウェブ層とアプリケーション層のインスタンスは Amazon EC2 Auto Scaling グループで実行されます。同社は、PostgreSQL データベースを実行する単一の EC2 インスタンスにデータ層を実装しました。同社はすでに CloudFormation Stacksets を使用して、ウェブ層とアプリケーション層を第 2 リージョンにレプリケートしています。同社は、設定された加重レコードセットで Amazon Route 53 を使用して DNS リクエストを管理しています。ソリューションアーキテクトは、データ層のマルチリージョンフェイルオーバー戦略を設計する必要があります。

    最速の復旧時間でこれらの要件を満たすソリューションはどれですか。

    1. データベースを Amazon Aurora Global Database に移行する2 番目のリージョンにセカンダリ DB クラスターを作成する

       正解です。**<u>Aurora グローバルデータベースは複数の AWS リージョンにまたがります。このソリューションにより、別のリージョンへの高速フェイルオーバーが可能になります。</u>**

       Aurora グローバルデータベースの詳細については、「[Amazon Aurora Global Database の使用](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database.html)」を参照してください。

       災害対策の詳細については、「[Amazon Aurora Global Database のフェイルオーバーを使用する](https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-global-database-disaster-recovery.html)」を参照してください。

    2. データベースを Amazon RDS for PostgreSQL DB インスタンスに移行する2 番目のリージョンにリードレプリカを作成する

       不正解です。Amazon RDS は、AWS クラウド上でリレーショナルデータベースを簡単にセットアップ、オペレーション、スケールできるウェブサービスです。**<u>ただし、リードレプリカを 2 番目のリージョンにフェイルオーバーするにはマニュアル作業が必要です。</u>**このソリューションでは、最速の復旧時間は提供されません。

19. ある会社では AWS に 3 層のアプリケーションがあります。最初の 2 つの層は、エンタープライズ Java ウェブアプリケーションと注文処理アプリケーションで構成されています。どちらのアプリケーションも、会社が複数のアベイラビリティーゾーンにデプロイした Amazon EC2 Auto Scaling グループで実行されます。注文処理アプリケーションは、複雑なスタンドアロンプログラムです。通常、注文処理アプリケーションは数分以内に終了します。ただし、大量注文の場合、処理に数時間がかかることがあります。データベース層は、EC2 インスタンスで実行される MySQL データベースで構成されています。同社は、管理するサーバーの数を減らしたいと考えています。

    これらの要件を満たすソリューションはどれですか。

    1. ソースコードに基づいて AWS App Runner サービスとして実行するようにウェブアプリケーションをリホストする既存のウェブアプリケーションコードをソースとして使用する注文処理アプリケーションをコンテナに変換し、AWS Fargate で実行するデータベースを Amazon RDS MySQL データベースに変換する

       正解です。App Runner は、ソースコードまたはコンテナイメージから AWS クラウド内のスケーラブルで安全なウェブアプリケーションに直接デプロイするための、高速、シンプル、コスト効率の高い方法を提供する AWS のサービスです。コンテナを作成し、AWS Fargate で既存の注文処理アプリケーションを実行するソリューションでは、注文処理アプリケーションのサーバー管理が不要になります。データベースを AWS RDS MySQL データベースに変換するソリューションでは、データベース層のサーバー管理が不要になります。このソリューションを実装するのに必要な開発作業はほとんどありません。

       App Runner の詳細については、「[What Is AWS App Runner? (AWS App Runner とは)](https://docs.aws.amazon.com/apprunner/latest/dg/what-is-apprunner.html)」を参照してください。

    

    

    ### [試験問題サンプル](https://d1.awsstatic.com/ja_JP/training-and-certification/docs-sa-pro/AWS-Certified-Solutions-Architect-Professional_Sample-Questions.pdf)

    1. ある企業には、個々のビジネスグループが所有する多数の AWS アカウントがあります。そのアカウントの うちの 1 つが最近侵害されました。攻撃者が多数のインスタンスを起動したため、そのアカウントの請求額が 高額になりました。 同社はセキュリティ侵害に対処しましたが、ソリューションアーキテクトは、すべてのアカウントで過剰な支出 を防ぐソリューションを開発しなければなりません。各ビジネスグループは、各自の AWS アカウントで完全な コントロールを維持したいと考えています。 これらの要件を満たすために、ソリューションアーキテクトが推奨すべきソリューションはどれですか。 

       A) AWS Organizations を使用する。各 AWS アカウントを管理アカウントに追加する。ec2:InstanceType 条件キーを使用する SCP を作成して、各アカウントで高コストのインスタンスタイプが起動されない ようにする。 

       B) カスタマー管理型の新しい IAM ポリシーを、各アカウントの IAM グループに添付する。 ec2:InstanceType 条件キーを使用するようにポリシーを設定し、高コストのインスタンスタイプが起動 されないようにする。既存の IAM ユーザーをすべて各グループに配置する。 

       C) AWS アカウントごとに請求アラートをオンにする。アカウントが指定された支出しきい値を超えると 必ず Amazon Simple Notification Service (Amazon SNS) 通知をアカウント管理者に送信する Amazon CloudWatch アラームを作成する。 

       D) 各アカウントで AWS Cost Explorer をオンにする。各アカウントの Cost Explorer レポートを 定期的に確認して、支出が希望額を超えていないことを確認する。

       1. (正解)C – 請求アラームは、どのビジネスグループからもコントロールを奪うことなく、過剰な支出に関する アラートを提供します。各ビジネスグループが各自のアカウントのコントロールを維持したいと考えているた め、オプション A と B は正しくありません。これらのオプションによって、大量のインスタンスの起動が 妨げられることはありません。オプション D は手動のプロセスで、過剰な支出に関するアラートはすぐには 提供されません。

          ※[こちら](https://dev.classmethod.jp/articles/restrict-iam-policy-specific-instance-types/)参照。ec2:InstanceTypeはインスタンスのタイプ(t2.microなど)を指定するもので、大量のインスタンスの軌道を防ぐものではない。

    2. ある企業は、AWS Organizations 内の組織に複数の AWS アカウントを持っています。同社は オンプレミスの Active Directory と AWS Single Sign-On (AWS SSO) を統合し、すべてのアカウントの インフラストラクチャを管理するための最小権限のアクセス許可を Active Directory ユーザーに 付与しています。 ソリューションアーキテクトは、すべての AWS アカウントでの読み取り専用アクセスを必要とする、 サードパーティーのモニタリングソリューションを統合しなければなりません。 モニタリングソリューションは独自の AWS アカウントで実行されます。 モニタリングソリューションに必要なアクセス許可を与えるために、ソリューションアーキテクトは何を すべきですか。 

       A) AWS SSO ディレクトリにユーザーを作成する。読み取り専用アクセス許可セットをユーザーに 割り当てる。モニタリングが必要なすべての AWS アカウントをユーザーに割り当てる。 サードパーティーのモニタリングソリューションに、ユーザー名とパスワードを指定する。 

       B) 組織の管理アカウントに IAM ロールを作成する。サードパーティーのモニタリングソリューションの AWS アカウントにロールを引き受けることを許可する。 

       C) サードパーティーのモニタリングソリューションの AWS アカウントを組織に招待する。 すべての機能を有効にする。

       D) サードパーティーのモニタリングソリューションの新しい IAM ロールを定義する AWS CloudFormation テンプレートを作成する。信頼ポリシーで、サードパーティーの モニタリングソリューションの AWS アカウントを指定する。スタックセットを使用して、 リンクされたすべての AWS アカウントで IAM ロールを作成する。

       1. D – AWS CloudFormation StackSets は、1 回のオペレーションで複数のアカウントに IAM ロールを デプロイできます。AWS Single Sign-On (AWS SSO) によって提供される認証情報は一時的なものであるため、 オプション A は正しくありません。アプリケーションはアクセス許可を失い、再度ログインが必要になり ます。オプション B では、管理アカウントにのみアクセス権が付与されます。オプション C は正し くありません。これは、あるアカウントが組織に加入すると、そのアカウントには組織内の他のアカウントへの アクセス許可が付与されないためです。

    3. あるチームが、パブリック Amazon S3 バケットでホストされる HTML フォームを作成しています。 このフォームでは、JavaScript を使用して Amazon API Gateway API エンドポイントにデータを ポストします。API エンドポイントは AWS Lambda 関数と統合されています。チームは API Gateway コンソールで各メソッドをテストし、有効な応答を受け取りました。 フォームが API エンドポイントに正常にポストされ、有効な応答を受け取れるように、チームはどの ステップの組み合わせを完了する必要がありますか。 (2 つ選択) 

       A) クロスオリジンリソース共有 (CORS) を許可するように S3 バケットを設定する。 

       B) Amazon S3 ではなく Amazon EC2 でフォームをホストする。 

       C) API Gateway のクォータ引き上げをリクエストする。 

       D) API Gateway でクロスオリジンリソース共有 (CORS) を有効にする。 

       E) S3 バケットをウェブホスティング用に設定する。

       1. D、E – クロスオリジンリソース共有 (CORS) は、ブラウザで実行されるスクリプトから開始される HTTP リクエストを制限するブラウザセキュリティ機能です。CORS は通常、別のドメインまたはオリジンでホストさ れている API にアクセスするウェブアプリケーションを構築するために必要です。CORS を有効にして、 別のドメインでホストされているウェブアプリケーションからの API へのリクエストを許可できます。 例えば、API が https://[api_id].execute-api.[region].amazonaws.com/ でホストされており、 [bucketname].s3.website-[region] でホストされているウェブアプリケーションから API を呼び出すには、 API が CORS をサポートしている必要があります。ウェブサイトエンドポイントを介して HTML フォームを 提供するには、オプション E が必要です。

    4. ある会社が、Amazon API Gateway、AWS Lambda 関数、Amazon Cognito、Amazon DynamoDB を 使用するサーバーレスモバイルアプリケーションを実行しています。トラフィックが急増すると、ユーザーか ら、断続的にシステム障害が発生しているとの報告があります。API Gateway API エンドポイントが、 有効なリクエストに対して HTTP ステータスコード 502 (Bad Gateway) エラーを返しています。 この問題を解決するソリューションはどれですか。

       A) Lambda 関数の同時実行クォータを増やす。ConcurrentExecutions メトリクスがクォータに近づいた ときに通知アラートを送信するように Amazon CloudWatch を設定する。 

       B) API Gateway API エンドポイントの 1 秒あたりのトランザクションクォータに関する通知アラートを 設定する。クォータに達したときにクォータを増やす Lambda 関数を作成する。 

       C) 複数の AWS リージョンの Amazon Cognito ユーザープールにユーザーをシャーディングして、 ユーザー認証のレイテンシーを低減する。 

       D) DynamoDB の強力な整合性のある読み込みを使用して、クライアントアプリケーションが常に最新の データを受信できるようにする。

       1.  A – **<u>Amazon API Gateway は、AWS Lambda 関数が同時実行クォータを超えると、HTTP ステータスコード 502 (Bad Gateway) エラーを断続的に返します。この場合、API Gateway はリクエストが多すぎるとステータ スコード 429 エラーを返すため、オプション B は正しくありません。</u>**エラーは認証プロセス中ではなく、 API Gateway API エンドポイントの呼び出し中に発生するため、オプション C は正しくありません。 古いデータによって Bad Gateway エラーは発生しないため、オプション D は正しくありません。

    5. ある企業が Amazon Elastic Container Service (Amazon ECS) クラスターで新しいウェブサービスを 立ち上げています。クラスターは 100 個の Amazon EC2 インスタンスで構成されています。会社の ポリシーでは、クラスターインスタンスのセキュリティグループが HTTPS (ポート 443) を除くすべての インバウンドトラフィックをブロックすることを義務付けています。 これらの要件を満たすソリューションはどれですか。

       A) ユーザーデータスクリプトを使用して、クラスターインスタンスの SSH ポートを 2222 に変更する。 ポート 2222 経由で SSH を使用して各インスタンスにログインする。 

       B) ユーザーデータスクリプトを使用して、クラスターインスタンスの SSH ポートを 2222 に変更する。 AWS Trusted Advisor を使用して、ポート 2222 経由でクラスターインスタンスをリモート管理する。 

       C) SSH キーペアなしでクラスターインスタンスを起動する。AWS Systems Manager Run Command を 使用して、クラスターインスタンスをリモート管理する。 

       D) SSH キーペアなしでクラスターインスタンスを起動する。AWS Trusted Advisor を使用して、 クラスターインスタンスをリモートで管理する。

       1.  C – AWS Systems Manager Run Command では、**<u>インバウンドポートを開く必要はありません。</u>** Run Command は、セキュリティグループに対してデフォルトで開かれているアウトバウンド HTTPS 上で 完全に動作します。オプション A と B は正しくありません。開いておくべき受信ポートは 443 だけであるという要件があるためです。AWS Trusted Advisor にこの管理機能はないため、オプション D は 正しくありません。

    6. ある会社には 2 つの AWS アカウントがあります。1 つのアカウントは本番環境のワークロード用、 もう 1 つのアカウントは開発ワークロード用です。開発チームと運用チームが、これらのワークロードを 作成して管理しています。同社は、次の要件を満たすセキュリティ戦略を必要としています。 • 開発チームのメンバーは、開発アプリケーションインフラストラクチャを作成および削除する 必要がある。 • 運用チームのメンバーは、開発および本番環境のアプリケーションインフラストラクチャを作成および 削除する必要がある。 • 開発チームのメンバーは本番インフラストラクチャにアクセスできてはならない。 • すべてのユーザーが 1 セットの AWS 認証情報を持っている必要がある。 これらの要件を満たす戦略はどれですか。 

       A) 本番稼働用アカウントで以下を実行します。 • アプリケーションインフラストラクチャを作成および削除できる運用 IAM グループを 作成する。 • 運用チームのメンバーごとに IAM ユーザーを作成する。これらのユーザーを運用グループに 割り当てる。 開発アカウントで以下を実行します。 • アプリケーションインフラストラクチャを作成および削除できる開発 IAM グループを 作成する。 • 運用チームのメンバーと開発チームのメンバーごとに IAM ユーザーを作成する。これらの ユーザーを開発グループに割り当てる。 

       B) 本番稼働用アカウントで以下を実行します。 • アプリケーションインフラストラクチャを作成および削除できる 運用 IAM グループを 作成する。 開発アカウントで以下を実行します。 • アプリケーションインフラストラクチャを作成および削除できる開発 IAM グループを 作成する。 • 開発チームのメンバーごとに IAM ユーザーを作成する。これらのユーザーを開発グループに 割り当てる。運用チームのメンバーごとに IAM ユーザーを作成する。これらのユーザーを開発グループと 本番稼働用アカウントの運用グループに割り当てる。 

       C) 開発アカウントで以下を実行します。 • 本番稼働用アカウントでアプリケーションインフラストラクチャを作成および削除できる 共有 IAM ロールを作成する。 • アプリケーションインフラストラクチャを作成および削除できる開発 IAM グループを 作成する。 • 共有ロールを引き受けることができる運用 IAM グループを作成する。 • 開発チームのメンバーごとに IAM ユーザーを作成する。これらのユーザーを開発グループに 割り当てる。 • 運用チームのメンバーごとに IAM ユーザーを作成する。これらのユーザーを開発グループと 運用グループに割り当てる。 

       D) 本番稼働用アカウントで以下を実行します。 • アプリケーションインフラストラクチャを作成および削除できる共有 IAM ロールを作成する。 • 開発用アカウントを共有ロールの信頼ポリシーに追加する。 開発アカウントで以下を実行します。 • アプリケーションインフラストラクチャを作成および削除できる開発 IAM グループを 作成する。 • 本番稼働用アカウントで共有ロールを引き受けることができる運用 IAM グループを作成する。 • 開発チームのメンバーごとに IAM ユーザーを作成する。これらのユーザーを開発グループに 割り当てる。 • 運用チームのメンバーごとに IAM ユーザーを作成する。これらのユーザーを開発グループと 運用グループに割り当てる。

       1. D – 正解は、管理する 2 つのアカウント間でクロスアカウントアクセスを許可するための標準的なガイドラ インに従っています。オプション A では、運用チームのメンバーに 2 セットの認証情報が必要なため、 要件を満たしていません。IAM ユーザーを別のアカウントの IAM グループに追加できないため、オプション B は正しくありません。ロールは別のアカウントのリソースへのアクセス権を付与できないため、オプション C は正しくありません。共有ロールは、その共有ロールが管理するリソースと同じアカウントに属している 必要があります。

    7. あるソリューションアーキテクトが、ビッグデータアプリケーションのコストを削減しなければならなくなり ました。アプリケーション環境は、Amazon Kinesis Data Streams にイベントを送信する数百ものデバイスで 構成されています。デバイス ID はパーティションキーとして使用されるため、各デバイスは個別のシャードを 取得します。各デバイスは、毎秒 50 KB から 450 KB のデータを送信します。AWS Lambda 関数はシャード をポーリングしてデータを処理し、その結果を Amazon S3 に保存します。 別の Lambda 関数が 1 時間ごとに結果データに対して Amazon Athena クエリを実行し、外れ値を特定しま す。この Lambda 関数は、外れ値を Amazon Simple Queue Service (Amazon SQS) キューに配置します。 2 つの EC2 インスタンスで構成される Amazon EC2 Auto Scaling グループは、キューをモニタリングし、 外れ値に対処するために 30 秒のプロセスを実行します。デバイスは 1 時間ごとに平均 10 個の外れ値を 送信します。 アプリケーションに対する変更の組み合わせで、最もコストが削減されるのはどれですか。 (2 つ選択) 

       A) Auto Scaling グループの起動設定を変更して、同じインスタンスファミリーでより小さい インスタンスタイプを使用するようにする。

       B) Auto Scaling グループを、メッセージがキューに到着したときに呼び出される Lambda 関数に 置き換える。 

       C) デバイスとデータストリームを再構成して、1 つのデータストリームシャードに対して 10 台の デバイスの比率を設定する。 

       D) デバイスとデータストリームを再構成して、1 つのデータストリームシャードに対して 2 台の デバイスの比率を設定する。 

       E) Auto Scaling グループのターゲット容量を EC2 インスタンス 1 つに変更する。

       1. B、D – 外れ値を処理するコンピューティングの平均量は 1 時間あたり 300 秒 (30 秒ごとに 10 個の イベント) です。AWS Lambda では、外れ値の処理に必要なわずかなコンピューティング時間に対してのみ 支払いが発生するため、オプション B が正解です。オプション A と E はコストを削減しますが、いずれの 場合も 1 時間あたり 3,300 秒間使用されない Amazon EC2 インスタンス 1 つ以上の料金を支払う必要が あります。オプション C と D は、Kinesis Data Streams のシャード時間のコストを削減します。ただし、 データ量が単一のシャードの 1 MB/秒のクォータを超えるため、オプション C は正しくありません。

    8. ある企業は、Application Load Balancer の背後で Amazon EC2 インスタンス上に e コマース アプリケーションを運用しています。インスタンスは、複数のアベイラビリティーゾーンにまたがる Amazon EC2 Auto Scaling グループ内で実行されます。注文が正常に処理されると、アプリケーションは 注文データをサードパーティーのアフィリエイトの外部追跡システムに即座にポストし、そのシステムから 注文の紹介に対して売上手数料が支払われます。 マーケティングプロモーションが成功すると、EC2 インスタンスの数が 2 から 20 に増加しました。 この間、アプリケーションは正常に動作し続けました。しかし、リクエスト率の上昇でサードパーティーの アフィリエイトが過負荷になり、リクエストが失敗する結果となりました。 負荷がかかってもプロセス全体が正しく機能するように、ソリューションアーキテクトはどのアーキテクチャの 変更を組み合わせて行うべきですか。 (2 つ選択) 

       A) アフィリエイトを呼び出すコードを新しい AWS Lambda 関数に移動する。Lambda 関数を非同期で 呼び出すようにアプリケーションを変更する。 

       B) アフィリエイトを呼び出すコードを新しい AWS Lambda 関数に移動する。注文データを Amazon Simple Queue Service (Amazon SQS) キューに配置するようにアプリケーションを変更する。 キューから Lambda 関数を呼び出す。 

       C) 新しい AWS Lambda 関数のタイムアウトを増やす。 

       D) 新しい AWS Lambda 関数の予約済み同時実行数を減らす。 

       E) 新しい AWS Lambda 関数のメモリを増やす。

       1. B、D – オプション B では、Amazon Simple Queue Service (Amazon SQS) キューを使用すると、 メインアプリケーションがアフィリエイトへの呼び出しから切り離されます。この変更により、 メインアプリケーションがアフィリエイトの容量低下から保護されます。また、失敗したリクエストは自動的に キューに戻ることができます。オプション D では、同時呼び出しの数を減らすことで、 アフィリエイトアプリケーションが過負荷になるのを防ぐことができます。 オプション A は Amazon EC2 インスタンスの負荷を軽減しますが、このソリューションでは アフィリエイトアプリケーションへのリクエスト数は減りません。オプション C では、外部呼び出しが 返されるまでの AWS Lambda 関数の待機時間が長くなりますが、このソリューションではアフィリエイトアプ リケーションの負荷は軽減されません。メモリの増加は Lambda 関数とアフィリエイト追跡システム間の相互 作用には影響しないため、オプション E は正しくありません。

    9. ) ある企業が AWS でオンラインチケット発行ウェブアプリケーションを構築しました。 このアプリケーションは AWS App Runner でホストされ、Amazon Elastic Container Registry (Amazon ECR) リポジトリに保存されているイメージを使用します。アプリケーションは Amazon Aurora MySQL DB クラスターにデータを格納します。同社は Amazon Route 53 にドメイン名を設定しています。 アプリケーションは、Active-Active 構成の 2 つの AWS リージョンにデプロイする必要があります。 アーキテクチャの変更を最小限に抑えながら、これらの要件を満たすステップの組み合わせはどれですか。 (3 つ選択) 

       A) ECR イメージの 2 つ目のリージョンへのクロスリージョンレプリケーションを設定する。

       B) 2 つ目のリージョンの ECR リポジトリから VPC エンドポイントを作成する。 

       C) 2 つ目のデプロイターゲットを 2 つ目のリージョンに追加して、App Runner 設定を編集する。 

       D) App Runner を 2 番目のリージョンにデプロイする。Route 53 レイテンシールーティングポリシーを 設定する。 

       E) 目的の 2 つのリージョンで Amazon DynamoDB グローバルテーブルを使用して、データベースを 変更する。 

       F) 2 つ目のリージョンで書き込み転送が有効になっている Aurora グローバルデータベースを使用する。

       1. A、D、F – AWS App Runner は、Amazon Elastic Container Registry (Amazon ECR) リポジトリに保存され ているイメージを使用して、コンテナ化されたウェブアプリケーションを迅速にデプロイするために使用できる フルマネージドサービスです。**<u>クロスリージョンレプリケーションでは 2 番目の AWS リージョンに リポジトリのコピーが作成される</u>**ため、オプション A は正解です。Route 53 を使用してカスタムドメイン名を ホストし、複数の AWS リージョンのリソースにトラフィックをルーティングできるため、オプション D は 正解です。Amazon Aurora Global Database は複数のリージョンにまたがり、グローバルに分散された アプリケーション向けに設計されているため、オプション F は正解です。 VPC エンドポイントは別のリージョンに保存されているイメージへのアクセスを提供しないため、オプション B は正しくありません。オプション C では、App Runner にそのような設定は存在しません。オプション E は 機能しますが、Amazon DynamoDB の導入では、Aurora グローバルデータベースを使用する場合よりもアーキテクチャに多くの変更が必要になります。この問題では、アーキテクチャの変更を最小限に抑える 必要があります。

    10. ある企業が AWS クラウドに多層ウェブアプリケーションをデプロイしました。このアプリケーションは、 次の階層で構成されています。 • Elastic IP アドレスを持つ Amazon EC2 インスタンスでホストされている Windows ベースのウェブ層 • パスベースのルーティングを使用する Application Load Balancer (ALB) の背後で実行される EC2 インスタンスでホストされる Linux ベースのアプリケーション層 • Linux EC2 インスタンスで実行される MySQL データベース すべての EC2 インスタンスは Intel ベースの x86 CPU を使用しています。ソリューションアーキテクトは、 パフォーマンスを向上させるためにインフラストラクチャをモダナイズする必要があります。 このソリューションでは、アプリケーションの運用上の必要コストを最小限に抑える必要があります。 これらの要件を満たすために、ソリューションアーキテクトが取るべきアクションの組み合わせはどれですか。 (2 つ選択) 

        A) MySQL データベースを複数の EC2 インスタンスで実行する。 

        B) ウェブ層インスタンスを ALB の背後に配置する。 

        C) MySQL データベースを Amazon Aurora Serverless に移行する。 

        D) すべての EC2 インスタンスタイプを Graviton2 に移行する。 

        E) アプリケーション層インスタンスの ALB を企業が管理するロードバランサーに置き換える。

        1. B、C – オプション B では、ウェブ層を Application Load Balancer (ALB) の背後に配置することで、 ウェブ層の可用性とスケーラビリティを向上させることができます。ALB はクライアントの単一窓口として 機能し、受信するアプリケーショントラフィックを Amazon EC2 インスタンスに分散します。 Amazon Aurora Serverless は高パフォーマンスと高可用性を実現し、運用の複雑さを軽減するため、 オプション C が正解です。 EC2 インスタンスを追加しても運用上の必要コストが最小化されないため、オプション A は正しく ありません。マネージドサービスを選択した方が良いでしょう。**<u>Graviton2 では使用できない Windows インスタンスがアプリケーションに含まれている</u>**ため、オプション D は正しくありません。企業が管理する ロードバランサーでは運用上のコストが最小化されないため、オプション E は正しくありません。

